{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type GPT2Config is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m custom_model \u001b[39m=\u001b[39m GPT2WithCustomHead(config)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Save locally\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m custom_model\u001b[39m.\u001b[39;49msave_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mmy-awesome-model\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmy-awesome-model/config.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     25\u001b[0m     json\u001b[39m.\u001b[39mdump(config\u001b[39m.\u001b[39mto_dict(), f)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hub_mixin.py:159\u001b[0m, in \u001b[0;36mModelHubMixin.save_pretrained\u001b[0;34m(self, save_directory, config, repo_id, push_to_hub, **push_to_hub_kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m is_dataclass(config):\n\u001b[1;32m    158\u001b[0m         config \u001b[39m=\u001b[39m asdict(config)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     (save_directory \u001b[39m/\u001b[39m CONFIG_NAME)\u001b[39m.\u001b[39mwrite_text(json\u001b[39m.\u001b[39;49mdumps(config, indent\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m))\n\u001b[1;32m    161\u001b[0m \u001b[39m# push to the Hub if required\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m push_to_hub:\n",
      "File \u001b[0;32m/usr/local/linux/mambaforge-3.11/lib/python3.11/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    235\u001b[0m     skipkeys\u001b[39m=\u001b[39;49mskipkeys, ensure_ascii\u001b[39m=\u001b[39;49mensure_ascii,\n\u001b[1;32m    236\u001b[0m     check_circular\u001b[39m=\u001b[39;49mcheck_circular, allow_nan\u001b[39m=\u001b[39;49mallow_nan, indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m    237\u001b[0m     separators\u001b[39m=\u001b[39;49mseparators, default\u001b[39m=\u001b[39;49mdefault, sort_keys\u001b[39m=\u001b[39;49msort_keys,\n\u001b[0;32m--> 238\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mencode(obj)\n",
      "File \u001b[0;32m/usr/local/linux/mambaforge-3.11/lib/python3.11/json/encoder.py:202\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    200\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterencode(o, _one_shot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 202\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n\u001b[1;32m    203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(chunks)\n",
      "File \u001b[0;32m/usr/local/linux/mambaforge-3.11/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[1;32m    440\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/linux/mambaforge-3.11/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m     \u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type GPT2Config is not JSON serializable"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Config, GPT2Model\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "\n",
    "class GPT2WithCustomHead(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config_or_model_name, num_labels=None):\n",
    "        super().__init__()\n",
    "        if isinstance(config_or_model_name, str):\n",
    "            self.base_model = GPT2Model.from_pretrained(config_or_model_name)\n",
    "            self.config = self.base_model.config\n",
    "        else:\n",
    "            self.config = config_or_model_name\n",
    "            self.base_model = GPT2Model(self.config)\n",
    "        self.score = nn.Linear(self.config.n_embd, num_labels or self.config.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = self.score(outputs.last_hidden_state[:, -1, :])\n",
    "        return logits\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, *args, **kwargs):\n",
    "        config = GPT2Config.from_pretrained(model_name)\n",
    "        return super().from_pretrained(model_name, config, *args, **kwargs)\n",
    "\n",
    "# Initialize the base model\n",
    "config = GPT2Config.from_pretrained('openai-community/gpt2')\n",
    "config.num_labels = 2\n",
    "custom_model = GPT2WithCustomHead(config)\n",
    "\n",
    "# Save locally\n",
    "custom_model.save_pretrained(\"my-awesome-model\", config=config.to_dict())\n",
    "\n",
    "# Push to the hub\n",
    "custom_model.push_to_hub(\"my-awesome-model\", config=config.to_dict())\n",
    "\n",
    "# Reload\n",
    "custom_model = GPT2WithCustomHead.from_pretrained(\"my-awesome-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
