{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5_f_experiment_0\")\n",
    "model_0 = AutoModelForSeq2SeqLM.from_pretrained(\"t5_f_experiment_0\")\n",
    "model_1 = AutoModelForSeq2SeqLM.from_pretrained(\"t5_f_experiment_1\")\n",
    "model_2 = AutoModelForSeq2SeqLM.from_pretrained(\"t5_f_experiment_2\")\n",
    "model_3 = AutoModelForSeq2SeqLM.from_pretrained(\"t5_f_experiment_3\")\n",
    "model_4 = AutoModelForSeq2SeqLM.from_pretrained(\"t5_f_experiment_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_model_weight = empty_model.state_dict()\n",
    "model_0_weight = model_0.state_dict()\n",
    "model_1_weight = model_1.state_dict()\n",
    "model_2_weight = model_2.state_dict()  \n",
    "model_3_weight = model_3.state_dict()\n",
    "model_4_weight = model_4.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bill_sum_experiment_3_t5_small_merge/tokenizer_config.json',\n",
       " './bill_sum_experiment_3_t5_small_merge/special_tokens_map.json',\n",
       " './bill_sum_experiment_3_t5_small_merge/spiece.model',\n",
       " './bill_sum_experiment_3_t5_small_merge/added_tokens.json',\n",
       " './bill_sum_experiment_3_t5_small_merge/tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in empty_model_weight.keys():\n",
    "    empty_model_weight[key] = torch.mean(torch.stack([model_0_weight[key], model_1_weight[key], model_2_weight[key], model_3_weight[key], model_4_weight[key]]), dim=0)\n",
    "empty_model.load_state_dict(empty_model_weight)\n",
    "empty_model.save_pretrained('./bill_sum_experiment_3_t5_small_merge')\n",
    "tokenizer.save_pretrained('./bill_sum_experiment_3_t5_small_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = AutoModelForSeq2SeqLM.from_pretrained(\"./bill_sum_experiment_3_t5_small_merge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: shared.weight\n",
      "Weight: tensor([[ -2.0153,   0.2239,  -7.0940,  ...,  -0.3533,   2.6409,  -2.8909],\n",
      "        [ 12.6247,   8.1872, -11.6247,  ...,   7.9372,  -7.3127,   0.9456],\n",
      "        [ -8.7499,   7.1873,  27.8749,  ..., -26.7501,   0.8555,  -1.5154],\n",
      "        ...,\n",
      "        [-25.2499, -28.4999, -17.2499,  ..., -17.7499,  -5.2500,  27.3749],\n",
      "        [-25.4999, -29.3749, -18.2499,  ..., -17.7499,  -4.8125,  27.7499],\n",
      "        [-26.7499, -28.3749, -17.8749,  ..., -18.4999,  -7.0000,  27.6249]])\n",
      "\n",
      "Name: encoder.embed_tokens.weight\n",
      "Weight: tensor([[ -2.0153,   0.2239,  -7.0940,  ...,  -0.3533,   2.6409,  -2.8909],\n",
      "        [ 12.6247,   8.1872, -11.6247,  ...,   7.9372,  -7.3127,   0.9456],\n",
      "        [ -8.7499,   7.1873,  27.8749,  ..., -26.7501,   0.8555,  -1.5154],\n",
      "        ...,\n",
      "        [-25.2499, -28.4999, -17.2499,  ..., -17.7499,  -5.2500,  27.3749],\n",
      "        [-25.4999, -29.3749, -18.2499,  ..., -17.7499,  -4.8125,  27.7499],\n",
      "        [-26.7499, -28.3749, -17.8749,  ..., -18.4999,  -7.0000,  27.6249]])\n",
      "\n",
      "Name: encoder.block.0.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[-0.0164, -0.0737,  0.0041,  ...,  0.0271, -0.0368, -0.1193],\n",
      "        [-0.0371, -0.0227,  0.0491,  ..., -0.0427, -0.0487,  0.0669],\n",
      "        [ 0.0540, -0.0566,  0.0055,  ..., -0.0339, -0.0173, -0.0428],\n",
      "        ...,\n",
      "        [-0.0908,  0.0104, -0.1104,  ..., -0.0070, -0.1001,  0.0405],\n",
      "        [ 0.0017,  0.0157, -0.0427,  ..., -0.0962,  0.0300,  0.0015],\n",
      "        [-0.1070,  0.0002, -0.0030,  ...,  0.0529, -0.0432, -0.0522]])\n",
      "\n",
      "Name: encoder.block.0.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 0.0728,  0.0976, -0.0689,  ..., -0.6720, -0.0560,  0.4336],\n",
      "        [ 0.0226,  0.0194, -0.2910,  ..., -0.6484,  0.0981,  0.0646],\n",
      "        [ 0.5430, -0.0143,  0.0995,  ..., -0.1357, -0.0335,  0.3537],\n",
      "        ...,\n",
      "        [ 0.0054,  0.2833,  0.0279,  ..., -0.1524,  0.4336, -0.1818],\n",
      "        [-0.3164, -0.0826, -0.1327,  ...,  0.2030,  0.3769, -0.4434],\n",
      "        [ 0.1992,  0.4024, -0.1875,  ..., -0.5977,  0.1807,  0.4082]])\n",
      "\n",
      "Name: encoder.block.0.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[-0.0191,  0.3924, -0.8165,  ...,  0.3535, -0.4474,  0.1473],\n",
      "        [-0.1357,  0.3263,  0.4452,  ...,  0.1183,  0.5429, -0.4121],\n",
      "        [-0.6445,  0.0939, -0.2373,  ..., -0.1117, -0.5859, -0.1019],\n",
      "        ...,\n",
      "        [ 0.2774, -0.0994,  0.5939,  ...,  0.1749, -0.1051,  0.1028],\n",
      "        [ 0.0328, -0.4647, -0.3360,  ...,  0.7579,  0.0229,  0.0424],\n",
      "        [-0.2217, -0.0233, -0.0242,  ..., -0.8202, -0.3848, -0.3749]])\n",
      "\n",
      "Name: encoder.block.0.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[ 0.8322,  0.1561, -0.9102,  ...,  0.5937, -0.3672,  0.2675],\n",
      "        [ 0.0364,  0.5236,  0.8360,  ..., -0.0516, -0.1483,  0.5703],\n",
      "        [-0.2119, -0.9646, -0.5861,  ...,  0.6253,  0.0198,  0.4431],\n",
      "        ...,\n",
      "        [ 0.4315, -0.8946,  0.4724,  ...,  0.1386,  0.3749, -0.6797],\n",
      "        [-0.2539, -0.8866, -0.5975,  ...,  0.9883,  1.0548, -0.1502],\n",
      "        [ 1.1643, -0.8984,  0.0328,  ..., -0.4199,  0.2452, -0.6017]])\n",
      "\n",
      "Name: encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
      "Weight: tensor([[-2.5157e+00,  2.0148e-02, -1.0812e+01, -2.4786e-01, -6.8440e+00,\n",
      "         -5.6765e-02, -3.9690e+00,  8.4377e-01],\n",
      "        [ 5.4375e+00,  1.3203e+00,  1.1987e-01, -6.1114e-02,  2.8750e+00,\n",
      "          6.1253e+00, -3.1716e+00, -3.6718e+00],\n",
      "        [ 4.1251e+00,  1.0078e+00,  9.5304e-01,  5.2745e-01,  2.9217e+00,\n",
      "          3.2655e+00, -2.8281e+00, -3.6091e+00],\n",
      "        [ 3.2655e+00,  7.8515e-01,  1.2812e+00,  7.5803e-01,  2.7342e+00,\n",
      "          1.7811e+00, -2.6877e+00, -3.5936e+00],\n",
      "        [ 2.5936e+00,  6.1321e-01,  1.3749e+00,  8.4393e-01,  2.5624e+00,\n",
      "          7.5761e-01, -2.7659e+00, -3.5627e+00],\n",
      "        [ 2.0468e+00,  4.5916e-01,  1.4609e+00,  8.7510e-01,  2.4218e+00,\n",
      "          8.4319e-02, -2.7815e+00, -3.6876e+00],\n",
      "        [ 1.6016e+00,  4.0629e-01,  1.4999e+00,  8.3609e-01,  2.2499e+00,\n",
      "         -3.4376e-01, -2.7815e+00, -3.7033e+00],\n",
      "        [ 1.2187e+00,  3.4574e-01,  1.5467e+00,  8.2828e-01,  2.1250e+00,\n",
      "         -6.0565e-01, -2.8128e+00, -3.7344e+00],\n",
      "        [ 4.0413e-01,  1.8947e-01,  1.5701e+00,  8.7524e-01,  1.8202e+00,\n",
      "         -9.0246e-01, -2.9534e+00, -3.7970e+00],\n",
      "        [-6.2906e-01,  8.6498e-02,  1.6015e+00,  8.7132e-01,  1.3595e+00,\n",
      "         -1.1174e+00, -3.0624e+00, -3.9533e+00],\n",
      "        [-1.6251e+00, -3.4137e-02,  1.5938e+00,  8.4768e-01,  9.1018e-01,\n",
      "         -1.2814e+00, -3.2656e+00, -4.0312e+00],\n",
      "        [-2.7814e+00, -1.6489e-01,  1.5939e+00,  8.6724e-01,  3.5941e-01,\n",
      "         -1.3907e+00, -3.4529e+00, -4.1248e+00],\n",
      "        [-3.8594e+00, -3.4945e-01,  1.4845e+00,  9.0627e-01, -2.5587e-01,\n",
      "         -1.5470e+00, -3.5623e+00, -4.2189e+00],\n",
      "        [-5.1562e+00, -5.3504e-01,  1.4219e+00,  9.2581e-01, -9.5297e-01,\n",
      "         -1.6330e+00, -3.7968e+00, -4.3439e+00],\n",
      "        [-7.3123e+00, -7.5788e-01,  1.3048e+00,  9.2966e-01, -1.7890e+00,\n",
      "         -1.8596e+00, -4.0312e+00, -4.5314e+00],\n",
      "        [-9.9372e+00, -1.3048e+00,  1.0701e+00,  1.0388e+00, -4.9373e+00,\n",
      "         -2.3752e+00, -4.3752e+00, -5.1249e+00],\n",
      "        [ 2.1094e-01, -3.7500e-01, -6.6406e-02,  1.7578e-01,  2.2266e-01,\n",
      "         -3.5156e-01,  5.8594e-03, -2.3438e-02],\n",
      "        [-5.0000e+00,  4.4688e+00, -1.4378e+00,  5.7830e-01, -5.0000e+00,\n",
      "         -5.9398e-01,  3.6250e+00,  5.5625e+00],\n",
      "        [-4.7499e+00,  2.8904e+00,  6.7162e-01,  7.9293e-01, -4.2187e+00,\n",
      "         -6.8383e-01,  3.6874e+00,  3.8905e+00],\n",
      "        [-4.6874e+00,  2.1250e+00,  1.0779e+00,  8.4783e-01, -4.1249e+00,\n",
      "         -5.9003e-01,  3.4531e+00,  2.9219e+00],\n",
      "        [-4.7187e+00,  1.6874e+00,  1.2733e+00,  8.3186e-01, -4.0625e+00,\n",
      "         -6.8381e-01,  3.2031e+00,  2.2657e+00],\n",
      "        [-4.7499e+00,  1.3670e+00,  1.3984e+00,  8.3970e-01, -4.0936e+00,\n",
      "         -8.9471e-01,  3.0156e+00,  1.6797e+00],\n",
      "        [-4.8749e+00,  1.0859e+00,  1.4530e+00,  7.8107e-01, -4.0937e+00,\n",
      "         -9.7283e-01,  2.8749e+00,  1.2968e+00],\n",
      "        [-4.8750e+00,  9.6860e-01,  1.4921e+00,  7.6932e-01, -4.1248e+00,\n",
      "         -1.0626e+00,  2.7031e+00,  9.3358e-01],\n",
      "        [-4.9062e+00,  6.3673e-01,  1.5623e+00,  7.3418e-01, -4.1561e+00,\n",
      "         -1.1252e+00,  2.3751e+00,  9.5709e-02],\n",
      "        [-5.0625e+00,  3.8288e-01,  1.5937e+00,  6.0526e-01, -4.1561e+00,\n",
      "         -1.2346e+00,  1.9063e+00, -1.0078e+00],\n",
      "        [-5.0937e+00,  9.0922e-02,  1.5938e+00,  5.1537e-01, -4.1875e+00,\n",
      "         -1.3831e+00,  1.4455e+00, -1.9141e+00],\n",
      "        [-5.2187e+00, -1.1362e-01,  1.5626e+00,  4.6854e-01, -4.2187e+00,\n",
      "         -1.4690e+00,  8.4007e-01, -2.7500e+00],\n",
      "        [-5.2499e+00, -4.3937e-01,  1.5236e+00,  4.0215e-01, -4.2187e+00,\n",
      "         -1.6331e+00,  1.6919e-01, -3.3593e+00],\n",
      "        [-5.3749e+00, -7.8899e-01,  1.3907e+00,  2.7323e-01, -4.2813e+00,\n",
      "         -1.7112e+00, -5.6228e-01, -3.7343e+00],\n",
      "        [-5.3436e+00, -1.0937e+00,  1.3439e+00,  1.4144e-01, -4.3438e+00,\n",
      "         -1.8440e+00, -1.2185e+00, -4.0312e+00],\n",
      "        [-5.4373e+00, -1.5079e+00,  1.0940e+00, -4.5149e-02, -4.2811e+00,\n",
      "         -2.0159e+00, -2.4998e+00, -4.4374e+00]])\n",
      "\n",
      "Name: encoder.block.0.layer.0.layer_norm.weight\n",
      "Weight: tensor([0.0920, 0.1427, 0.0761, 0.0950, 0.1856, 0.0743, 0.1154, 0.1191, 0.1593,\n",
      "        0.0670, 0.0700, 0.0903, 0.0698, 0.0719, 0.1367, 0.0722, 0.0679, 0.0816,\n",
      "        0.0893, 0.0795, 0.0719, 0.0520, 0.1211, 0.1405, 0.0644, 0.0892, 0.0781,\n",
      "        0.1757, 0.0722, 0.1092, 0.0709, 0.1171, 0.1050, 0.0674, 0.1385, 0.1099,\n",
      "        0.0846, 0.0730, 0.0775, 0.0957, 0.0729, 0.0614, 0.0685, 0.1177, 0.1139,\n",
      "        0.0659, 0.2470, 0.0940, 0.0851, 0.0744, 0.0839, 0.1051, 0.1186, 0.1138,\n",
      "        0.1457, 0.0827, 0.0799, 0.0844, 0.0641, 0.1472, 0.0693, 0.1133, 0.1271,\n",
      "        0.0774, 0.0645, 0.1093, 0.0905, 0.0739, 0.2278, 0.1268, 0.1134, 0.0808,\n",
      "        0.0827, 0.0698, 0.0777, 0.0650, 0.0728, 0.0868, 0.1045, 0.1348, 0.1407,\n",
      "        0.0962, 0.0866, 0.1138, 0.0603, 0.1059, 0.0624, 0.0913, 0.0769, 0.3811,\n",
      "        0.0861, 0.1109, 0.0732, 0.0869, 0.0928, 0.0811, 0.0868, 0.0604, 0.0389,\n",
      "        0.0656, 0.0771, 0.0644, 0.1166, 0.1211, 0.0638, 0.0756, 0.0626, 0.0897,\n",
      "        0.0902, 0.0929, 0.0909, 0.1288, 0.0629, 0.0723, 0.0659, 0.1174, 0.0762,\n",
      "        0.0763, 0.0637, 0.0529, 0.0687, 0.0834, 0.0666, 0.0733, 0.0584, 0.2344,\n",
      "        0.0988, 0.0787, 0.0493, 0.0806, 0.0812, 0.0637, 0.1041, 0.1248, 0.0996,\n",
      "        0.0739, 0.1152, 0.0667, 0.0616, 0.0646, 0.0713, 0.1682, 0.1041, 0.0645,\n",
      "        0.0774, 0.0964, 0.1060, 0.0981, 0.1026, 0.0757, 0.0634, 0.0680, 0.1128,\n",
      "        0.0650, 0.0739, 0.0699, 0.0646, 0.1056, 0.0887, 0.2147, 0.0648, 0.1308,\n",
      "        0.0720, 0.0703, 0.0991, 0.0898, 0.0534, 0.1086, 0.0694, 0.0619, 0.1178,\n",
      "        0.0822, 0.0801, 0.0653, 0.0702, 0.0883, 0.0634, 0.1031, 0.0600, 0.0777,\n",
      "        0.0621, 0.1003, 0.1514, 0.1228, 0.1159, 0.0792, 0.0816, 0.0978, 0.0737,\n",
      "        0.1034, 0.1659, 0.0924, 0.0738, 0.1193, 0.0748, 0.0650, 0.0601, 0.1300,\n",
      "        0.0641, 0.0786, 0.1151, 0.1211, 0.1088, 0.0853, 0.0827, 0.0920, 0.1022,\n",
      "        0.1277, 0.0846, 0.0685, 0.0774, 0.0705, 0.1137, 0.1251, 0.0737, 0.0674,\n",
      "        0.0934, 0.0971, 0.1748, 0.0636, 0.0635, 0.0660, 0.1123, 0.0688, 0.1311,\n",
      "        0.0710, 0.0978, 0.0653, 0.1231, 0.1153, 0.0827, 0.0646, 0.0870, 0.0864,\n",
      "        0.1447, 0.0988, 0.0857, 0.0617, 0.0680, 0.1028, 0.1271, 0.1240, 0.0880,\n",
      "        0.0672, 0.1223, 0.2073, 0.1300, 0.1154, 0.0672, 0.1178, 0.0584, 0.0728,\n",
      "        0.1143, 0.0622, 0.0631, 0.0775, 0.0915, 0.0873, 0.0918, 0.1132, 0.1016,\n",
      "        0.0681, 0.0679, 0.1887, 0.1031, 0.0802, 0.0888, 0.0654, 0.0539, 0.0661,\n",
      "        0.0733, 0.1003, 0.1065, 0.1778, 0.0592, 0.1269, 0.0722, 0.0720, 0.1005,\n",
      "        0.1118, 0.1535, 0.1021, 0.0699, 0.1110, 0.0724, 0.0917, 0.1052, 0.1198,\n",
      "        0.0650, 0.1151, 0.1417, 0.0707, 0.0702, 0.0693, 0.1223, 0.1378, 0.0964,\n",
      "        0.0639, 0.0718, 0.0929, 0.1086, 0.1154, 0.1348, 0.0749, 0.1277, 0.0675,\n",
      "        0.0822, 0.1749, 0.1874, 0.1133, 0.0744, 0.0944, 0.0924, 0.0861, 0.0900,\n",
      "        0.0676, 0.0594, 0.0609, 0.1207, 0.1029, 0.0836, 0.0621, 0.0661, 0.1565,\n",
      "        0.1904, 0.0676, 0.1159, 0.0612, 0.0707, 0.1145, 0.1198, 0.1084, 0.1225,\n",
      "        0.0693, 0.0651, 0.0999, 0.1121, 0.0827, 0.0704, 0.1013, 0.1329, 0.0969,\n",
      "        0.0843, 0.1355, 0.0749, 0.1073, 0.1113, 0.0611, 0.0601, 0.1052, 0.1201,\n",
      "        0.0760, 0.0699, 0.0670, 0.0841, 0.1668, 0.0781, 0.0792, 0.0830, 0.1069,\n",
      "        0.0988, 0.0605, 0.0723, 0.0730, 0.0850, 0.1117, 0.0641, 0.1807, 0.0822,\n",
      "        0.0712, 0.0793, 0.1050, 0.0676, 0.0680, 0.1184, 0.0704, 0.0662, 0.0688,\n",
      "        0.0573, 0.1309, 0.0787, 0.1297, 0.1012, 0.0743, 0.1049, 0.0702, 0.0783,\n",
      "        0.0729, 0.1357, 0.0688, 0.0671, 0.0698, 0.0766, 0.0856, 0.0820, 0.0944,\n",
      "        0.0599, 0.0897, 0.0813, 0.1205, 0.1447, 0.1004, 0.0794, 0.2258, 0.0595,\n",
      "        0.0554, 0.0743, 0.0645, 0.0742, 0.0715, 0.0860, 0.1580, 0.1201, 0.1078,\n",
      "        0.0703, 0.1115, 0.0953, 0.1912, 0.0714, 0.0743, 0.0864, 0.0846, 0.0777,\n",
      "        0.0732, 0.1013, 0.0734, 0.0690, 0.0931, 0.0644, 0.1093, 0.0680, 0.0685,\n",
      "        0.0595, 0.1212, 0.0695, 0.0733, 0.0979, 0.0559, 0.0920, 0.1184, 0.0677,\n",
      "        0.0702, 0.0641, 0.0934, 0.0798, 0.0727, 0.0629, 0.1250, 0.0744, 0.0778,\n",
      "        0.0542, 0.0575, 0.0660, 0.1055, 0.1163, 0.0806, 0.0632, 0.0825, 0.0821,\n",
      "        0.0621, 0.0599, 0.0684, 0.0649, 0.0651, 0.0710, 0.0597, 0.0561, 0.1085,\n",
      "        0.1145, 0.0690, 0.0754, 0.0610, 0.0855, 0.0665, 0.0783, 0.0687, 0.0623,\n",
      "        0.1262, 0.0709, 0.0596, 0.1348, 0.0899, 0.0640, 0.0630, 0.0738, 0.0700,\n",
      "        0.0937, 0.0899, 0.0814, 0.0795, 0.1444, 0.0644, 0.0792, 0.0704, 0.0647,\n",
      "        0.1186, 0.0714, 0.0777, 0.0963, 0.1093, 0.0834, 0.1672, 0.1089, 0.0799,\n",
      "        0.0883, 0.1227, 0.1321, 0.0662, 0.1156, 0.0743, 0.0727, 0.0979])\n",
      "\n",
      "Name: encoder.block.0.layer.1.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-0.6835, -1.3515,  0.6485,  ..., -0.2138,  0.4844, -0.1534],\n",
      "        [-0.0661, -0.3087, -0.1492,  ...,  0.4180,  0.1826,  0.5158],\n",
      "        [ 0.6252,  0.2619,  0.4221,  ...,  0.4455, -0.1455,  0.0696],\n",
      "        ...,\n",
      "        [-0.5976,  0.0810, -0.6952,  ...,  0.8907, -0.1933,  0.4611],\n",
      "        [-0.5939, -0.0065, -0.1329,  ..., -0.3536,  0.2295,  0.5002],\n",
      "        [-0.2794, -0.3673,  0.2052,  ..., -0.0045,  0.6914, -0.0184]])\n",
      "\n",
      "Name: encoder.block.0.layer.1.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.0581, -0.1360, -0.2970,  ..., -0.0372,  0.0385, -0.3046],\n",
      "        [-0.3340,  0.2794,  0.0296,  ..., -0.1826, -0.0951, -0.2911],\n",
      "        [ 0.2561,  0.0131, -0.2029,  ..., -0.7616,  0.0214, -0.3123],\n",
      "        ...,\n",
      "        [-0.1767, -0.3066, -0.1954,  ...,  0.1992,  0.0168, -0.2813],\n",
      "        [-0.0951,  0.0536,  0.1349,  ...,  0.0139, -0.0276,  0.4454],\n",
      "        [ 0.4062,  0.1513,  0.0636,  ..., -0.2187,  0.0996,  0.0544]])\n",
      "\n",
      "Name: encoder.block.0.layer.1.layer_norm.weight\n",
      "Weight: tensor([0.2948, 0.4706, 0.2414, 0.3029, 0.4415, 0.2343, 0.4006, 0.3945, 0.4589,\n",
      "        0.2011, 0.2166, 0.3905, 0.2156, 0.2207, 0.9219, 0.2382, 0.2150, 0.2969,\n",
      "        0.2795, 0.2304, 0.2501, 0.1720, 0.3731, 0.8281, 0.1944, 0.2891, 0.2197,\n",
      "        0.5038, 0.2012, 0.2394, 0.2078, 0.3984, 0.3046, 0.2012, 0.4295, 0.3885,\n",
      "        0.2344, 0.2316, 0.2929, 0.3085, 0.2383, 0.2032, 0.2305, 0.3632, 0.3341,\n",
      "        0.2022, 0.7228, 0.2929, 0.2814, 0.2110, 0.2871, 0.3358, 0.3769, 0.4277,\n",
      "        0.4100, 0.2618, 0.2459, 0.2813, 0.1991, 0.4142, 0.2208, 0.3028, 0.3477,\n",
      "        0.2315, 0.3049, 0.3360, 0.2539, 0.1914, 0.5624, 0.3751, 0.3260, 0.2597,\n",
      "        0.2354, 0.2111, 0.2257, 0.2206, 0.2138, 0.2772, 0.3398, 0.3692, 0.3518,\n",
      "        0.3007, 0.2656, 0.3221, 0.1935, 0.3380, 0.2236, 0.3163, 0.2245, 0.9454,\n",
      "        0.2472, 0.3417, 0.2675, 0.2714, 0.3086, 0.2520, 0.3223, 0.1912, 0.2294,\n",
      "        0.2462, 0.2316, 0.2128, 0.3397, 0.4843, 0.1944, 0.2294, 0.2023, 0.2909,\n",
      "        0.2469, 0.2989, 0.2793, 0.3770, 0.1906, 0.2421, 0.1916, 0.3653, 0.2245,\n",
      "        0.2315, 0.2196, 0.1796, 0.2118, 0.2656, 0.1866, 0.2598, 0.2079, 0.7888,\n",
      "        0.2911, 0.2423, 0.2244, 0.2693, 0.2560, 0.2100, 0.3164, 0.3595, 0.3475,\n",
      "        0.2149, 0.3654, 0.4044, 0.2101, 0.2022, 0.2069, 0.5078, 0.3262, 0.2079,\n",
      "        0.2384, 0.3008, 0.3457, 0.3965, 0.2831, 0.2912, 0.1855, 0.1936, 0.3809,\n",
      "        0.1994, 0.2412, 0.2070, 0.2051, 0.3671, 0.3379, 3.6874, 0.2040, 0.2813,\n",
      "        0.2111, 0.2168, 0.3281, 0.2948, 0.4355, 0.3300, 0.2029, 0.1972, 0.3808,\n",
      "        0.2430, 0.2716, 0.2029, 0.2208, 0.2637, 0.2440, 0.3514, 0.1964, 0.2051,\n",
      "        0.2022, 0.2696, 0.3768, 0.4044, 0.5623, 0.2580, 0.2501, 0.3165, 0.2224,\n",
      "        0.3223, 2.3437, 0.1718, 0.2099, 0.3983, 0.2577, 0.1983, 0.2023, 0.3557,\n",
      "        0.1924, 0.2324, 0.3553, 0.3672, 0.3301, 0.3690, 0.2403, 0.2637, 0.2834,\n",
      "        0.3262, 0.2792, 0.2110, 0.2235, 0.2098, 0.3537, 0.3986, 0.2159, 0.1973,\n",
      "        0.2656, 0.3204, 0.4865, 0.1816, 0.2012, 0.2098, 0.3710, 0.2168, 0.4843,\n",
      "        0.2033, 0.3498, 0.1885, 0.3339, 0.3553, 0.2434, 0.2218, 0.3105, 0.2694,\n",
      "        0.4414, 0.3145, 0.2619, 0.2734, 0.2188, 0.3770, 0.4240, 0.3924, 0.2891,\n",
      "        0.2012, 0.4237, 0.5000, 0.1618, 0.3144, 0.3889, 0.3574, 0.1983, 0.2335,\n",
      "        0.3536, 0.2022, 0.1924, 0.2637, 0.2675, 0.3006, 0.3319, 0.3632, 0.0738,\n",
      "        0.2060, 0.2236, 0.8709, 0.1789, 0.2275, 0.2890, 0.2050, 0.2197, 0.2792,\n",
      "        0.2323, 0.3243, 0.3651, 0.6248, 0.2013, 0.1379, 0.2323, 0.1933, 0.3280,\n",
      "        0.3497, 0.5118, 0.3359, 0.2031, 0.3281, 0.2148, 0.2791, 0.3282, 0.3419,\n",
      "        0.2130, 0.3768, 0.5861, 0.2052, 0.2111, 0.2198, 0.5274, 0.4629, 0.2577,\n",
      "        0.2051, 0.1974, 0.4861, 0.3242, 0.3534, 0.5390, 0.2012, 0.4258, 0.2071,\n",
      "        0.2754, 0.5779, 0.7499, 0.3633, 0.2160, 0.2792, 0.4433, 0.2714, 0.2833,\n",
      "        0.2079, 0.1795, 0.2001, 0.3654, 0.3477, 0.2500, 0.2070, 0.1983, 0.3828,\n",
      "        1.2422, 0.1824, 0.3593, 0.2092, 0.2088, 0.3945, 0.4179, 0.3262, 0.3593,\n",
      "        0.2013, 0.1895, 0.3693, 0.3535, 0.2558, 0.2246, 0.2138, 0.4278, 0.3241,\n",
      "        0.2346, 0.3925, 0.2196, 0.3516, 0.3517, 0.2070, 0.1981, 0.3065, 0.3672,\n",
      "        0.2209, 0.2225, 0.1965, 0.2755, 0.5547, 0.2677, 0.2283, 0.2491, 0.3301,\n",
      "        0.3007, 0.2011, 0.2108, 0.2695, 0.2520, 0.3262, 0.2023, 1.7889, 0.2658,\n",
      "        0.2120, 0.2187, 0.3342, 0.2343, 0.2237, 0.4667, 0.1983, 0.2276, 0.2264,\n",
      "        0.1864, 0.4666, 0.2187, 0.6561, 0.3028, 0.2061, 0.3905, 0.2071, 0.3127,\n",
      "        0.2197, 0.4101, 0.2030, 0.2090, 0.2186, 0.2949, 0.2795, 0.2676, 0.2967,\n",
      "        0.2353, 0.1551, 0.2502, 0.3283, 0.4218, 0.4298, 0.2949, 0.5469, 0.1991,\n",
      "        0.3284, 0.2274, 0.2255, 0.2187, 0.2225, 0.2970, 0.4513, 0.3945, 0.3730,\n",
      "        0.2088, 0.3263, 0.2989, 0.5900, 0.2081, 0.1991, 0.2578, 0.2559, 0.1196,\n",
      "        0.2617, 0.2089, 0.2101, 0.2002, 0.2775, 0.1924, 0.3260, 0.1935, 0.2098,\n",
      "        0.1896, 0.1076, 0.2287, 0.2392, 0.3144, 0.1906, 0.2989, 0.3437, 0.2189,\n",
      "        0.2169, 0.2030, 0.3165, 0.2236, 0.2264, 0.1965, 0.3749, 0.2179, 0.2238,\n",
      "        0.1884, 0.1954, 0.2890, 0.2344, 0.3399, 0.2636, 0.1973, 0.2394, 0.2540,\n",
      "        0.1962, 0.1838, 0.2634, 0.2157, 0.2119, 0.2237, 0.2001, 0.1915, 0.3320,\n",
      "        0.3769, 0.2138, 0.2384, 0.1816, 0.2753, 0.2102, 0.2138, 0.5428, 0.2031,\n",
      "        0.4588, 0.2209, 0.1925, 0.4044, 0.2657, 0.2003, 0.1893, 0.2109, 0.2002,\n",
      "        0.2791, 0.2870, 0.2715, 0.2335, 0.3691, 0.2127, 0.0898, 0.2315, 0.1953,\n",
      "        0.3654, 0.2177, 0.3340, 0.2949, 0.3595, 0.3027, 0.5858, 0.3065, 0.2392,\n",
      "        0.2559, 0.4045, 0.3398, 0.2225, 0.3437, 0.2499, 0.2364, 0.3651])\n",
      "\n",
      "Name: encoder.block.1.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[ 0.0414,  0.0309, -0.0211,  ..., -0.0095,  0.0325, -0.0085],\n",
      "        [-0.0307,  0.0146, -0.0032,  ...,  0.0217, -0.0310,  0.0167],\n",
      "        [-0.0485,  0.0545,  0.0417,  ...,  0.0023,  0.0180, -0.0598],\n",
      "        ...,\n",
      "        [-0.0737,  0.0673,  0.0581,  ..., -0.0088,  0.0761,  0.0069],\n",
      "        [-0.0688,  0.0193,  0.0126,  ...,  0.0608, -0.0464,  0.0551],\n",
      "        [-0.0486, -0.0553, -0.0017,  ...,  0.0459,  0.0098,  0.0674]])\n",
      "\n",
      "Name: encoder.block.1.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 0.3399, -0.4747,  0.0016,  ...,  0.4024, -0.4962,  0.4549],\n",
      "        [-0.2911, -0.3125,  0.4843,  ..., -0.0477,  0.6054,  0.5039],\n",
      "        [-0.0578, -0.3106,  0.0249,  ...,  0.2773, -0.4864, -0.0370],\n",
      "        ...,\n",
      "        [-0.1689, -0.4667,  0.1719,  ..., -0.0840,  0.0190, -0.1378],\n",
      "        [-0.5194,  0.6133, -0.8828,  ...,  0.0055,  0.3477,  0.1427],\n",
      "        [-0.8710,  0.5742,  0.0529,  ..., -0.1601,  0.0938, -0.2812]])\n",
      "\n",
      "Name: encoder.block.1.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[ 0.4628,  0.4588,  0.7657,  ...,  0.0343, -0.6835, -0.0727],\n",
      "        [-0.6406,  0.1681,  0.8398,  ...,  0.1864,  0.3614,  0.1492],\n",
      "        [ 0.4081, -0.8943,  0.3517,  ..., -1.0623,  0.1893,  0.3401],\n",
      "        ...,\n",
      "        [ 0.2791,  0.0365,  0.9260,  ..., -0.4628,  0.2713, -0.3122],\n",
      "        [-0.0996,  0.5119, -0.9571,  ..., -0.3497,  0.2852, -0.1247],\n",
      "        [ 0.1270, -0.2381,  0.2140,  ..., -0.9218, -0.0284, -0.4705]])\n",
      "\n",
      "Name: encoder.block.1.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-1.1117e-01, -5.4515e-02, -1.8431e-01,  ...,  4.6885e-01,\n",
      "         -7.1481e-01, -1.7597e-01],\n",
      "        [ 3.1658e-01, -1.9376e+00,  4.8052e-01,  ...,  5.7027e-01,\n",
      "          1.0158e+00, -1.5528e-01],\n",
      "        [-2.4918e-01,  2.8109e-01, -6.7603e-01,  ..., -4.6487e-01,\n",
      "          1.2423e+00,  2.2861e-05],\n",
      "        ...,\n",
      "        [-4.6309e-01,  2.0676e-02, -4.6117e-01,  ...,  8.5931e-01,\n",
      "          4.6467e-01, -8.5923e-01],\n",
      "        [-7.4611e-01, -1.6197e-01, -3.1041e-01,  ..., -6.1703e-01,\n",
      "          2.6719e-02, -1.3517e+00],\n",
      "        [-1.2969e+00,  1.4533e+00,  2.3086e-03,  ...,  1.4922e+00,\n",
      "          5.7039e-01,  1.4257e-02]])\n",
      "\n",
      "Name: encoder.block.1.layer.0.layer_norm.weight\n",
      "Weight: tensor([0.1116, 0.1435, 0.0944, 0.1097, 0.1601, 0.0895, 0.1366, 0.1424, 0.1241,\n",
      "        0.0879, 0.0897, 0.1067, 0.0830, 0.0939, 0.1594, 0.0943, 0.0863, 0.0977,\n",
      "        0.1058, 0.0942, 0.0999, 0.0679, 0.1309, 0.1767, 0.0802, 0.0994, 0.0944,\n",
      "        0.1330, 0.0863, 0.0403, 0.0869, 0.1281, 0.1131, 0.0844, 0.1292, 0.1278,\n",
      "        0.0980, 0.0941, 0.0747, 0.1139, 0.0942, 0.0839, 0.0675, 0.1279, 0.1131,\n",
      "        0.0838, 0.1824, 0.1090, 0.1053, 0.0889, 0.1123, 0.1156, 0.1280, 0.1145,\n",
      "        0.1187, 0.1067, 0.0996, 0.1003, 0.0826, 0.1306, 0.0903, 0.0463, 0.1436,\n",
      "        0.0942, 0.0916, 0.1206, 0.1056, 0.0824, 0.1631, 0.1290, 0.1307, 0.0942,\n",
      "        0.0972, 0.0913, 0.0929, 0.0944, 0.0869, 0.1082, 0.1173, 0.1129, 0.0970,\n",
      "        0.1002, 0.1033, 0.1268, 0.0820, 0.1157, 0.0827, 0.1000, 0.0915, 0.2180,\n",
      "        0.0979, 0.1279, 0.0966, 0.1022, 0.1152, 0.1076, 0.0977, 0.0801, 0.0663,\n",
      "        0.0913, 0.0977, 0.0819, 0.1278, 0.1218, 0.0786, 0.0945, 0.0829, 0.1072,\n",
      "        0.0463, 0.1069, 0.1124, 0.1267, 0.0827, 0.0908, 0.0844, 0.0621, 0.0955,\n",
      "        0.0969, 0.0856, 0.0739, 0.0882, 0.1020, 0.0848, 0.0902, 0.0892, 0.1779,\n",
      "        0.1131, 0.0927, 0.0595, 0.1069, 0.1010, 0.0849, 0.1026, 0.1092, 0.1090,\n",
      "        0.0913, 0.0438, 0.1020, 0.0781, 0.0776, 0.0868, 0.1661, 0.1095, 0.0845,\n",
      "        0.0928, 0.1153, 0.1139, 0.0977, 0.1139, 0.0510, 0.0784, 0.0828, 0.1248,\n",
      "        0.0818, 0.1026, 0.0774, 0.0795, 0.1226, 0.1183, 0.3614, 0.0834, 0.1078,\n",
      "        0.0893, 0.0925, 0.1193, 0.1075, 0.0635, 0.1209, 0.0816, 0.0781, 0.1358,\n",
      "        0.0986, 0.0975, 0.0862, 0.0909, 0.1050, 0.0853, 0.1175, 0.0794, 0.0882,\n",
      "        0.0828, 0.1051, 0.1360, 0.1407, 0.1259, 0.1070, 0.0970, 0.1161, 0.0909,\n",
      "        0.1182, 0.2560, 0.0392, 0.0936, 0.1260, 0.1004, 0.0866, 0.0825, 0.1144,\n",
      "        0.0851, 0.0924, 0.0968, 0.1280, 0.1165, 0.0411, 0.0962, 0.1011, 0.1241,\n",
      "        0.1289, 0.1045, 0.0899, 0.0916, 0.0868, 0.1098, 0.1238, 0.0843, 0.0800,\n",
      "        0.1165, 0.1187, 0.1396, 0.0747, 0.0849, 0.0837, 0.1338, 0.0917, 0.1229,\n",
      "        0.0811, 0.0992, 0.0742, 0.1246, 0.1140, 0.0946, 0.0844, 0.0841, 0.1003,\n",
      "        0.1339, 0.1187, 0.0951, 0.0846, 0.0885, 0.1209, 0.1251, 0.1245, 0.1105,\n",
      "        0.0875, 0.1194, 0.1385, 0.0426, 0.1031, 0.0769, 0.1270, 0.0770, 0.0863,\n",
      "        0.1190, 0.0829, 0.0775, 0.1000, 0.1053, 0.1112, 0.1028, 0.1261, 0.0381,\n",
      "        0.0835, 0.0898, 0.1799, 0.0388, 0.0929, 0.1083, 0.0815, 0.0779, 0.0951,\n",
      "        0.0936, 0.1198, 0.1222, 0.1777, 0.0785, 0.0622, 0.0930, 0.0793, 0.1095,\n",
      "        0.1189, 0.1377, 0.1163, 0.0901, 0.1199, 0.0896, 0.1093, 0.1224, 0.1386,\n",
      "        0.0814, 0.1269, 0.1394, 0.0892, 0.0885, 0.0897, 0.1317, 0.1513, 0.1085,\n",
      "        0.0887, 0.0863, 0.0835, 0.1229, 0.1287, 0.1288, 0.0909, 0.1174, 0.0815,\n",
      "        0.1026, 0.1554, 0.1690, 0.1166, 0.0956, 0.1052, 0.0736, 0.1055, 0.1068,\n",
      "        0.0861, 0.0768, 0.0773, 0.0921, 0.1215, 0.1012, 0.0820, 0.0805, 0.1076,\n",
      "        0.1981, 0.0761, 0.1261, 0.0848, 0.0895, 0.1072, 0.1086, 0.1143, 0.1329,\n",
      "        0.0884, 0.0835, 0.1223, 0.1176, 0.0979, 0.0906, 0.0750, 0.1240, 0.1174,\n",
      "        0.0999, 0.1299, 0.0875, 0.1177, 0.1277, 0.0834, 0.0779, 0.1161, 0.1300,\n",
      "        0.0977, 0.0838, 0.0838, 0.1030, 0.1623, 0.1014, 0.0964, 0.0987, 0.1167,\n",
      "        0.1124, 0.0832, 0.0886, 0.0952, 0.1020, 0.1190, 0.0830, 0.1737, 0.0986,\n",
      "        0.0910, 0.0970, 0.0844, 0.0808, 0.0934, 0.1227, 0.0872, 0.0875, 0.0874,\n",
      "        0.0765, 0.1234, 0.0966, 0.1437, 0.1181, 0.0943, 0.1262, 0.0929, 0.0961,\n",
      "        0.0912, 0.1407, 0.0833, 0.0859, 0.0880, 0.1063, 0.0999, 0.1014, 0.1174,\n",
      "        0.0821, 0.0291, 0.0972, 0.1112, 0.1318, 0.1139, 0.0977, 0.1495, 0.0763,\n",
      "        0.0832, 0.0959, 0.0854, 0.0890, 0.0868, 0.0780, 0.1130, 0.1387, 0.1357,\n",
      "        0.0910, 0.1112, 0.1181, 0.1580, 0.0907, 0.0797, 0.1065, 0.1121, 0.0299,\n",
      "        0.0997, 0.0553, 0.0900, 0.0840, 0.1097, 0.0820, 0.1248, 0.0829, 0.0872,\n",
      "        0.0763, 0.0294, 0.0879, 0.0926, 0.1143, 0.0785, 0.1063, 0.1297, 0.0877,\n",
      "        0.0899, 0.0850, 0.1093, 0.0954, 0.0931, 0.0800, 0.1301, 0.0894, 0.0967,\n",
      "        0.0745, 0.0795, 0.0928, 0.0568, 0.1239, 0.1056, 0.0785, 0.1083, 0.1011,\n",
      "        0.0846, 0.0746, 0.0713, 0.0868, 0.0878, 0.0892, 0.0807, 0.0736, 0.1191,\n",
      "        0.1253, 0.0863, 0.0989, 0.0785, 0.1064, 0.0890, 0.0967, 0.0970, 0.0844,\n",
      "        0.1101, 0.0888, 0.0848, 0.1396, 0.1069, 0.0809, 0.0769, 0.0874, 0.0844,\n",
      "        0.1123, 0.1151, 0.1090, 0.0975, 0.1174, 0.0822, 0.0324, 0.0890, 0.0835,\n",
      "        0.1216, 0.0883, 0.1088, 0.1153, 0.1224, 0.0817, 0.1630, 0.1214, 0.0963,\n",
      "        0.1070, 0.1196, 0.1124, 0.0886, 0.1259, 0.0896, 0.0864, 0.1012])\n",
      "\n",
      "Name: encoder.block.1.layer.1.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-0.3184,  0.9961,  0.0191,  ..., -0.2012, -0.1444, -0.8047],\n",
      "        [ 0.3144,  0.5937, -0.2891,  ...,  0.8906, -0.3926, -0.8321],\n",
      "        [-0.0433, -0.5743, -0.4610,  ..., -0.3301,  0.9883,  0.9806],\n",
      "        ...,\n",
      "        [ 0.6716,  0.8517,  1.7736,  ..., -1.0547, -0.1827, -0.7381],\n",
      "        [-0.1894,  0.6327,  0.0486,  ...,  0.9218, -0.0743, -0.8673],\n",
      "        [-0.7344, -0.5899, -0.8124,  ..., -0.5781,  0.4785, -0.2205]])\n",
      "\n",
      "Name: encoder.block.1.layer.1.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.0387,  0.1746, -0.0915,  ..., -0.2034, -0.0067, -0.0238],\n",
      "        [-0.2676, -0.0174, -0.1876,  ..., -0.6680, -0.2168, -0.3595],\n",
      "        [-0.0108,  0.5704,  0.6096,  ..., -0.4256, -0.0873, -0.0644],\n",
      "        ...,\n",
      "        [-0.2206,  0.2891, -0.1757,  ...,  0.1169, -0.2909, -0.2889],\n",
      "        [-0.5586, -0.0485, -0.3378,  ...,  0.3593,  0.1865, -0.2655],\n",
      "        [ 0.2969,  0.3338,  0.0128,  ..., -0.2852, -0.0966,  0.1339]])\n",
      "\n",
      "Name: encoder.block.1.layer.1.layer_norm.weight\n",
      "Weight: tensor([0.4395, 0.5234, 0.3572, 0.4063, 0.5626, 0.3652, 0.5197, 0.4648, 0.5040,\n",
      "        0.3241, 0.3457, 0.4277, 0.3322, 0.3399, 0.8358, 0.3516, 0.3380, 0.3769,\n",
      "        0.3967, 0.3692, 0.3671, 0.2852, 0.4982, 0.8516, 0.3223, 0.4238, 0.3653,\n",
      "        0.5821, 0.3380, 0.3418, 0.3379, 0.4707, 0.4414, 0.3299, 0.5157, 0.4881,\n",
      "        0.3693, 0.3633, 0.3437, 0.4471, 0.3576, 0.3242, 0.7029, 0.4530, 0.4239,\n",
      "        0.3339, 0.6682, 0.4239, 0.4296, 0.3653, 0.4317, 0.4628, 0.4901, 0.3947,\n",
      "        0.4239, 0.4042, 0.3671, 0.4024, 0.3183, 0.4863, 0.3478, 0.3086, 0.4549,\n",
      "        0.3516, 0.3984, 0.4670, 0.4316, 0.3045, 0.6837, 0.4746, 0.4473, 0.3731,\n",
      "        0.3730, 0.3302, 0.3653, 0.3808, 0.3146, 0.4103, 0.4453, 0.4160, 0.3867,\n",
      "        0.4668, 0.3885, 0.4473, 0.3068, 0.4706, 0.3381, 0.3594, 0.3535, 0.8791,\n",
      "        0.3788, 0.4472, 0.3868, 0.3906, 0.4394, 0.3846, 0.4140, 0.3123, 0.3477,\n",
      "        0.3673, 0.3808, 0.3339, 0.4376, 0.4998, 0.3106, 0.3593, 0.3184, 0.3926,\n",
      "        0.3184, 0.4101, 0.4161, 0.5353, 0.3202, 0.3827, 0.3164, 0.3634, 0.3670,\n",
      "        0.3673, 0.3653, 0.3026, 0.3319, 0.3770, 0.3125, 0.3691, 0.3204, 0.7149,\n",
      "        0.3478, 0.3573, 0.2948, 0.3847, 0.3985, 0.3398, 0.4396, 0.4318, 0.4686,\n",
      "        0.3319, 0.5158, 0.4241, 0.3243, 0.3496, 0.3339, 0.5390, 0.4025, 0.3204,\n",
      "        0.3808, 0.3829, 0.4708, 0.6795, 0.3631, 0.4397, 0.3202, 0.3105, 0.4552,\n",
      "        0.3147, 0.3691, 0.3514, 0.3126, 0.4668, 0.4921, 1.5704, 0.3126, 0.3008,\n",
      "        0.3515, 0.3751, 0.4279, 0.4278, 0.3966, 0.5155, 0.3241, 0.3087, 0.5118,\n",
      "        0.3788, 0.3887, 0.3279, 0.3379, 0.3830, 0.3457, 0.3965, 0.3242, 0.3282,\n",
      "        0.3280, 0.3946, 0.4863, 0.5080, 0.6716, 0.3945, 0.3731, 0.4217, 0.3497,\n",
      "        0.4357, 1.3282, 0.1766, 0.3498, 0.4866, 0.3789, 0.3320, 0.3261, 0.4415,\n",
      "        0.3067, 0.3670, 0.6525, 0.4395, 0.4258, 0.6095, 0.3790, 0.3925, 0.3887,\n",
      "        0.3514, 0.3946, 0.3339, 0.3339, 0.3478, 0.4298, 0.4764, 0.3419, 0.3262,\n",
      "        0.4024, 0.4139, 0.4940, 0.3066, 0.3126, 0.3164, 0.4904, 0.3555, 0.5234,\n",
      "        0.3359, 0.4120, 0.3087, 0.4453, 0.5897, 0.3634, 0.3340, 0.3556, 0.4005,\n",
      "        0.5000, 0.3965, 0.4569, 0.3592, 0.3516, 0.4530, 0.5116, 0.4648, 0.3926,\n",
      "        0.3282, 0.4707, 0.5002, 0.1980, 0.4472, 0.3791, 0.4531, 0.2970, 0.3731,\n",
      "        0.4552, 0.3398, 0.3104, 0.3924, 0.4081, 0.4296, 0.4745, 0.4706, 0.4003,\n",
      "        0.3125, 0.3556, 0.9688, 0.1876, 0.3671, 0.3984, 0.3281, 0.3301, 0.3826,\n",
      "        0.3593, 0.4140, 0.4336, 0.6680, 0.3340, 0.8397, 0.3731, 0.3028, 0.4160,\n",
      "        0.4629, 0.5194, 0.4354, 0.3184, 0.4532, 0.3359, 0.4160, 0.4590, 0.4217,\n",
      "        0.3143, 0.4453, 0.5546, 0.3302, 0.3302, 0.3339, 0.5077, 0.5117, 0.3945,\n",
      "        0.3358, 0.3341, 0.5235, 0.4237, 0.4787, 0.6367, 0.3221, 0.4708, 0.3281,\n",
      "        0.3691, 0.5234, 0.7929, 0.4784, 0.3399, 0.4004, 0.3847, 0.4004, 0.4180,\n",
      "        0.3280, 0.3066, 0.3143, 0.3791, 0.4531, 0.3790, 0.3203, 0.3105, 0.3982,\n",
      "        1.1406, 0.3104, 0.4823, 0.3203, 0.3260, 0.4179, 0.7381, 0.4259, 0.4609,\n",
      "        0.3184, 0.3086, 0.4532, 0.4610, 0.3828, 0.3574, 0.7186, 0.5078, 0.4415,\n",
      "        0.3636, 0.4394, 0.3300, 0.4298, 0.4689, 0.3145, 0.3281, 0.4334, 0.4453,\n",
      "        0.3651, 0.3497, 0.3007, 0.4198, 0.5782, 0.3946, 0.3691, 0.3634, 0.4102,\n",
      "        0.3907, 0.3280, 0.3359, 0.3848, 0.3809, 0.4395, 0.3182, 0.9061, 0.3886,\n",
      "        0.3302, 0.3438, 0.3693, 0.3065, 0.3594, 0.4844, 0.3281, 0.3359, 0.3534,\n",
      "        0.3162, 0.5977, 0.3456, 0.6094, 0.4277, 0.3340, 0.4882, 0.3341, 0.3554,\n",
      "        0.3378, 0.4922, 0.3222, 0.3241, 0.3515, 0.4102, 0.4200, 0.3985, 0.4041,\n",
      "        0.3162, 0.1516, 0.3769, 0.4006, 0.4882, 0.4921, 0.3927, 0.5390, 0.3126,\n",
      "        0.3457, 0.3555, 0.3418, 0.3614, 0.3534, 0.3690, 0.4940, 0.4863, 0.4240,\n",
      "        0.3241, 0.4120, 0.4122, 0.6367, 0.3495, 0.3203, 0.4198, 0.3927, 0.1379,\n",
      "        0.4045, 0.2071, 0.3262, 0.3300, 0.4178, 0.3164, 0.4376, 0.3320, 0.3396,\n",
      "        0.2909, 0.2482, 0.3457, 0.3534, 0.4355, 0.3008, 0.4295, 0.4921, 0.3302,\n",
      "        0.3614, 0.3419, 0.4256, 0.3535, 0.3513, 0.3223, 0.4511, 0.3419, 0.3594,\n",
      "        0.3009, 0.3087, 0.3632, 0.2227, 0.4648, 0.4101, 0.3027, 0.3711, 0.4061,\n",
      "        0.3300, 0.3048, 0.3084, 0.3458, 0.3319, 0.3498, 0.3144, 0.3125, 0.4629,\n",
      "        0.4803, 0.3321, 0.3575, 0.2969, 0.4042, 0.3342, 0.3672, 0.4902, 0.3380,\n",
      "        0.4940, 0.3262, 0.3146, 0.4491, 0.4102, 0.3319, 0.3165, 0.3418, 0.3242,\n",
      "        0.4220, 0.4101, 0.4179, 0.3436, 0.4805, 0.3222, 0.1447, 0.3516, 0.3067,\n",
      "        0.4414, 0.3710, 0.3964, 0.4374, 0.4647, 0.3690, 0.6290, 0.3947, 0.3790,\n",
      "        0.3750, 0.6955, 0.4003, 0.3457, 0.4513, 0.3789, 0.3400, 0.4256])\n",
      "\n",
      "Name: encoder.block.2.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[ 0.0239,  0.0559,  0.0476,  ..., -0.0022, -0.0513, -0.0341],\n",
      "        [-0.0374,  0.0496,  0.0655,  ..., -0.0640, -0.0800, -0.0463],\n",
      "        [ 0.1407,  0.0220, -0.0470,  ..., -0.0402,  0.0315, -0.0101],\n",
      "        ...,\n",
      "        [ 0.0472,  0.0525, -0.0069,  ...,  0.0066,  0.0348,  0.0273],\n",
      "        [ 0.0644,  0.0722,  0.0567,  ..., -0.0255, -0.0063,  0.0028],\n",
      "        [ 0.0005,  0.0708, -0.0170,  ..., -0.0480,  0.0277,  0.0308]])\n",
      "\n",
      "Name: encoder.block.2.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 3.5548e-01, -1.5701e-02,  5.2359e-01,  ...,  9.9569e-02,\n",
      "          4.7453e-01, -4.9009e-01],\n",
      "        [-2.2950e-01,  7.3053e-01,  3.4186e-01,  ..., -4.1020e-01,\n",
      "          7.8698e-02,  1.4942e-01],\n",
      "        [ 6.7585e-01, -3.7309e-01,  2.2369e-01,  ..., -1.2393e-01,\n",
      "          2.7147e-01,  3.9653e-01],\n",
      "        ...,\n",
      "        [-3.1060e-01,  5.6241e-01,  2.0226e-01,  ...,  4.8244e-01,\n",
      "         -1.5937e-01, -1.7401e-01],\n",
      "        [-1.3495e-01, -6.7278e-04, -2.4416e-01,  ..., -3.6531e-01,\n",
      "          8.8604e-03, -3.2359e-02],\n",
      "        [-1.0216e-01,  4.3945e-01, -2.3542e-01,  ..., -3.6271e-02,\n",
      "          1.0405e-01,  3.2624e-01]])\n",
      "\n",
      "Name: encoder.block.2.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[ 3.0642e-02,  7.3458e-01, -4.3567e-01,  ..., -4.5880e-01,\n",
      "          4.2198e-01, -1.5890e-01],\n",
      "        [-6.3666e-01, -1.3014e-01,  2.0912e-01,  ...,  8.9482e-04,\n",
      "          3.9050e-01,  3.9034e-01],\n",
      "        [-1.6250e+00,  3.4790e-01,  3.9063e-01,  ...,  1.2178e-01,\n",
      "          3.0572e-02, -3.9801e-02],\n",
      "        ...,\n",
      "        [ 6.0134e-01,  8.4789e-01, -7.8906e-01,  ..., -4.0610e-01,\n",
      "         -5.3530e-01, -3.9817e-01],\n",
      "        [ 7.8919e-01, -9.9837e-02,  5.0390e-01,  ...,  1.4933e-01,\n",
      "          5.4691e-01,  2.4095e-01],\n",
      "        [-8.0480e-01,  2.9095e-01, -1.8949e-01,  ...,  3.3785e-01,\n",
      "         -5.8031e-02,  2.4049e-01]])\n",
      "\n",
      "Name: encoder.block.2.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-0.2478, -0.4255,  0.0276,  ...,  0.1073,  0.6838, -0.3811],\n",
      "        [-0.5195, -0.2108,  0.3435,  ..., -0.1005, -0.2431, -0.2121],\n",
      "        [ 0.1238, -0.1749,  0.1641,  ...,  0.1611,  0.2596, -0.5820],\n",
      "        ...,\n",
      "        [ 0.1423,  0.1582,  0.2238,  ..., -0.5311, -1.0860, -0.1922],\n",
      "        [ 0.4025,  0.2479,  0.2000,  ..., -1.2733, -0.0897,  0.3615],\n",
      "        [-1.1327, -0.2890, -1.9062,  ...,  0.2831,  0.8400,  0.7382]])\n",
      "\n",
      "Name: encoder.block.2.layer.0.layer_norm.weight\n",
      "Weight: tensor([0.1542, 0.1877, 0.1369, 0.1357, 0.1876, 0.1347, 0.1808, 0.1711, 0.1681,\n",
      "        0.1223, 0.1170, 0.1515, 0.1219, 0.1360, 0.2259, 0.1317, 0.1216, 0.1016,\n",
      "        0.1456, 0.1356, 0.1367, 0.1013, 0.1678, 0.1971, 0.1170, 0.1346, 0.1416,\n",
      "        0.1712, 0.1212, 0.0521, 0.1165, 0.1631, 0.1428, 0.1199, 0.1689, 0.1649,\n",
      "        0.1454, 0.1405, 0.0883, 0.1553, 0.1307, 0.1233, 0.1057, 0.1584, 0.1398,\n",
      "        0.1143, 0.2141, 0.1541, 0.1515, 0.1269, 0.1533, 0.1523, 0.1650, 0.1446,\n",
      "        0.1407, 0.1414, 0.1320, 0.1516, 0.1208, 0.1604, 0.1282, 0.0466, 0.1770,\n",
      "        0.1278, 0.1252, 0.1652, 0.1494, 0.1272, 0.1994, 0.1575, 0.1565, 0.1326,\n",
      "        0.1385, 0.1269, 0.1336, 0.1301, 0.1282, 0.1414, 0.1622, 0.1339, 0.1250,\n",
      "        0.1214, 0.1387, 0.1525, 0.1203, 0.1583, 0.1200, 0.1319, 0.1309, 0.2390,\n",
      "        0.1368, 0.1707, 0.1349, 0.1446, 0.1484, 0.1427, 0.1457, 0.1187, 0.1015,\n",
      "        0.1282, 0.1357, 0.1272, 0.1690, 0.1619, 0.1155, 0.1396, 0.1165, 0.1446,\n",
      "        0.0612, 0.1426, 0.1533, 0.1521, 0.1162, 0.1301, 0.1188, 0.0575, 0.1447,\n",
      "        0.1388, 0.1252, 0.1046, 0.1291, 0.1346, 0.1200, 0.1329, 0.1227, 0.2146,\n",
      "        0.1504, 0.1300, 0.0749, 0.1388, 0.1511, 0.1301, 0.1195, 0.1355, 0.1429,\n",
      "        0.1247, 0.0489, 0.1257, 0.1175, 0.1232, 0.1252, 0.2011, 0.1247, 0.1129,\n",
      "        0.1379, 0.1395, 0.1379, 0.1245, 0.1504, 0.1023, 0.1243, 0.1098, 0.1534,\n",
      "        0.1218, 0.1416, 0.1203, 0.1178, 0.1613, 0.1575, 0.2989, 0.1226, 0.1247,\n",
      "        0.1228, 0.1318, 0.1492, 0.1457, 0.0935, 0.1702, 0.1214, 0.1129, 0.1661,\n",
      "        0.1360, 0.1349, 0.1183, 0.1289, 0.1300, 0.1193, 0.1466, 0.1194, 0.1328,\n",
      "        0.1243, 0.1438, 0.1692, 0.1775, 0.1613, 0.1399, 0.1368, 0.1501, 0.1288,\n",
      "        0.1477, 0.2639, 0.0623, 0.1310, 0.1677, 0.1428, 0.1157, 0.1130, 0.1330,\n",
      "        0.1159, 0.1426, 0.1194, 0.1680, 0.1515, 0.0430, 0.1406, 0.1389, 0.1513,\n",
      "        0.1611, 0.1358, 0.1349, 0.1290, 0.1309, 0.1405, 0.1584, 0.1217, 0.1223,\n",
      "        0.1506, 0.1423, 0.1581, 0.1118, 0.1083, 0.1246, 0.1649, 0.1331, 0.1670,\n",
      "        0.1199, 0.1389, 0.1160, 0.1477, 0.1349, 0.1327, 0.1272, 0.1110, 0.1378,\n",
      "        0.1643, 0.1477, 0.1200, 0.1189, 0.1350, 0.1503, 0.1661, 0.1614, 0.1482,\n",
      "        0.1227, 0.1670, 0.1600, 0.0657, 0.1321, 0.1033, 0.1565, 0.1150, 0.1319,\n",
      "        0.1394, 0.1192, 0.1135, 0.1365, 0.1404, 0.1483, 0.1425, 0.1523, 0.0417,\n",
      "        0.1155, 0.1318, 0.2146, 0.0481, 0.1299, 0.1417, 0.1244, 0.1100, 0.1311,\n",
      "        0.1340, 0.1609, 0.1561, 0.2159, 0.1141, 0.0934, 0.1340, 0.1179, 0.1407,\n",
      "        0.1688, 0.1739, 0.1552, 0.1238, 0.1620, 0.1252, 0.1504, 0.1563, 0.1621,\n",
      "        0.1261, 0.1553, 0.1751, 0.1268, 0.1211, 0.1301, 0.1865, 0.1828, 0.1399,\n",
      "        0.1245, 0.1248, 0.1005, 0.1437, 0.1797, 0.1690, 0.1271, 0.1536, 0.1272,\n",
      "        0.1388, 0.1865, 0.2215, 0.1524, 0.1338, 0.1487, 0.0753, 0.1484, 0.1466,\n",
      "        0.1160, 0.1208, 0.1174, 0.1198, 0.1580, 0.1417, 0.1182, 0.1178, 0.1337,\n",
      "        0.2542, 0.1186, 0.1593, 0.1226, 0.1262, 0.1388, 0.1350, 0.1472, 0.1700,\n",
      "        0.1183, 0.1154, 0.1504, 0.1434, 0.1427, 0.1319, 0.0992, 0.1574, 0.1533,\n",
      "        0.1349, 0.1711, 0.1232, 0.1533, 0.1536, 0.1187, 0.1125, 0.1434, 0.1661,\n",
      "        0.1346, 0.1271, 0.1224, 0.1513, 0.1903, 0.1308, 0.1328, 0.1298, 0.1525,\n",
      "        0.1379, 0.1162, 0.1250, 0.1245, 0.1376, 0.1624, 0.1188, 0.2014, 0.1377,\n",
      "        0.1281, 0.1299, 0.0897, 0.1064, 0.1261, 0.1681, 0.1191, 0.1238, 0.1237,\n",
      "        0.1140, 0.1633, 0.1339, 0.1804, 0.1523, 0.1235, 0.1594, 0.1250, 0.1310,\n",
      "        0.1279, 0.1661, 0.1226, 0.1245, 0.1259, 0.1406, 0.1475, 0.1378, 0.1574,\n",
      "        0.1175, 0.0520, 0.1328, 0.1280, 0.1708, 0.1415, 0.1290, 0.1828, 0.1139,\n",
      "        0.1086, 0.1340, 0.1232, 0.1297, 0.1320, 0.1061, 0.1311, 0.1613, 0.1691,\n",
      "        0.1218, 0.1306, 0.1501, 0.1912, 0.1340, 0.1190, 0.1425, 0.1409, 0.0548,\n",
      "        0.1319, 0.0719, 0.1281, 0.1238, 0.1515, 0.1223, 0.1612, 0.1173, 0.1292,\n",
      "        0.1087, 0.0335, 0.1228, 0.1328, 0.1581, 0.1121, 0.1477, 0.1594, 0.1195,\n",
      "        0.1290, 0.1246, 0.1495, 0.1360, 0.1307, 0.1245, 0.1551, 0.1271, 0.1418,\n",
      "        0.1062, 0.1193, 0.1356, 0.0685, 0.1643, 0.1418, 0.1122, 0.1365, 0.1370,\n",
      "        0.1196, 0.1195, 0.0960, 0.1244, 0.1221, 0.1291, 0.1159, 0.1079, 0.1592,\n",
      "        0.1702, 0.1210, 0.1297, 0.1188, 0.1444, 0.1317, 0.1298, 0.1374, 0.1245,\n",
      "        0.1505, 0.1280, 0.1181, 0.1750, 0.1427, 0.1240, 0.1153, 0.1217, 0.1242,\n",
      "        0.1563, 0.1483, 0.1457, 0.1298, 0.1350, 0.1223, 0.0383, 0.1300, 0.1133,\n",
      "        0.1532, 0.1224, 0.1328, 0.1561, 0.1624, 0.0941, 0.1946, 0.1484, 0.1317,\n",
      "        0.1427, 0.1428, 0.1311, 0.1239, 0.1633, 0.1347, 0.1201, 0.1419])\n",
      "\n",
      "Name: encoder.block.2.layer.1.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-3.9265e-01,  6.4798e-02, -6.4849e-01,  ...,  3.1645e-01,\n",
      "         -1.4668e-01, -1.1482e+00],\n",
      "        [ 4.4727e-01,  8.5153e-01, -7.0907e-04,  ..., -1.6498e-01,\n",
      "         -7.8131e-01, -8.3962e-02],\n",
      "        [-1.0494e-01,  3.0666e-01,  7.0314e-01,  ...,  2.9693e-01,\n",
      "         -7.9297e-01,  4.0425e-01],\n",
      "        ...,\n",
      "        [ 1.9687e+00,  2.3635e-01,  1.2646e-02,  ...,  1.2188e+00,\n",
      "          2.8517e-01,  9.6482e-01],\n",
      "        [-1.1407e+00, -1.1160e-01,  5.7039e-01,  ...,  1.3594e+00,\n",
      "          9.8433e-01, -9.6466e-01],\n",
      "        [ 1.8361e-01, -5.3906e-01, -4.6289e-01,  ...,  1.8457e-01,\n",
      "          5.0389e-01,  1.0078e+00]])\n",
      "\n",
      "Name: encoder.block.2.layer.1.DenseReluDense.wo.weight\n",
      "Weight: tensor([[ 0.1501,  0.4803, -0.4552,  ...,  0.7185, -0.4592, -0.1279],\n",
      "        [-0.1493,  0.4296,  0.1318,  ...,  0.5312, -0.2833,  0.0231],\n",
      "        [ 0.2141,  0.3166,  0.1465,  ...,  0.2579, -0.0121,  0.0170],\n",
      "        ...,\n",
      "        [-0.2283,  0.0379,  0.5234,  ..., -0.3457,  0.1154,  0.0332],\n",
      "        [-0.1160, -0.4608,  1.0781,  ..., -0.4121, -1.0703,  0.1040],\n",
      "        [ 0.3044,  1.1639,  0.1875,  ...,  0.3359,  0.5779,  0.2813]])\n",
      "\n",
      "Name: encoder.block.2.layer.1.layer_norm.weight\n",
      "Weight: tensor([0.6562, 0.6680, 0.5782, 0.5625, 0.6993, 0.6092, 0.6955, 0.6289, 0.6367,\n",
      "        0.5548, 0.6018, 0.5390, 0.5743, 0.5898, 0.8321, 0.6017, 0.5821, 0.5197,\n",
      "        0.6405, 0.6093, 0.6056, 0.4922, 0.6680, 1.0389, 0.5588, 0.6487, 0.6291,\n",
      "        0.6993, 0.5546, 0.5822, 0.5510, 0.6017, 0.6991, 0.5350, 0.7264, 0.6796,\n",
      "        0.5976, 0.6173, 0.4474, 0.6679, 0.6053, 0.5587, 1.4607, 0.6171, 0.5389,\n",
      "        0.5548, 0.7147, 0.6521, 0.6446, 0.5977, 0.6288, 0.6798, 0.6562, 0.4785,\n",
      "        0.5548, 0.6407, 0.5936, 0.6486, 0.5430, 0.6640, 0.5822, 0.4455, 0.6913,\n",
      "        0.5781, 0.5118, 0.6525, 0.6795, 0.5546, 0.7775, 0.6287, 0.6210, 0.6134,\n",
      "        0.5900, 0.5740, 0.5979, 0.6445, 0.5391, 0.6875, 0.6484, 0.5510, 0.5234,\n",
      "        0.7346, 0.6133, 0.6639, 0.5469, 0.6953, 0.5820, 0.4940, 0.5859, 0.9687,\n",
      "        0.6365, 0.6717, 0.6444, 0.6015, 0.6249, 0.6367, 0.6016, 0.5468, 0.5078,\n",
      "        0.5898, 0.6405, 0.5666, 0.5898, 0.5741, 0.5470, 0.6212, 0.5508, 0.6015,\n",
      "        0.4688, 0.6096, 0.6055, 0.7342, 0.5624, 0.5937, 0.5664, 0.6133, 0.6056,\n",
      "        0.6174, 0.5858, 0.5194, 0.5546, 0.5625, 0.5390, 0.5818, 0.5510, 0.8478,\n",
      "        0.4764, 0.5781, 0.5158, 0.5781, 0.6407, 0.5938, 0.6288, 0.5509, 0.6329,\n",
      "        0.5781, 0.8554, 0.5196, 0.5389, 0.5860, 0.5705, 0.8127, 0.5391, 0.5390,\n",
      "        0.6170, 0.5271, 0.6134, 1.1172, 0.5195, 0.6093, 0.5586, 0.5469, 0.5899,\n",
      "        0.5509, 0.6407, 0.5741, 0.5430, 0.6874, 0.6836, 1.2734, 0.5586, 0.4162,\n",
      "        0.5860, 0.6211, 0.6054, 0.6443, 0.4511, 0.7579, 0.5547, 0.5546, 0.6993,\n",
      "        0.5900, 0.6131, 0.5664, 0.5818, 0.5782, 0.5666, 0.5588, 0.5628, 0.5975,\n",
      "        0.5820, 0.6132, 0.6721, 0.6874, 0.7696, 0.6326, 0.6329, 0.5937, 0.5820,\n",
      "        0.6327, 1.0001, 0.2481, 0.5978, 0.6641, 0.6250, 0.5507, 0.5665, 0.6327,\n",
      "        0.5509, 0.6291, 1.0393, 0.6249, 0.5430, 1.0156, 0.6251, 0.5861, 0.5311,\n",
      "        0.4980, 0.5938, 0.5506, 0.5506, 0.5858, 0.6056, 0.6094, 0.5935, 0.5820,\n",
      "        0.6290, 0.5978, 0.6405, 0.5705, 0.5584, 0.5393, 0.6523, 0.5625, 0.7069,\n",
      "        0.5623, 0.6055, 0.5744, 0.6174, 0.9218, 0.6289, 0.5587, 0.4649, 0.5977,\n",
      "        0.6799, 0.5311, 0.7693, 0.5545, 0.5743, 0.5781, 0.6796, 0.6641, 0.5900,\n",
      "        0.5662, 0.5938, 0.6251, 0.2774, 0.6561, 0.4768, 0.6133, 0.5430, 0.6056,\n",
      "        0.5978, 0.5703, 0.5549, 0.6209, 0.6409, 0.6405, 0.6953, 0.6290, 0.9374,\n",
      "        0.5471, 0.5978, 0.9998, 0.2753, 0.5897, 0.6327, 0.5744, 0.5236, 0.5506,\n",
      "        0.6172, 0.6054, 0.5977, 0.8556, 0.5779, 2.4998, 0.6170, 0.5508, 0.6174,\n",
      "        0.6758, 0.6484, 0.5938, 0.5545, 0.6913, 0.6132, 0.6092, 0.6523, 0.6054,\n",
      "        0.5546, 0.5701, 0.6641, 0.5508, 0.5741, 0.5626, 0.6368, 0.6485, 0.6212,\n",
      "        0.5742, 0.5662, 0.5900, 0.5431, 0.6327, 0.7382, 0.5467, 0.5977, 0.5822,\n",
      "        0.6014, 0.6954, 0.8401, 0.6523, 0.5781, 0.6485, 0.4709, 0.6290, 0.6406,\n",
      "        0.5703, 0.5157, 0.5507, 0.4885, 0.6876, 0.6328, 0.5623, 0.5393, 0.5314,\n",
      "        1.0938, 0.5351, 0.6483, 0.5312, 0.5822, 0.5898, 1.0938, 0.5666, 0.7110,\n",
      "        0.5704, 0.5392, 0.6017, 0.5899, 0.6366, 0.5937, 1.8125, 0.6523, 0.6640,\n",
      "        0.6172, 0.6092, 0.5506, 0.6797, 0.6484, 0.5898, 0.5859, 0.5860, 0.6328,\n",
      "        0.6289, 0.5858, 0.5624, 0.6131, 0.7033, 0.6561, 0.5978, 0.6055, 0.5821,\n",
      "        0.5274, 0.5508, 0.5506, 0.6210, 0.6053, 0.6368, 0.5665, 0.8752, 0.6054,\n",
      "        0.5939, 0.6172, 0.4315, 0.4668, 0.5820, 0.6211, 0.5898, 0.5429, 0.6014,\n",
      "        0.5196, 0.7423, 0.5821, 0.7186, 0.6095, 0.5743, 0.6248, 0.5742, 0.5158,\n",
      "        0.5350, 0.6445, 0.5392, 0.5627, 0.6056, 0.6130, 0.6251, 0.6290, 0.5899,\n",
      "        0.5155, 0.2033, 0.5937, 0.5468, 0.6368, 0.6757, 0.5900, 0.6483, 0.5274,\n",
      "        0.5155, 0.5744, 0.5741, 0.6094, 0.5742, 0.5353, 0.6873, 0.6096, 0.6409,\n",
      "        0.5859, 0.5977, 0.6249, 0.7929, 0.5742, 0.5351, 0.6642, 0.6055, 0.2190,\n",
      "        0.6056, 0.2713, 0.6092, 0.5705, 0.6835, 0.5624, 0.5936, 0.5587, 0.5781,\n",
      "        0.5313, 0.3925, 0.5899, 0.5818, 0.6055, 0.5509, 0.6720, 0.7072, 0.5665,\n",
      "        0.5781, 0.5822, 0.6484, 0.5821, 0.5978, 0.5741, 0.5857, 0.5705, 0.5976,\n",
      "        0.5547, 0.5663, 0.5353, 0.3164, 0.6132, 0.6209, 0.5080, 0.5977, 0.5936,\n",
      "        0.6134, 0.5312, 0.4197, 0.6131, 0.5469, 0.5896, 0.5470, 0.5430, 0.7578,\n",
      "        0.6328, 0.5897, 0.6053, 0.5040, 0.6252, 0.5937, 0.6132, 0.6057, 0.5899,\n",
      "        0.5977, 0.5820, 0.5470, 0.6210, 0.6290, 0.5468, 0.5546, 0.5820, 0.5547,\n",
      "        0.6604, 0.6211, 0.6445, 0.5586, 0.5975, 0.5665, 0.2041, 0.5896, 0.5467,\n",
      "        0.6250, 0.6092, 0.5588, 0.6602, 0.6291, 0.5234, 0.7343, 0.5234, 0.6055,\n",
      "        0.5976, 1.2108, 0.5037, 0.5821, 0.6328, 0.5703, 0.5275, 0.5312])\n",
      "\n",
      "Name: encoder.block.3.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[-0.0044, -0.0547,  0.0604,  ..., -0.0934,  0.0099,  0.0063],\n",
      "        [-0.0162,  0.0778, -0.1123,  ...,  0.1090,  0.0083, -0.1319],\n",
      "        [-0.0313,  0.0030, -0.0675,  ..., -0.0117,  0.0538, -0.0638],\n",
      "        ...,\n",
      "        [-0.0727,  0.0336,  0.0010,  ..., -0.0167, -0.0334,  0.0389],\n",
      "        [-0.0190,  0.0052, -0.0266,  ...,  0.0409, -0.0114, -0.0048],\n",
      "        [ 0.0376, -0.0568, -0.0526,  ..., -0.0538,  0.0617,  0.1533]])\n",
      "\n",
      "Name: encoder.block.3.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 0.0026, -0.1297,  0.5116,  ...,  0.0259, -0.5235,  0.6289],\n",
      "        [-0.8477, -1.0624, -0.8125,  ...,  0.8554,  0.1187,  0.9218],\n",
      "        [-0.5038, -0.0119,  0.1147,  ..., -0.9492, -0.8906, -0.3438],\n",
      "        ...,\n",
      "        [ 0.0217, -0.5548, -0.0747,  ...,  0.2871,  0.0470,  0.7188],\n",
      "        [ 0.8827, -0.1748, -0.8241,  ..., -0.3691,  0.1083, -0.0216],\n",
      "        [-0.1445,  0.0031, -0.4570,  ...,  0.0406,  1.0157, -0.7968]])\n",
      "\n",
      "Name: encoder.block.3.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[-0.3789, -0.5548, -1.0858,  ...,  0.6056, -0.9533,  0.1102],\n",
      "        [ 1.4376,  0.0974,  0.2029,  ..., -0.4883, -0.7577,  0.0720],\n",
      "        [ 0.9841, -0.0822, -0.5234,  ...,  0.1349, -0.2831, -0.6091],\n",
      "        ...,\n",
      "        [ 0.9807, -0.1867,  0.1428,  ...,  0.2421, -0.9881,  0.2634],\n",
      "        [ 0.2853, -0.6094,  0.0727,  ..., -0.2431,  0.8672,  0.5158],\n",
      "        [ 0.6484,  0.2111,  1.0078,  ...,  0.2559,  1.5858, -0.1599]])\n",
      "\n",
      "Name: encoder.block.3.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-0.2653,  1.3516, -0.4040,  ..., -0.1018, -0.7186,  0.0285],\n",
      "        [ 0.2598, -0.3904,  0.7931,  ..., -0.5193, -1.8907,  2.1563],\n",
      "        [-0.1966, -0.0364,  0.0147,  ...,  0.3630, -0.5041, -0.4373],\n",
      "        ...,\n",
      "        [ 0.3084, -0.6716, -0.2473,  ...,  1.3904, -0.0336,  0.5470],\n",
      "        [ 0.3046, -0.1213,  1.8435,  ..., -2.0783,  0.2322,  0.9963],\n",
      "        [-0.2695,  1.9142,  0.2619,  ..., -0.0784,  1.4297,  0.4783]])\n",
      "\n",
      "Name: encoder.block.3.layer.0.layer_norm.weight\n",
      "Weight: tensor([ 0.1307,  0.1477,  0.1270,  0.0991,  0.1591,  0.1250,  0.1540,  0.1386,\n",
      "         0.1204,  0.1208,  0.1199,  0.1078,  0.1161,  0.1281,  0.1523,  0.1174,\n",
      "         0.1228,  0.0925,  0.1355,  0.1271,  0.1427,  0.1012,  0.1308,  0.1326,\n",
      "         0.1137,  0.1300,  0.1287,  0.1311,  0.1159,  0.0584,  0.1165,  0.1122,\n",
      "         0.1156,  0.1121,  0.1448,  0.1366,  0.1327,  0.1290,  0.0691,  0.1271,\n",
      "         0.1286,  0.1143,  0.0950,  0.1195,  0.0984,  0.1159,  0.1345,  0.1376,\n",
      "         0.1384,  0.1270,  0.1366,  0.1148,  0.1438,  0.1077,  0.1083,  0.1311,\n",
      "         0.1309,  0.1453,  0.1156,  0.1271,  0.1248,  0.0454,  0.1541,  0.1289,\n",
      "         0.1130,  0.1374,  0.1380,  0.1121,  0.1502,  0.1335,  0.1257,  0.1249,\n",
      "         0.1213,  0.1159,  0.1267,  0.1224,  0.1238,  0.1300,  0.1541,  0.0911,\n",
      "         0.0916,  0.0993,  0.1345,  0.1378,  0.1121,  0.1359,  0.1242,  0.1047,\n",
      "         0.1173,  0.1546,  0.1316,  0.1375,  0.1214,  0.1301,  0.1221,  0.1370,\n",
      "         0.1199,  0.1097,  0.0958,  0.1116,  0.1243,  0.1209,  0.1311,  0.1184,\n",
      "         0.1140,  0.1296,  0.1198,  0.1248,  0.0565,  0.1178,  0.1336,  0.1096,\n",
      "         0.1096,  0.1258,  0.1161,  0.0529,  0.1320,  0.1296,  0.1184,  0.1106,\n",
      "         0.1213,  0.1262,  0.1137,  0.1145,  0.1194,  0.1506,  0.1182,  0.1336,\n",
      "         0.0836,  0.1282,  0.1310,  0.1205,  0.1091,  0.1088,  0.1205,  0.1164,\n",
      "         0.0468,  0.1081,  0.1108,  0.1110,  0.1120,  0.1663,  0.0979,  0.1121,\n",
      "         0.1298,  0.1262,  0.1198,  0.1009,  0.1317,  0.0950,  0.1165,  0.1099,\n",
      "         0.1151,  0.1131,  0.1376,  0.1135,  0.1140,  0.1367,  0.1417,  0.2011,\n",
      "         0.1135,  0.1102,  0.1172,  0.1292,  0.1260,  0.1261,  0.0867,  0.1495,\n",
      "         0.1097,  0.1127,  0.1377,  0.1306,  0.1280,  0.1137,  0.1184,  0.1223,\n",
      "         0.1193,  0.1242,  0.1171,  0.1214,  0.1155,  0.1288,  0.1267,  0.1418,\n",
      "         0.1272,  0.1365,  0.1339,  0.1208,  0.1206,  0.1331,  0.1864,  0.0508,\n",
      "         0.1228,  0.1477,  0.1297,  0.1132,  0.1106,  0.0998,  0.1134,  0.1320,\n",
      "         0.1001,  0.1260,  0.1147,  0.0402,  0.1278,  0.1249,  0.1318,  0.1292,\n",
      "         0.1166,  0.1227,  0.1232,  0.1213,  0.1059,  0.1296,  0.1179,  0.1108,\n",
      "         0.1359,  0.1262,  0.1112,  0.1156,  0.1139,  0.1170,  0.1299,  0.1140,\n",
      "         0.1396,  0.1130,  0.1257,  0.1078,  0.1223,  0.1053,  0.1306,  0.1154,\n",
      "         0.0865,  0.1258,  0.1179,  0.1105,  0.1037,  0.1012,  0.1172,  0.1127,\n",
      "         0.1345,  0.1326,  0.1321,  0.1146,  0.1300,  0.1167,  0.0603,  0.0979,\n",
      "         0.0847,  0.1238,  0.1104,  0.1193,  0.1179,  0.1115,  0.1067,  0.1262,\n",
      "         0.1329,  0.1348,  0.1252,  0.1259,  0.0360,  0.1111,  0.1247,  0.1584,\n",
      "         0.0433,  0.1306,  0.1230,  0.1094,  0.1092,  0.1163,  0.1221,  0.1396,\n",
      "         0.1218,  0.1799,  0.1101,  0.0824,  0.1252,  0.1087,  0.1288,  0.1385,\n",
      "         0.1376,  0.1238,  0.1103,  0.1365,  0.1209,  0.1270,  0.1318,  0.1438,\n",
      "         0.1130,  0.1168,  0.1326,  0.1188,  0.1172,  0.1245,  0.1229,  0.1356,\n",
      "         0.1179,  0.1194,  0.1163,  0.0857,  0.1150,  0.1408,  0.1165,  0.1151,\n",
      "         0.1193,  0.1159,  0.1214,  0.1395,  0.1475,  0.1214,  0.1286,  0.1385,\n",
      "         0.0706,  0.1232,  0.1395,  0.1174,  0.1062,  0.1082,  0.0960,  0.1404,\n",
      "         0.1350,  0.1091,  0.1110,  0.1081,  0.1770,  0.1093,  0.1269,  0.1165,\n",
      "         0.1262,  0.1126,  0.1177,  0.1124,  0.1375,  0.1166,  0.1155,  0.1189,\n",
      "         0.1187,  0.1326,  0.1248,  0.0887,  0.1271,  0.1331,  0.1326,  0.1300,\n",
      "         0.1270,  0.1417,  0.1243,  0.1130,  0.1068,  0.1100,  0.1249,  0.1270,\n",
      "         0.1192,  0.1096,  0.1318,  0.1358,  0.1309,  0.1282,  0.1209,  0.1165,\n",
      "         0.1116,  0.1178,  0.1170,  0.1272,  0.1335,  0.1370,  0.1135,  0.1413,\n",
      "         0.1349,  0.1174,  0.1310,  0.0720,  0.0984,  0.1191,  0.1282,  0.1165,\n",
      "         0.1225,  0.1179,  0.1087,  0.1346,  0.1262,  0.1397,  0.1355,  0.1244,\n",
      "         0.1271,  0.1233,  0.1116,  0.1219,  0.1249,  0.1111,  0.1184,  0.1193,\n",
      "         0.1316,  0.1289,  0.1271,  0.1280,  0.1059,  0.0483,  0.1204,  0.1150,\n",
      "         0.1251,  0.1237,  0.1204,  0.1247,  0.1024,  0.0925,  0.1230,  0.1179,\n",
      "         0.1258,  0.1194,  0.0828,  0.0964,  0.1296,  0.1486,  0.1162,  0.0848,\n",
      "         0.1270,  0.1446,  0.1246,  0.1121,  0.1329,  0.1199,  0.0502,  0.1262,\n",
      "         0.0607,  0.1203,  0.1169,  0.1318,  0.1139,  0.1262,  0.1197,  0.1204,\n",
      "         0.1106, -0.0330,  0.1262,  0.1287,  0.1253,  0.1112,  0.1394,  0.1213,\n",
      "         0.1174,  0.1220,  0.1184,  0.1245,  0.1298,  0.1218,  0.1099,  0.1184,\n",
      "         0.1223,  0.1299,  0.1005,  0.1098,  0.1179,  0.0582,  0.1356,  0.1247,\n",
      "         0.1087,  0.1279,  0.1209,  0.1118,  0.1082,  0.0710,  0.1223,  0.1199,\n",
      "         0.1223,  0.1072,  0.0992,  0.1521,  0.1413,  0.1270,  0.1302,  0.1089,\n",
      "         0.1355,  0.1238,  0.1240,  0.1071,  0.1191,  0.1116,  0.1271,  0.1170,\n",
      "         0.1296,  0.1365,  0.1106,  0.1153,  0.1157,  0.1216,  0.1444,  0.1408,\n",
      "         0.1414,  0.1248,  0.1107,  0.1140,  0.0339,  0.1247,  0.1147,  0.1162,\n",
      "         0.1198,  0.1101,  0.1444,  0.1287,  0.0772,  0.1542,  0.1184,  0.1248,\n",
      "         0.1286,  0.1155,  0.0980,  0.1223,  0.1317,  0.1242,  0.1090,  0.1035])\n",
      "\n",
      "Name: encoder.block.3.layer.1.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-1.7422,  0.9962,  0.7969,  ...,  0.0371,  0.3829, -0.1367],\n",
      "        [-0.3789,  0.5272,  0.0782,  ...,  0.1866,  0.2519,  0.0751],\n",
      "        [-0.2873, -0.8554,  0.1426,  ...,  0.1564,  0.8983,  0.7108],\n",
      "        ...,\n",
      "        [-1.2422, -0.8594, -1.2188,  ...,  1.2812,  1.6485,  0.5117],\n",
      "        [ 0.8867, -0.3301,  0.7032,  ...,  0.3926, -0.9101,  0.3712],\n",
      "        [ 0.3711, -0.4141,  0.5820,  ...,  0.8007, -0.1299,  0.2393]])\n",
      "\n",
      "Name: encoder.block.3.layer.1.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.9025, -0.6760, -0.0105,  ...,  0.4882, -0.1818, -0.1670],\n",
      "        [ 0.1298, -0.1682,  0.1054,  ..., -0.4239,  0.0458, -0.7539],\n",
      "        [ 0.2218,  0.0228, -0.0230,  ...,  0.3810, -0.2791, -0.5820],\n",
      "        ...,\n",
      "        [-0.2381,  0.1718, -0.2595,  ..., -0.2812, -0.4433, -1.1719],\n",
      "        [ 0.0639, -0.2753, -0.1609,  ...,  1.4297, -0.2734,  0.7969],\n",
      "        [ 0.1532,  0.3260, -0.1476,  ..., -0.1962,  0.0952,  0.3164]])\n",
      "\n",
      "Name: encoder.block.3.layer.1.layer_norm.weight\n",
      "Weight: tensor([0.7540, 0.7148, 0.7851, 0.6563, 0.7657, 0.8362, 0.8166, 0.6720, 0.6717,\n",
      "        0.7344, 0.8006, 0.7267, 0.7459, 0.7616, 0.7539, 0.7693, 0.7695, 0.5467,\n",
      "        0.8125, 0.8046, 0.8243, 0.7030, 0.7695, 0.9962, 0.7774, 0.8710, 0.8435,\n",
      "        0.7304, 0.7500, 0.6838, 0.7030, 0.6406, 0.9532, 0.7459, 0.7497, 0.8517,\n",
      "        0.7618, 0.8007, 0.4511, 0.8790, 0.7814, 0.7539, 1.9999, 0.6525, 0.5900,\n",
      "        0.7541, 0.6834, 0.7774, 0.7772, 0.7890, 0.7811, 0.7030, 0.7266, 0.5039,\n",
      "        0.6290, 0.7971, 0.7581, 0.8008, 0.7461, 0.6446, 0.7346, 0.5703, 0.8283,\n",
      "        0.7577, 0.5351, 0.7226, 0.8674, 0.7382, 0.7578, 0.6174, 0.6330, 0.8084,\n",
      "        0.7734, 0.7693, 0.7541, 0.8201, 0.7538, 0.8008, 0.7734, 0.6093, 0.5662,\n",
      "        0.8748, 0.7892, 0.7618, 0.7190, 0.8087, 0.7929, 0.5389, 0.8438, 0.9060,\n",
      "        0.8633, 0.7853, 0.7773, 0.7813, 0.6992, 0.7890, 0.7109, 0.7732, 0.5858,\n",
      "        0.6874, 0.8045, 0.7810, 0.7304, 0.6405, 0.7617, 0.7540, 0.7264, 0.6914,\n",
      "        0.5158, 0.7108, 0.8008, 0.7190, 0.7618, 0.8516, 0.7735, 0.8163, 0.7382,\n",
      "        0.8164, 0.8283, 0.7111, 0.7735, 0.6912, 0.7384, 0.7538, 0.7148, 0.7891,\n",
      "        0.5549, 0.7735, 0.6409, 0.6834, 0.7774, 0.7538, 0.7265, 0.7303, 0.7578,\n",
      "        0.7888, 1.0624, 0.5350, 0.7343, 0.7971, 0.7775, 1.0310, 0.5235, 0.7306,\n",
      "        0.7733, 0.6365, 0.6994, 1.2345, 0.6173, 0.6756, 0.7655, 0.7422, 0.6874,\n",
      "        0.7306, 0.8086, 0.8010, 0.7228, 0.7852, 0.7811, 1.1565, 0.7655, 0.5432,\n",
      "        0.7501, 0.8010, 0.6525, 0.8046, 0.6368, 0.8789, 0.7696, 0.7579, 0.7813,\n",
      "        0.8010, 0.7932, 0.7421, 0.7380, 0.7070, 0.7540, 0.6562, 0.7540, 0.7615,\n",
      "        0.8088, 0.7499, 0.7616, 0.7459, 0.7306, 0.8084, 0.8631, 0.7538, 0.7854,\n",
      "        0.6913, 0.9451, 0.3240, 0.7852, 0.7501, 0.7775, 0.7853, 0.7264, 0.7344,\n",
      "        0.7226, 0.8475, 1.1330, 0.7030, 0.5549, 1.0939, 0.7735, 0.7267, 0.5740,\n",
      "        0.5744, 0.7304, 0.8046, 0.7110, 0.7892, 0.6991, 0.6443, 0.7773, 0.7775,\n",
      "        0.7341, 0.7187, 0.6447, 0.7694, 0.7304, 0.7424, 0.7228, 0.7342, 0.7189,\n",
      "        0.7578, 0.8088, 0.7616, 0.6643, 0.9416, 0.8399, 0.7385, 0.5276, 0.7150,\n",
      "        0.7969, 0.5743, 1.0080, 0.6523, 0.7537, 0.7502, 0.7342, 0.7772, 0.7190,\n",
      "        0.7813, 0.6798, 0.6718, 0.4474, 0.8283, 0.5859, 0.7226, 0.7619, 0.7305,\n",
      "        0.6639, 0.7734, 0.7737, 0.7228, 0.7304, 0.7461, 0.7694, 0.6913, 1.3984,\n",
      "        0.7578, 0.8088, 0.9456, 0.3513, 0.8204, 0.7226, 0.7656, 0.6641, 0.6446,\n",
      "        0.8242, 0.7148, 0.6955, 0.9881, 0.7383, 4.0938, 0.7735, 0.7892, 0.7735,\n",
      "        0.7695, 0.6954, 0.6991, 0.7576, 0.7773, 0.8086, 0.7537, 0.6990, 0.6600,\n",
      "        0.7304, 0.6173, 0.6993, 0.7734, 0.7385, 0.8124, 0.6562, 0.6914, 0.7070,\n",
      "        0.7659, 0.7424, 0.5744, 0.5859, 0.7149, 0.6951, 0.7618, 0.6721, 0.7932,\n",
      "        0.7462, 0.7073, 0.8398, 0.7851, 0.7268, 0.8046, 0.5744, 0.7890, 0.7304,\n",
      "        0.7775, 0.7187, 0.7382, 0.5624, 0.7461, 0.7655, 0.7776, 0.7383, 0.6053,\n",
      "        1.0076, 0.7226, 0.7146, 0.7148, 0.7967, 0.6447, 1.2815, 0.6366, 0.8439,\n",
      "        0.7459, 0.7345, 0.6017, 0.5897, 0.8596, 0.7733, 2.6405, 0.7461, 0.7381,\n",
      "        0.8087, 0.7147, 0.7694, 0.7930, 0.7110, 0.7850, 0.7580, 0.5665, 0.8947,\n",
      "        0.8478, 0.8087, 0.7305, 0.7307, 0.7969, 0.8162, 0.7890, 0.7736, 0.6406,\n",
      "        0.6328, 0.7307, 0.7307, 0.7618, 0.7343, 0.7773, 0.7659, 0.8201, 0.8087,\n",
      "        0.7654, 0.8049, 0.4395, 0.6056, 0.7695, 0.7305, 0.7580, 0.7381, 0.7732,\n",
      "        0.7264, 0.8243, 0.7693, 0.7577, 0.6990, 0.7540, 0.6953, 0.6952, 0.6132,\n",
      "        0.7226, 0.6838, 0.7577, 0.7579, 0.8281, 0.7576, 0.7812, 0.7772, 0.6756,\n",
      "        0.6560, 0.2658, 0.7421, 0.6525, 0.6836, 0.7228, 0.7697, 0.6560, 0.6993,\n",
      "        0.5349, 0.7578, 0.7774, 0.7693, 0.7812, 0.6369, 0.7225, 0.6760, 0.6838,\n",
      "        0.7928, 0.6053, 0.6912, 0.8906, 0.7578, 0.7149, 0.7970, 0.6916, 0.2874,\n",
      "        0.7811, 0.3378, 0.8165, 0.7772, 0.9024, 0.7421, 0.6799, 0.7659, 0.7889,\n",
      "        0.7421, 0.4959, 0.7538, 0.7812, 0.6914, 0.7228, 0.8323, 0.8829, 0.7616,\n",
      "        0.7615, 0.7772, 0.7069, 0.7501, 0.7734, 0.7658, 0.6291, 0.7892, 0.8124,\n",
      "        0.7307, 0.6913, 0.6603, 0.3828, 0.6836, 0.7577, 0.6798, 0.7420, 0.7655,\n",
      "        0.7967, 0.7771, 0.4961, 0.7538, 0.7460, 0.8162, 0.7344, 0.7381, 0.9299,\n",
      "        0.7774, 0.7812, 0.8006, 0.7150, 0.8322, 0.7888, 0.7850, 0.6484, 0.7734,\n",
      "        0.6327, 0.7420, 0.7618, 0.6835, 0.7267, 0.7342, 0.7813, 0.7851, 0.7070,\n",
      "        0.8088, 0.7773, 0.8282, 0.7381, 0.6369, 0.7889, 0.2263, 0.7737, 0.7539,\n",
      "        0.6485, 0.8124, 0.7187, 0.8048, 0.7267, 0.6954, 0.7224, 0.6174, 0.8049,\n",
      "        0.7423, 1.4689, 0.5549, 0.7382, 0.6915, 0.7382, 0.6328, 0.5782])\n",
      "\n",
      "Name: encoder.block.4.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[ 0.0570, -0.0441,  0.0135,  ...,  0.0111, -0.0079,  0.0101],\n",
      "        [-0.0016, -0.0169,  0.0032,  ..., -0.0398,  0.0020, -0.0993],\n",
      "        [ 0.0208, -0.0294, -0.0153,  ..., -0.0438,  0.0138,  0.0096],\n",
      "        ...,\n",
      "        [ 0.0215,  0.0705, -0.0340,  ...,  0.0634, -0.0217, -0.0440],\n",
      "        [-0.0030,  0.0669,  0.0302,  ...,  0.0171, -0.0058, -0.0209],\n",
      "        [-0.0015,  0.0304,  0.0419,  ..., -0.0428, -0.0435,  0.0054]])\n",
      "\n",
      "Name: encoder.block.4.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[-0.0609,  0.7968,  0.1485,  ..., -0.3008, -0.2558,  0.0298],\n",
      "        [ 0.2274,  0.2756,  0.1854,  ...,  0.1924, -0.3166, -0.1164],\n",
      "        [ 0.0858, -0.0700,  0.1310,  ..., -0.1983, -0.3163, -0.4783],\n",
      "        ...,\n",
      "        [ 0.1194, -0.2754,  0.0268,  ..., -0.7227,  0.1514, -0.1232],\n",
      "        [ 0.4627, -0.2197,  0.0043,  ...,  0.3026, -0.3009, -0.1260],\n",
      "        [ 0.0686, -0.3594,  0.0517,  ..., -0.2189,  0.3849, -0.4959]])\n",
      "\n",
      "Name: encoder.block.4.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[-1.1014, -0.3396,  1.1950,  ..., -1.1016,  0.9063,  1.1018],\n",
      "        [-0.2557,  1.0471, -0.1643,  ..., -0.6289,  0.1604,  0.5432],\n",
      "        [-0.8592,  1.1325,  0.2199,  ...,  1.4529,  1.0470,  0.7615],\n",
      "        ...,\n",
      "        [-1.3359,  0.1604, -0.2034,  ...,  0.0727,  0.7342,  1.7268],\n",
      "        [ 0.9256,  0.4554, -0.4651,  ..., -0.5704, -0.0623,  0.1155],\n",
      "        [-1.2346,  0.0194, -0.3299,  ..., -0.5466, -0.9142, -0.2912]])\n",
      "\n",
      "Name: encoder.block.4.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-0.1696,  0.4235,  0.2145,  ..., -1.4222,  0.1712,  0.3304],\n",
      "        [ 1.4685, -0.3884, -0.4919,  ..., -0.0145, -2.7034, -0.4612],\n",
      "        [ 0.2692,  0.5159, -0.3181,  ...,  0.6565, -0.5159, -0.0633],\n",
      "        ...,\n",
      "        [-0.3870, -0.5466, -1.1247,  ...,  0.1741,  1.7185, -0.0638],\n",
      "        [ 0.8713, -0.2258, -0.1897,  ...,  0.5818, -0.5701, -0.4372],\n",
      "        [-1.8122,  0.0250,  0.7224,  ..., -0.8870, -0.3845, -0.2009]])\n",
      "\n",
      "Name: encoder.block.4.layer.0.layer_norm.weight\n",
      "Weight: tensor([0.1360, 0.1296, 0.1307, 0.0959, 0.1337, 0.1238, 0.1552, 0.1286, 0.1155,\n",
      "        0.1159, 0.1218, 0.1047, 0.1213, 0.1337, 0.1370, 0.1261, 0.1258, 0.0803,\n",
      "        0.1271, 0.1271, 0.1349, 0.1008, 0.1250, 0.1131, 0.1131, 0.1296, 0.1258,\n",
      "        0.1242, 0.1198, 0.0508, 0.1184, 0.1059, 0.1046, 0.1177, 0.1370, 0.1228,\n",
      "        0.1189, 0.1219, 0.0696, 0.1316, 0.1337, 0.1205, 0.0994, 0.1067, 0.0892,\n",
      "        0.1149, 0.1155, 0.1388, 0.1281, 0.1175, 0.1522, 0.1121, 0.1396, 0.0973,\n",
      "        0.1065, 0.1311, 0.1359, 0.1376, 0.1189, 0.1214, 0.1248, 0.0484, 0.1428,\n",
      "        0.1228, 0.1112, 0.1280, 0.1443, 0.1086, 0.1423, 0.1142, 0.1174, 0.1234,\n",
      "        0.1228, 0.1186, 0.1258, 0.1287, 0.1223, 0.1321, 0.1356, 0.0923, 0.0813,\n",
      "        0.1072, 0.1359, 0.1375, 0.1145, 0.1243, 0.1180, 0.0950, 0.1202, 0.1316,\n",
      "        0.1258, 0.1345, 0.1227, 0.1325, 0.1216, 0.1350, 0.1225, 0.1072, 0.0979,\n",
      "        0.1169, 0.1188, 0.1194, 0.1270, 0.1134, 0.1194, 0.1331, 0.1233, 0.1205,\n",
      "        0.0579, 0.1199, 0.1375, 0.1057, 0.1110, 0.1217, 0.1111, 0.0589, 0.1350,\n",
      "        0.1320, 0.1223, 0.1130, 0.1247, 0.1249, 0.1131, 0.1164, 0.1258, 0.1331,\n",
      "        0.1165, 0.1345, 0.0712, 0.1208, 0.1355, 0.1219, 0.1062, 0.1023, 0.1179,\n",
      "        0.1208, 0.0402, 0.1174, 0.1072, 0.1057, 0.1243, 0.1444, 0.0886, 0.1136,\n",
      "        0.1277, 0.1203, 0.1154, 0.0935, 0.1369, 0.0745, 0.1121, 0.1091, 0.1125,\n",
      "        0.1102, 0.1336, 0.1150, 0.1092, 0.1244, 0.1307, 0.1777, 0.1147, 0.1065,\n",
      "        0.1250, 0.1276, 0.1195, 0.1286, 0.0872, 0.1474, 0.1184, 0.1103, 0.1229,\n",
      "        0.1299, 0.1241, 0.1142, 0.1197, 0.1230, 0.1180, 0.1081, 0.1086, 0.1267,\n",
      "        0.1144, 0.1300, 0.1097, 0.1282, 0.1155, 0.1282, 0.1321, 0.1096, 0.1218,\n",
      "        0.1335, 0.1633, 0.0572, 0.1228, 0.1452, 0.1259, 0.1115, 0.1139, 0.0901,\n",
      "        0.1091, 0.1307, 0.0832, 0.1189, 0.0966, 0.0364, 0.1349, 0.1262, 0.1155,\n",
      "        0.1137, 0.1042, 0.1164, 0.1198, 0.1173, 0.1032, 0.1250, 0.1204, 0.1133,\n",
      "        0.1376, 0.1338, 0.1098, 0.1170, 0.1180, 0.1111, 0.1203, 0.1134, 0.1241,\n",
      "        0.1124, 0.1287, 0.1101, 0.1179, 0.1010, 0.1238, 0.1200, 0.0798, 0.1257,\n",
      "        0.1179, 0.1030, 0.0964, 0.1091, 0.1155, 0.1072, 0.1321, 0.1281, 0.1364,\n",
      "        0.1176, 0.1252, 0.1116, 0.0525, 0.0879, 0.0916, 0.1228, 0.1156, 0.1223,\n",
      "        0.1101, 0.1130, 0.1164, 0.1262, 0.1309, 0.1307, 0.1235, 0.1177, 0.0296,\n",
      "        0.1145, 0.1260, 0.0890, 0.0449, 0.1289, 0.1228, 0.1149, 0.1057, 0.1165,\n",
      "        0.1269, 0.1321, 0.1131, 0.1571, 0.1101, 0.0695, 0.1238, 0.1174, 0.1320,\n",
      "        0.1370, 0.1413, 0.1187, 0.1168, 0.1472, 0.1236, 0.1358, 0.1301, 0.1218,\n",
      "        0.1118, 0.1130, 0.1198, 0.1223, 0.1131, 0.1228, 0.1148, 0.1257, 0.1124,\n",
      "        0.1125, 0.1188, 0.0868, 0.1018, 0.1463, 0.1101, 0.1223, 0.1169, 0.1145,\n",
      "        0.1214, 0.1335, 0.1368, 0.1287, 0.1345, 0.1336, 0.0765, 0.1287, 0.1423,\n",
      "        0.1145, 0.1058, 0.1197, 0.1092, 0.1310, 0.1252, 0.1121, 0.1143, 0.0982,\n",
      "        0.1502, 0.1096, 0.1258, 0.1223, 0.1226, 0.1097, 0.1101, 0.1055, 0.1355,\n",
      "        0.1228, 0.1169, 0.1086, 0.1096, 0.1328, 0.1243, 0.0880, 0.1214, 0.1331,\n",
      "        0.1398, 0.1281, 0.1179, 0.1385, 0.1140, 0.1130, 0.1148, 0.1018, 0.1087,\n",
      "        0.1296, 0.1184, 0.1186, 0.1331, 0.1187, 0.1292, 0.1308, 0.1260, 0.1105,\n",
      "        0.1086, 0.1086, 0.1164, 0.1224, 0.1388, 0.1357, 0.1223, 0.1235, 0.1237,\n",
      "        0.1230, 0.1243, 0.0691, 0.1130, 0.1159, 0.1159, 0.1209, 0.1230, 0.1204,\n",
      "        0.1083, 0.1261, 0.1282, 0.1307, 0.1272, 0.1297, 0.1218, 0.1140, 0.1111,\n",
      "        0.1189, 0.1080, 0.1177, 0.1183, 0.1218, 0.1300, 0.1247, 0.1317, 0.1237,\n",
      "        0.1144, 0.0512, 0.1210, 0.0974, 0.1242, 0.1141, 0.1301, 0.1233, 0.1071,\n",
      "        0.0896, 0.1279, 0.1151, 0.1223, 0.1238, 0.0783, 0.0866, 0.1262, 0.1257,\n",
      "        0.1121, 0.0710, 0.1204, 0.1359, 0.1321, 0.1165, 0.1330, 0.1195, 0.0559,\n",
      "        0.1232, 0.0662, 0.1123, 0.1145, 0.1270, 0.1169, 0.1131, 0.1184, 0.1169,\n",
      "        0.1067, 0.0273, 0.1199, 0.1277, 0.1225, 0.1067, 0.1380, 0.1204, 0.1218,\n",
      "        0.1199, 0.1122, 0.1150, 0.1365, 0.1257, 0.1130, 0.1165, 0.1205, 0.1310,\n",
      "        0.1013, 0.1082, 0.1218, 0.0586, 0.1267, 0.1191, 0.1091, 0.1280, 0.1277,\n",
      "        0.1173, 0.1120, 0.0735, 0.1206, 0.1261, 0.1243, 0.1114, 0.1086, 0.1486,\n",
      "        0.1467, 0.1248, 0.1267, 0.1086, 0.1326, 0.1267, 0.1282, 0.1082, 0.1209,\n",
      "        0.1148, 0.1233, 0.1141, 0.1282, 0.1345, 0.1101, 0.1150, 0.1131, 0.1215,\n",
      "        0.1346, 0.1341, 0.1463, 0.1287, 0.0999, 0.1155, 0.0302, 0.1350, 0.1167,\n",
      "        0.1101, 0.1198, 0.1062, 0.1444, 0.1198, 0.0739, 0.1355, 0.1147, 0.1288,\n",
      "        0.1291, 0.1032, 0.0915, 0.1267, 0.1320, 0.1220, 0.1111, 0.0992])\n",
      "\n",
      "Name: encoder.block.4.layer.1.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-0.2675,  0.6367,  0.2559,  ..., -0.5624, -1.3515,  0.1073],\n",
      "        [-0.3437, -0.2832, -0.2070,  ...,  0.0722,  0.2100, -0.2812],\n",
      "        [ 1.2893, -0.3221, -0.9686,  ...,  0.7265, -0.5939,  0.2696],\n",
      "        ...,\n",
      "        [-1.1017,  0.3537, -0.0978,  ..., -0.9530,  0.8594,  0.1108],\n",
      "        [ 0.5507, -0.6641,  0.6053,  ..., -0.3692, -1.0623, -0.3107],\n",
      "        [-0.6172, -0.0981,  1.0079,  ..., -0.4435, -0.5273,  0.5273]])\n",
      "\n",
      "Name: encoder.block.4.layer.1.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.0846, -0.4884,  0.9335,  ...,  0.0711,  0.7224,  0.4353],\n",
      "        [-0.3925, -0.4354, -1.2264,  ..., -0.1248,  0.0677, -0.1454],\n",
      "        [-0.0597, -0.2156, -0.1688,  ..., -0.2069, -0.6247,  0.5705],\n",
      "        ...,\n",
      "        [ 0.4982,  0.3437, -0.2479,  ..., -0.3046,  0.7189,  0.4201],\n",
      "        [ 0.3047,  0.1982,  0.3515,  ..., -0.0791,  0.0128,  0.6015],\n",
      "        [-0.4415,  0.3691, -0.5431,  ...,  0.2158, -0.4944, -0.4980]])\n",
      "\n",
      "Name: encoder.block.4.layer.1.layer_norm.weight\n",
      "Weight: tensor([0.7773, 0.6638, 0.7929, 0.5625, 0.6485, 0.8826, 0.8048, 0.6057, 0.6209,\n",
      "        0.7967, 0.8630, 0.5782, 0.8398, 0.8086, 0.6721, 0.7970, 0.7732, 0.4861,\n",
      "        0.7576, 0.8513, 0.8751, 0.7458, 0.6170, 0.7812, 0.8126, 0.8319, 0.8712,\n",
      "        0.6603, 0.8123, 0.5900, 0.8318, 0.5779, 1.0000, 0.8553, 0.7029, 0.6678,\n",
      "        0.8283, 0.8631, 0.4177, 0.8046, 0.8279, 0.8475, 2.2815, 0.5154, 0.5274,\n",
      "        0.8239, 0.5466, 0.7810, 0.8357, 0.8318, 0.8123, 0.6017, 0.7268, 0.4626,\n",
      "        0.6169, 0.8435, 0.7929, 0.7928, 0.8201, 0.5041, 0.7849, 0.5628, 0.7657,\n",
      "        0.8005, 0.5118, 0.7263, 0.8669, 0.8083, 0.6794, 0.4280, 0.5666, 0.8438,\n",
      "        0.8127, 0.8670, 0.8009, 0.8243, 0.8201, 0.7813, 0.7732, 0.5388, 0.5310,\n",
      "        0.8866, 0.8280, 0.7537, 0.7854, 0.7343, 0.8200, 0.5075, 0.8396, 0.8318,\n",
      "        0.9099, 0.7383, 0.8241, 0.7733, 0.6522, 0.8594, 0.6443, 0.8279, 0.5626,\n",
      "        0.7226, 0.8240, 0.8825, 0.7303, 0.5666, 0.8357, 0.8044, 0.8201, 0.6482,\n",
      "        0.4553, 0.7069, 0.7890, 0.6286, 0.8202, 0.7968, 0.8396, 0.7341, 0.8010,\n",
      "        0.8161, 0.8946, 0.7774, 0.8552, 0.7263, 0.7814, 0.7966, 0.8047, 0.6876,\n",
      "        0.4805, 0.8084, 0.5940, 0.6990, 0.7776, 0.8596, 0.6057, 0.5544, 0.7107,\n",
      "        0.8826, 0.8435, 0.5154, 0.7927, 0.8396, 0.7966, 0.9334, 0.4238, 0.7929,\n",
      "        0.7775, 0.6015, 0.6990, 1.2893, 0.6408, 1.0627, 0.8556, 0.8126, 0.5820,\n",
      "        0.8085, 0.8046, 0.7968, 0.8435, 0.7146, 0.7927, 0.8907, 0.8166, 0.5432,\n",
      "        0.8435, 0.8864, 0.5936, 0.8045, 0.5976, 0.8088, 0.8748, 0.8358, 0.7224,\n",
      "        0.8358, 0.7893, 0.7849, 0.7811, 0.6991, 0.8045, 0.6173, 0.8552, 0.7891,\n",
      "        0.8866, 0.7264, 0.6639, 0.6601, 0.6681, 0.8556, 0.9021, 0.6052, 0.8671,\n",
      "        0.6599, 0.7498, 0.3475, 0.8553, 0.7111, 0.8282, 0.8357, 0.8166, 0.6992,\n",
      "        0.8085, 0.8907, 0.9260, 0.5937, 0.5038, 0.9417, 0.8200, 0.7107, 0.4980,\n",
      "        0.6448, 0.6252, 0.8748, 0.7967, 0.8088, 0.5857, 0.6091, 0.8591, 0.8513,\n",
      "        0.7537, 0.7033, 0.6053, 0.8279, 0.8126, 0.8200, 0.6286, 0.8008, 0.6872,\n",
      "        0.8280, 0.8127, 0.8552, 0.5974, 0.7854, 0.8708, 0.7927, 0.4861, 0.7070,\n",
      "        0.7070, 0.5158, 0.9768, 0.6130, 0.8162, 0.5862, 0.7109, 0.6366, 0.6563,\n",
      "        0.8240, 0.6446, 0.6016, 0.4747, 0.6210, 0.5585, 0.6367, 0.8241, 0.7771,\n",
      "        0.5701, 0.8865, 0.8282, 0.7536, 0.7541, 0.7343, 0.6912, 0.6406, 1.6097,\n",
      "        0.8045, 0.8552, 0.8279, 0.3594, 0.8866, 0.7538, 0.8200, 0.7224, 0.6833,\n",
      "        0.8126, 0.6681, 0.5935, 1.0159, 0.8083, 4.7503, 0.8397, 0.8435, 0.7537,\n",
      "        0.7616, 0.7148, 0.6794, 0.7695, 0.7654, 0.8128, 0.7224, 0.6837, 0.6604,\n",
      "        0.8083, 0.5427, 0.6524, 0.7968, 0.7967, 0.8435, 0.5974, 0.5663, 0.6755,\n",
      "        0.8161, 0.8007, 0.4764, 0.4841, 0.6796, 0.5116, 0.7927, 0.6251, 0.8435,\n",
      "        0.7733, 0.6409, 0.6603, 0.6289, 0.7810, 0.8162, 0.5075, 0.7380, 0.7342,\n",
      "        0.8826, 0.7967, 0.8167, 0.5940, 0.7108, 0.8164, 0.8437, 0.7927, 0.5429,\n",
      "        0.7776, 0.7968, 0.6638, 0.7773, 0.8596, 0.6405, 1.0315, 0.5507, 0.7694,\n",
      "        0.7966, 0.7893, 0.4802, 0.5584, 0.7890, 0.8318, 2.9690, 0.6835, 0.7151,\n",
      "        0.9101, 0.5974, 0.7967, 0.7577, 0.6015, 0.8357, 0.8787, 0.4824, 0.6873,\n",
      "        0.8908, 0.8280, 0.8554, 0.7889, 0.6055, 0.8436, 0.8435, 0.7849, 0.5820,\n",
      "        0.5312, 0.8317, 0.8240, 0.8200, 0.8279, 0.7890, 0.8009, 0.6290, 0.8239,\n",
      "        0.8162, 0.8906, 0.4178, 0.6173, 0.8319, 0.6247, 0.8515, 0.8240, 0.8435,\n",
      "        0.7696, 0.7383, 0.7927, 0.6208, 0.6522, 0.8358, 0.6717, 0.7498, 0.6094,\n",
      "        0.7967, 0.6249, 0.7966, 0.8084, 0.8320, 0.7693, 0.8240, 0.7463, 0.6247,\n",
      "        0.6872, 0.2869, 0.8046, 0.6093, 0.6095, 0.6365, 0.8045, 0.5935, 0.7732,\n",
      "        0.4942, 0.7927, 0.7736, 0.8631, 0.8592, 0.6325, 0.6365, 0.6212, 0.6370,\n",
      "        0.8358, 0.5037, 0.6599, 0.7654, 0.8161, 0.8161, 0.8359, 0.6756, 0.3279,\n",
      "        0.8010, 0.3495, 0.8709, 0.8318, 0.8787, 0.8396, 0.6252, 0.8279, 0.8435,\n",
      "        0.8357, 0.4710, 0.8164, 0.8046, 0.6604, 0.7849, 0.8398, 0.6835, 0.8127,\n",
      "        0.8166, 0.8086, 0.6602, 0.8200, 0.8204, 0.8513, 0.6014, 0.8359, 0.7810,\n",
      "        0.7849, 0.7616, 0.6484, 0.3689, 0.6212, 0.7225, 0.7732, 0.7966, 0.7462,\n",
      "        0.8241, 0.8165, 0.4607, 0.8907, 0.8087, 0.8591, 0.7851, 0.8161, 0.9455,\n",
      "        0.7854, 0.8399, 0.8399, 0.7732, 0.7928, 0.8867, 0.8318, 0.5742, 0.8005,\n",
      "        0.6016, 0.8166, 0.8239, 0.6638, 0.7614, 0.8397, 0.8045, 0.8320, 0.8478,\n",
      "        0.8399, 0.7810, 0.8594, 0.7966, 0.6990, 0.8244, 0.2464, 0.8669, 0.8318,\n",
      "        0.6015, 0.8553, 0.6131, 0.8084, 0.6365, 0.4804, 0.6952, 0.4958, 0.8904,\n",
      "        0.7380, 1.7815, 0.5076, 0.7849, 0.6603, 0.7695, 0.6482, 0.5780])\n",
      "\n",
      "Name: encoder.block.5.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[ 0.0146,  0.0226, -0.0490,  ...,  0.0358, -0.0712, -0.0310],\n",
      "        [-0.0389, -0.0151,  0.0153,  ...,  0.0022, -0.0343, -0.0866],\n",
      "        [ 0.0066, -0.0464,  0.0981,  ...,  0.0048,  0.0204, -0.0514],\n",
      "        ...,\n",
      "        [-0.0027, -0.0428, -0.0503,  ..., -0.0035,  0.1639,  0.0471],\n",
      "        [ 0.0890, -0.0779, -0.0439,  ...,  0.0248,  0.0356, -0.0080],\n",
      "        [ 0.0452, -0.0818, -0.0336,  ...,  0.1278, -0.0326,  0.1121]])\n",
      "\n",
      "Name: encoder.block.5.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[-3.4371e-01,  2.2538e-01,  6.0172e-01,  ..., -6.6960e-02,\n",
      "         -1.8274e-01, -1.8634e-01],\n",
      "        [ 1.0080e+00,  6.0928e-01,  6.2510e-01,  ..., -3.9858e-01,\n",
      "         -6.9510e-01, -3.8656e-01],\n",
      "        [-1.7898e-01, -4.5097e-01,  3.1621e-01,  ..., -1.8344e-01,\n",
      "          8.6303e-01, -6.6927e-04],\n",
      "        ...,\n",
      "        [-1.0989e-01, -2.0530e-01,  2.4408e-01,  ..., -1.3161e-02,\n",
      "         -2.3635e-01,  1.8855e-01],\n",
      "        [-7.1484e-01, -1.2188e+00, -1.5142e-01,  ..., -4.5508e-01,\n",
      "         -2.5199e-01, -7.6580e-01],\n",
      "        [-5.5451e-01, -6.4437e-01,  5.1568e-01,  ..., -1.0849e-01,\n",
      "         -8.0090e-01, -6.2877e-01]])\n",
      "\n",
      "Name: encoder.block.5.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[ 0.4103, -0.4060,  0.7345,  ...,  0.6249,  0.1300, -0.6054],\n",
      "        [-0.1805,  0.3651, -0.0850,  ...,  1.6716,  0.4160, -0.7028],\n",
      "        [ 0.2561,  1.0314, -0.0112,  ..., -0.9651, -0.8162,  0.4924],\n",
      "        ...,\n",
      "        [ 0.8440, -0.4339,  0.9258,  ..., -1.6016,  0.2775,  0.0315],\n",
      "        [ 0.6292, -0.2083,  1.6565,  ...,  0.4280, -0.6210, -1.0394],\n",
      "        [ 0.4509, -0.2829, -0.2913,  ...,  0.7616, -0.9415, -0.3649]])\n",
      "\n",
      "Name: encoder.block.5.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[ 1.6721,  0.6995, -0.3396,  ...,  1.9529,  0.5589, -0.2414],\n",
      "        [-1.3362,  0.6013,  0.0400,  ..., -0.8396, -3.1409, -0.4548],\n",
      "        [-0.1741, -0.2562,  1.1247,  ...,  1.2425,  0.7810,  2.3597],\n",
      "        ...,\n",
      "        [ 0.3826,  0.4392,  0.1501,  ..., -0.9177,  1.5703,  1.5940],\n",
      "        [ 0.3573,  0.8439, -0.1065,  ..., -1.4611,  0.7108, -0.9338],\n",
      "        [-0.0822, -0.4919,  0.3499,  ..., -2.8128, -1.0310, -2.0628]])\n",
      "\n",
      "Name: encoder.block.5.layer.0.layer_norm.weight\n",
      "Weight: tensor([0.1282, 0.1267, 0.1375, 0.0979, 0.1287, 0.1286, 0.1512, 0.1159, 0.1118,\n",
      "        0.1241, 0.1272, 0.1058, 0.1378, 0.1472, 0.1306, 0.1287, 0.1249, 0.0662,\n",
      "        0.1369, 0.1272, 0.1409, 0.1091, 0.1174, 0.1159, 0.1250, 0.1301, 0.1492,\n",
      "        0.1267, 0.1259, 0.0393, 0.1228, 0.1154, 0.1018, 0.1262, 0.1319, 0.1192,\n",
      "        0.1307, 0.1350, 0.0642, 0.1321, 0.1306, 0.1336, 0.0944, 0.0928, 0.0896,\n",
      "        0.1253, 0.1120, 0.1308, 0.1384, 0.1316, 0.1472, 0.1150, 0.1385, 0.0951,\n",
      "        0.1077, 0.1374, 0.1394, 0.1413, 0.1268, 0.0963, 0.1325, 0.0416, 0.1199,\n",
      "        0.1296, 0.1077, 0.1263, 0.1487, 0.1180, 0.1413, 0.0898, 0.1062, 0.1330,\n",
      "        0.1321, 0.1291, 0.1257, 0.1267, 0.1301, 0.1326, 0.1429, 0.0910, 0.0882,\n",
      "        0.0896, 0.1345, 0.1325, 0.1169, 0.1257, 0.1311, 0.0920, 0.1306, 0.1296,\n",
      "        0.1376, 0.1317, 0.1253, 0.1272, 0.1160, 0.1513, 0.1194, 0.1184, 0.1043,\n",
      "        0.1164, 0.1272, 0.1272, 0.1238, 0.1112, 0.1301, 0.1345, 0.1296, 0.1143,\n",
      "        0.0495, 0.1197, 0.1385, 0.0921, 0.1227, 0.1297, 0.1288, 0.0515, 0.1435,\n",
      "        0.1384, 0.1311, 0.1203, 0.1272, 0.1316, 0.1247, 0.1204, 0.1298, 0.1316,\n",
      "        0.0994, 0.1399, 0.0562, 0.1270, 0.1384, 0.1316, 0.1093, 0.1028, 0.1127,\n",
      "        0.1292, 0.0318, 0.1071, 0.1111, 0.1185, 0.1272, 0.1370, 0.0838, 0.1150,\n",
      "        0.1394, 0.1106, 0.1109, 0.0901, 0.1257, 0.0691, 0.1242, 0.1164, 0.1107,\n",
      "        0.1228, 0.1345, 0.1214, 0.1208, 0.1272, 0.1380, 0.1560, 0.1218, 0.1013,\n",
      "        0.1335, 0.1339, 0.1170, 0.1300, 0.0929, 0.1385, 0.1223, 0.1168, 0.1277,\n",
      "        0.1403, 0.1321, 0.1150, 0.1306, 0.1233, 0.1215, 0.1089, 0.1214, 0.1321,\n",
      "        0.1247, 0.1308, 0.1058, 0.1258, 0.1087, 0.1300, 0.1475, 0.1106, 0.1320,\n",
      "        0.1252, 0.1438, 0.0562, 0.1350, 0.1396, 0.1350, 0.1242, 0.1199, 0.0930,\n",
      "        0.1214, 0.1418, 0.0862, 0.1150, 0.0984, 0.0252, 0.1326, 0.1330, 0.1047,\n",
      "        0.1028, 0.1135, 0.1358, 0.1307, 0.1237, 0.1018, 0.1155, 0.1301, 0.1233,\n",
      "        0.1394, 0.1286, 0.1037, 0.1251, 0.1287, 0.1209, 0.1183, 0.1268, 0.1194,\n",
      "        0.1230, 0.1230, 0.1228, 0.1111, 0.1136, 0.1306, 0.1263, 0.0803, 0.1179,\n",
      "        0.1189, 0.0925, 0.0900, 0.1119, 0.1184, 0.1102, 0.1289, 0.1229, 0.1277,\n",
      "        0.1238, 0.1223, 0.1081, 0.0520, 0.0822, 0.0936, 0.1175, 0.1189, 0.1267,\n",
      "        0.1068, 0.1223, 0.1232, 0.1291, 0.1345, 0.1338, 0.1201, 0.1083, 0.0248,\n",
      "        0.1277, 0.1335, 0.0764, 0.0433, 0.1375, 0.1214, 0.1246, 0.1127, 0.1131,\n",
      "        0.1335, 0.1297, 0.1111, 0.1501, 0.1164, 0.0562, 0.1316, 0.1287, 0.1243,\n",
      "        0.1358, 0.1307, 0.1204, 0.1271, 0.1385, 0.1350, 0.1311, 0.1291, 0.1106,\n",
      "        0.1215, 0.1023, 0.1175, 0.1374, 0.1286, 0.1267, 0.1184, 0.1218, 0.1194,\n",
      "        0.1258, 0.1316, 0.0764, 0.0940, 0.1404, 0.0979, 0.1386, 0.1135, 0.1358,\n",
      "        0.1280, 0.1218, 0.1248, 0.1175, 0.1399, 0.1364, 0.0681, 0.1227, 0.1374,\n",
      "        0.1296, 0.1193, 0.1179, 0.1037, 0.1316, 0.1418, 0.1199, 0.1268, 0.0955,\n",
      "        0.1414, 0.1243, 0.1220, 0.1355, 0.1267, 0.1090, 0.1008, 0.0935, 0.1335,\n",
      "        0.1366, 0.1213, 0.1057, 0.1028, 0.1418, 0.1309, 0.0920, 0.1186, 0.1247,\n",
      "        0.1492, 0.1250, 0.1235, 0.1370, 0.1076, 0.1199, 0.1213, 0.0838, 0.1072,\n",
      "        0.1306, 0.1258, 0.1326, 0.1355, 0.1116, 0.1394, 0.1306, 0.1267, 0.1008,\n",
      "        0.1034, 0.1223, 0.1327, 0.1355, 0.1423, 0.1272, 0.1308, 0.1101, 0.1311,\n",
      "        0.1345, 0.1435, 0.0651, 0.1081, 0.1243, 0.1140, 0.1277, 0.1248, 0.1221,\n",
      "        0.1194, 0.1233, 0.1463, 0.1238, 0.1280, 0.1345, 0.1199, 0.1218, 0.1132,\n",
      "        0.1229, 0.1018, 0.1277, 0.1233, 0.1301, 0.1335, 0.1242, 0.1298, 0.1233,\n",
      "        0.1229, 0.0464, 0.1286, 0.0838, 0.1165, 0.1168, 0.1335, 0.1096, 0.1242,\n",
      "        0.0681, 0.1345, 0.1278, 0.1286, 0.1311, 0.0862, 0.0906, 0.1184, 0.0983,\n",
      "        0.1257, 0.0647, 0.1163, 0.1282, 0.1297, 0.1320, 0.1389, 0.1297, 0.0471,\n",
      "        0.1346, 0.0606, 0.1286, 0.1236, 0.1326, 0.1251, 0.1154, 0.1203, 0.1224,\n",
      "        0.1209, 0.0233, 0.1272, 0.1386, 0.1277, 0.1248, 0.1455, 0.1150, 0.1277,\n",
      "        0.1296, 0.1298, 0.1209, 0.1404, 0.1260, 0.1238, 0.1053, 0.1288, 0.1423,\n",
      "        0.1133, 0.1208, 0.1130, 0.0548, 0.1170, 0.1272, 0.1234, 0.1276, 0.1326,\n",
      "        0.1267, 0.1174, 0.0691, 0.1232, 0.1374, 0.1302, 0.1145, 0.1179, 0.1524,\n",
      "        0.1416, 0.1318, 0.1419, 0.1187, 0.1404, 0.1335, 0.1374, 0.1009, 0.1301,\n",
      "        0.1136, 0.1321, 0.1310, 0.1277, 0.1340, 0.1150, 0.1259, 0.1270, 0.1307,\n",
      "        0.1476, 0.1357, 0.1482, 0.1330, 0.0808, 0.1282, 0.0269, 0.1425, 0.1243,\n",
      "        0.1018, 0.1279, 0.1043, 0.1423, 0.1282, 0.0652, 0.1237, 0.0870, 0.1355,\n",
      "        0.1350, 0.0808, 0.0906, 0.1335, 0.1170, 0.1228, 0.1148, 0.1062])\n",
      "\n",
      "Name: encoder.block.5.layer.1.DenseReluDense.wi.weight\n",
      "Weight: tensor([[ 0.1756,  0.6014,  0.5899,  ...,  0.3904, -0.0608,  0.3670],\n",
      "        [ 0.3771,  0.9219,  0.5743,  ..., -1.4062, -0.7421,  1.0624],\n",
      "        [ 0.4608,  0.7497, -0.7028,  ..., -0.5393,  0.2635,  0.9885],\n",
      "        ...,\n",
      "        [-0.5078,  0.1523, -0.0113,  ..., -0.2179,  0.7773,  0.0757],\n",
      "        [ 0.3672, -1.1327,  1.2968,  ..., -1.4765,  1.6328,  1.1249],\n",
      "        [ 0.8242,  0.2197, -0.1103,  ..., -0.9141, -0.2129, -0.2636]])\n",
      "\n",
      "Name: encoder.block.5.layer.1.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.4143, -0.4924,  0.1355,  ...,  0.0211,  0.3104,  0.8672],\n",
      "        [-0.4060,  0.0195,  0.0081,  ..., -0.2244, -1.0858,  0.7774],\n",
      "        [ 0.0848,  0.3342,  0.4065,  ..., -0.1873, -0.5115,  0.3809],\n",
      "        ...,\n",
      "        [ 0.1594, -0.1836,  0.2640,  ..., -0.4179,  0.0459, -0.2735],\n",
      "        [-0.1858,  0.1396, -0.0623,  ..., -0.4453,  0.4688, -0.3281],\n",
      "        [ 0.2556, -1.4064, -0.2913,  ...,  0.1795,  0.1601, -0.7735]])\n",
      "\n",
      "Name: encoder.block.5.layer.1.layer_norm.weight\n",
      "Weight: tensor([ 0.6248,  0.4841,  0.6912,  0.4080,  0.4924,  0.7696,  0.6093,  0.4412,\n",
      "         0.4842,  0.6953,  0.7810,  0.4159,  0.7268,  0.7029,  0.5041,  0.6873,\n",
      "         0.6794,  0.2542,  0.6209,  0.7460,  0.7382,  0.6796,  0.4509,  0.5311,\n",
      "         0.6755,  0.6638,  0.7576,  0.5276,  0.7263,  0.2581,  0.7302,  0.4626,\n",
      "         0.6013,  0.7263,  0.5351,  0.4690,  0.7107,  0.7422,  0.2791,  0.5818,\n",
      "         0.7380,  0.6872,  1.8437,  0.3397,  0.3830,  0.6994,  0.3923,  0.6447,\n",
      "         0.7107,  0.7263,  0.6716,  0.4373,  0.5935,  0.3401,  0.5000,  0.7072,\n",
      "         0.7185,  0.6951,  0.7112,  0.3010,  0.6914,  0.4217,  0.3753,  0.7303,\n",
      "         0.3845,  0.5779,  0.7380,  0.7107,  0.5157,  0.2576,  0.4143,  0.6833,\n",
      "         0.6601,  0.7380,  0.6911,  0.7185,  0.6990,  0.6603,  0.6716,  0.3670,\n",
      "         0.3538,  0.6796,  0.6954,  0.6091,  0.6794,  0.5745,  0.7068,  0.3655,\n",
      "         0.7146,  0.5818,  0.7771,  0.5589,  0.6564,  0.6208,  0.5037,  0.7186,\n",
      "         0.5428,  0.7263,  0.4863,  0.6091,  0.7069,  0.7068,  0.6057,  0.4392,\n",
      "         0.7302,  0.7185,  0.7341,  0.5388,  0.2831,  0.5666,  0.6209,  0.4903,\n",
      "         0.7497,  0.6600,  0.7498,  0.5389,  0.6992,  0.6720,  0.7813,  0.7146,\n",
      "         0.7458,  0.5779,  0.6911,  0.6794,  0.6911,  0.4978,  0.2776,  0.6835,\n",
      "         0.3030,  0.5628,  0.6990,  0.7615,  0.4279,  0.3786,  0.5467,  0.8010,\n",
      "         0.4222,  0.3889,  0.6872,  0.7458,  0.7731,  0.6057,  0.2433,  0.6833,\n",
      "         0.7033,  0.4685,  0.5194,  0.8987,  0.4588,  1.0706,  0.7380,  0.7459,\n",
      "         0.4670,  0.7029,  0.7187,  0.7537,  0.7302,  0.5622,  0.6403,  0.5469,\n",
      "         0.7185,  0.4021,  0.7107,  0.7536,  0.4627,  0.6368,  0.4104,  0.6443,\n",
      "         0.7658,  0.6872,  0.5310,  0.6952,  0.6758,  0.6951,  0.6794,  0.5935,\n",
      "         0.7107,  0.4397,  0.7381,  0.6951,  0.7458,  0.5661,  0.5276,  0.5510,\n",
      "         0.4377,  0.7497,  0.8005,  0.4239,  0.7071,  0.5314,  0.5353,  0.2732,\n",
      "         0.7732,  0.5701,  0.7185,  0.6833,  0.7069,  0.5153,  0.7302,  0.7497,\n",
      "         0.3831,  0.4807,  0.3750,  0.2815,  0.6951,  0.5974,  0.3084,  0.4238,\n",
      "         0.4670,  0.7732,  0.6405,  0.6835,  0.4099,  0.4880,  0.7459,  0.7263,\n",
      "         0.5936,  0.5935,  0.4316,  0.7771,  0.7107,  0.6833,  0.4451,  0.7224,\n",
      "         0.5311,  0.7342,  0.6404,  0.7342,  0.4179,  0.6017,  0.7341,  0.6951,\n",
      "         0.3714,  0.5780,  0.5115,  0.3692,  0.6994,  0.5427,  0.6755,  0.4529,\n",
      "         0.6053,  0.4706,  0.5349,  0.7068,  0.5158,  0.4569,  0.3670,  0.4259,\n",
      "         0.4377,  0.4942,  0.7107,  0.6794,  0.3846,  0.7927,  0.7146,  0.6091,\n",
      "         0.6326,  0.6013,  0.5349,  0.4490,  1.2425,  0.6950,  0.7498,  0.5427,\n",
      "        -0.2390,  0.7693,  0.6052,  0.7225,  0.6445,  0.5818,  0.6873,  0.5349,\n",
      "         0.4358,  0.7893,  0.7146,  3.5470,  0.6837,  0.7380,  0.6638,  0.6640,\n",
      "         0.5427,  0.5037,  0.6835,  0.6326,  0.6915,  0.5782,  0.5466,  0.3811,\n",
      "         0.7344,  0.3690,  0.4509,  0.6993,  0.6794,  0.7458,  0.4528,  0.4319,\n",
      "         0.5700,  0.7146,  0.6872,  0.2947,  0.2966,  0.5078,  0.3123,  0.7302,\n",
      "         0.5433,  0.7263,  0.6641,  0.4690,  0.4627,  0.4690,  0.6560,  0.6916,\n",
      "         0.3108,  0.5935,  0.6052,  0.7577,  0.7344,  0.6990,  0.5037,  0.5702,\n",
      "         0.6990,  0.7539,  0.7185,  0.3577,  0.5505,  0.7185,  0.5430,  0.6681,\n",
      "         0.7146,  0.5118,  0.3128,  0.4314,  0.5273,  0.7109,  0.6834,  0.3259,\n",
      "         0.4103,  0.7072,  0.7615,  2.2190,  0.5193,  0.5626,  0.7422,  0.4900,\n",
      "         0.6912,  0.6013,  0.4139,  0.7185,  0.7617,  0.3225,  0.4490,  0.7771,\n",
      "         0.6796,  0.7029,  0.6599,  0.4373,  0.7502,  0.7107,  0.6911,  0.3867,\n",
      "         0.4003,  0.7345,  0.7224,  0.6993,  0.7188,  0.6247,  0.7341,  0.4528,\n",
      "         0.6872,  0.7068,  0.7419,  0.2991,  0.4841,  0.7147,  0.4685,  0.7185,\n",
      "         0.6799,  0.7229,  0.6833,  0.5350,  0.7185,  0.4822,  0.5232,  0.7263,\n",
      "         0.5276,  0.6679,  0.4920,  0.6678,  0.4490,  0.6795,  0.7146,  0.7536,\n",
      "         0.6683,  0.6599,  0.6209,  0.5154,  0.6169,  0.2440,  0.6993,  0.4103,\n",
      "         0.4571,  0.5544,  0.6874,  0.4373,  0.6873,  0.2620,  0.6443,  0.6639,\n",
      "         0.7226,  0.7497,  0.5583,  0.4065,  0.4768,  0.3573,  0.7463,  0.2868,\n",
      "         0.4846,  0.5700,  0.6912,  0.7263,  0.6716,  0.6096,  0.2541,  0.7224,\n",
      "         0.2597,  0.7538,  0.7342,  0.7380,  0.7029,  0.4666,  0.7419,  0.7380,\n",
      "         0.7380,  0.3050,  0.7341,  0.7029,  0.5702,  0.7107,  0.7263,  0.5036,\n",
      "         0.6874,  0.6993,  0.7072,  0.5546,  0.6990,  0.7068,  0.7342,  0.3475,\n",
      "         0.7500,  0.7033,  0.6833,  0.7305,  0.5427,  0.2810,  0.4841,  0.5700,\n",
      "         0.6755,  0.6364,  0.6523,  0.7186,  0.7227,  0.3397,  0.7497,  0.7107,\n",
      "         0.7499,  0.7263,  0.7146,  0.8122,  0.6599,  0.7263,  0.7500,  0.6717,\n",
      "         0.6483,  0.7502,  0.7302,  0.3792,  0.7653,  0.4375,  0.7149,  0.7419,\n",
      "         0.4744,  0.6092,  0.7575,  0.7341,  0.7186,  0.7185,  0.6992,  0.6365,\n",
      "         0.7501,  0.7461,  0.3849,  0.6911,  0.2278,  0.7458,  0.7111,  0.4570,\n",
      "         0.7732,  0.4280,  0.6755,  0.4940,  0.3166,  0.5271,  0.2656,  0.7619,\n",
      "         0.6443,  1.2344,  0.3439,  0.7111,  0.4922,  0.6680,  0.5588,  0.4432])\n",
      "\n",
      "Name: encoder.final_layer_norm.weight\n",
      "Weight: tensor([0.2405, 0.1888, 0.2892, 0.1458, 0.1971, 0.3244, 0.2403, 0.1678, 0.1819,\n",
      "        0.3128, 0.3322, 0.1503, 0.3240, 0.2951, 0.1848, 0.2813, 0.2987, 0.0911,\n",
      "        0.2474, 0.3067, 0.3128, 0.3147, 0.1731, 0.1634, 0.3165, 0.2561, 0.3323,\n",
      "        0.1965, 0.3302, 0.0344, 0.3128, 0.1761, 0.1809, 0.3220, 0.1902, 0.1906,\n",
      "        0.3087, 0.3201, 0.0828, 0.2444, 0.3068, 0.3206, 0.1843, 0.1370, 0.1409,\n",
      "        0.3165, 0.1663, 0.2522, 0.2833, 0.3342, 0.2639, 0.1907, 0.2394, 0.1350,\n",
      "        0.1575, 0.2909, 0.2952, 0.2815, 0.3202, 0.1356, 0.3126, 0.0612, 0.1299,\n",
      "        0.3108, 0.1511, 0.2210, 0.3069, 0.3245, 0.1956, 0.1208, 0.1497, 0.2933,\n",
      "        0.2990, 0.3206, 0.3050, 0.3064, 0.3084, 0.2502, 0.2616, 0.1409, 0.1370,\n",
      "        0.1419, 0.2952, 0.2347, 0.2990, 0.2239, 0.3123, 0.1253, 0.3245, 0.1956,\n",
      "        0.3304, 0.2179, 0.2575, 0.2659, 0.2044, 0.2909, 0.2102, 0.3225, 0.1878,\n",
      "        0.2454, 0.3084, 0.3245, 0.2236, 0.1761, 0.3299, 0.3030, 0.3069, 0.2053,\n",
      "        0.0604, 0.2049, 0.2414, 0.1378, 0.3342, 0.2717, 0.3263, 0.0786, 0.2854,\n",
      "        0.2932, 0.3440, 0.2991, 0.3338, 0.2442, 0.3186, 0.2540, 0.3128, 0.1787,\n",
      "        0.1355, 0.3010, 0.0686, 0.2363, 0.3011, 0.3303, 0.1601, 0.1419, 0.1858,\n",
      "        0.3440, 0.0567, 0.1494, 0.2933, 0.3499, 0.3362, 0.1787, 0.1048, 0.2890,\n",
      "        0.2815, 0.1706, 0.1926, 0.1644, 0.1711, 0.2131, 0.3401, 0.3264, 0.1746,\n",
      "        0.3105, 0.3049, 0.3030, 0.3381, 0.2063, 0.2556, 0.2229, 0.3399, 0.1228,\n",
      "        0.3377, 0.3323, 0.1800, 0.2581, 0.1194, 0.2659, 0.3460, 0.3108, 0.1917,\n",
      "        0.3103, 0.2790, 0.3206, 0.2891, 0.2305, 0.2970, 0.1438, 0.3339, 0.3050,\n",
      "        0.3396, 0.2415, 0.1643, 0.2160, 0.1487, 0.2796, 0.3128, 0.1702, 0.3088,\n",
      "        0.2019, 0.2111, 0.0696, 0.3167, 0.2210, 0.3006, 0.3206, 0.3202, 0.1370,\n",
      "        0.3259, 0.3167, 0.1331, 0.1942, 0.1502, 0.0322, 0.2796, 0.2581, 0.1349,\n",
      "        0.1253, 0.1691, 0.3323, 0.2952, 0.3029, 0.1565, 0.1848, 0.3300, 0.3223,\n",
      "        0.2542, 0.2112, 0.1634, 0.3304, 0.3206, 0.3202, 0.1770, 0.3089, 0.1878,\n",
      "        0.3262, 0.2229, 0.3342, 0.1575, 0.1941, 0.3089, 0.3108, 0.1180, 0.2239,\n",
      "        0.1853, 0.1341, 0.1530, 0.1995, 0.3128, 0.1736, 0.2287, 0.1786, 0.2171,\n",
      "        0.3145, 0.2005, 0.1546, 0.0684, 0.1253, 0.1399, 0.1835, 0.3161, 0.2756,\n",
      "        0.1556, 0.3299, 0.3223, 0.2380, 0.2600, 0.2473, 0.1995, 0.1673, 0.0383,\n",
      "        0.3341, 0.3225, 0.0950, 0.0462, 0.3420, 0.2405, 0.3205, 0.2737, 0.2061,\n",
      "        0.2948, 0.2132, 0.1657, 0.1960, 0.3206, 0.0461, 0.3010, 0.3186, 0.2522,\n",
      "        0.2482, 0.2180, 0.1897, 0.3030, 0.2307, 0.3147, 0.2355, 0.2110, 0.1296,\n",
      "        0.3225, 0.1399, 0.1780, 0.3067, 0.2952, 0.3260, 0.1868, 0.1799, 0.2197,\n",
      "        0.3265, 0.3362, 0.1046, 0.1321, 0.2151, 0.1331, 0.3300, 0.1882, 0.3397,\n",
      "        0.2599, 0.1877, 0.1835, 0.1697, 0.2891, 0.2737, 0.0886, 0.2595, 0.2698,\n",
      "        0.3421, 0.3362, 0.3205, 0.1595, 0.2210, 0.2947, 0.3298, 0.3127, 0.1199,\n",
      "        0.2053, 0.3439, 0.2132, 0.2834, 0.3225, 0.1878, 0.1374, 0.1585, 0.2112,\n",
      "        0.3147, 0.3225, 0.1409, 0.1535, 0.3010, 0.3127, 0.2009, 0.1839, 0.2219,\n",
      "        0.3259, 0.1927, 0.3045, 0.2294, 0.1624, 0.3183, 0.3263, 0.1159, 0.1659,\n",
      "        0.3557, 0.2952, 0.3361, 0.2854, 0.1545, 0.2988, 0.3128, 0.2972, 0.1582,\n",
      "        0.1487, 0.3245, 0.3302, 0.2615, 0.2815, 0.2277, 0.3206, 0.1673, 0.2874,\n",
      "        0.3146, 0.3420, 0.0774, 0.1917, 0.3147, 0.1726, 0.3265, 0.2951, 0.3166,\n",
      "        0.3050, 0.2021, 0.3108, 0.1868, 0.2034, 0.3145, 0.1877, 0.2874, 0.1975,\n",
      "        0.2972, 0.1565, 0.3225, 0.3166, 0.3186, 0.2464, 0.2678, 0.2463, 0.2054,\n",
      "        0.1995, 0.0540, 0.2790, 0.1194, 0.1770, 0.1927, 0.2794, 0.1639, 0.3206,\n",
      "        0.0955, 0.2717, 0.2952, 0.3205, 0.3108, 0.1546, 0.1321, 0.1833, 0.1262,\n",
      "        0.3181, 0.0860, 0.1888, 0.2161, 0.3226, 0.3302, 0.2581, 0.2468, 0.0525,\n",
      "        0.3050, 0.0721, 0.3360, 0.3279, 0.2581, 0.3186, 0.1798, 0.3284, 0.3147,\n",
      "        0.3304, 0.0341, 0.3048, 0.2932, 0.2072, 0.3145, 0.2854, 0.1678, 0.3005,\n",
      "        0.3147, 0.3107, 0.1991, 0.3010, 0.2851, 0.3263, 0.1341, 0.3203, 0.3126,\n",
      "        0.3008, 0.3108, 0.1917, 0.0779, 0.1857, 0.2372, 0.3147, 0.2620, 0.2522,\n",
      "        0.3128, 0.3205, 0.0960, 0.3226, 0.2933, 0.2991, 0.3108, 0.3127, 0.3343,\n",
      "        0.2483, 0.3089, 0.3242, 0.3185, 0.2600, 0.3378, 0.3147, 0.1370, 0.3069,\n",
      "        0.1751, 0.3184, 0.3298, 0.1819, 0.2430, 0.3167, 0.3264, 0.3186, 0.3323,\n",
      "        0.2913, 0.2522, 0.3065, 0.2972, 0.1204, 0.3220, 0.0317, 0.3224, 0.3167,\n",
      "        0.1604, 0.3206, 0.1552, 0.2713, 0.1895, 0.0878, 0.2005, 0.1155, 0.3323,\n",
      "        0.2581, 0.1593, 0.1248, 0.2971, 0.1936, 0.2717, 0.2169, 0.1604])\n",
      "\n",
      "Name: decoder.embed_tokens.weight\n",
      "Weight: tensor([[ -2.0153,   0.2239,  -7.0940,  ...,  -0.3533,   2.6409,  -2.8909],\n",
      "        [ 12.6247,   8.1872, -11.6247,  ...,   7.9372,  -7.3127,   0.9456],\n",
      "        [ -8.7499,   7.1873,  27.8749,  ..., -26.7501,   0.8555,  -1.5154],\n",
      "        ...,\n",
      "        [-25.2499, -28.4999, -17.2499,  ..., -17.7499,  -5.2500,  27.3749],\n",
      "        [-25.4999, -29.3749, -18.2499,  ..., -17.7499,  -4.8125,  27.7499],\n",
      "        [-26.7499, -28.3749, -17.8749,  ..., -18.4999,  -7.0000,  27.6249]])\n",
      "\n",
      "Name: decoder.block.0.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[-0.0335,  0.0786, -0.0425,  ...,  0.0271, -0.0705, -0.0052],\n",
      "        [-0.0679,  0.0914,  0.0067,  ..., -0.1443,  0.0294,  0.0544],\n",
      "        [ 0.0737,  0.1108, -0.0364,  ...,  0.0187,  0.0062, -0.0543],\n",
      "        ...,\n",
      "        [ 0.0069, -0.0018, -0.0138,  ...,  0.0218, -0.0055, -0.0051],\n",
      "        [ 0.0449, -0.0061, -0.0121,  ...,  0.0139, -0.0174,  0.0881],\n",
      "        [ 0.0141,  0.0746,  0.0249,  ..., -0.0232,  0.0508, -0.0416]])\n",
      "\n",
      "Name: decoder.block.0.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 1.3047, -0.5467, -0.8750,  ..., -0.4374, -1.1952, -0.1854],\n",
      "        [ 0.4041,  1.0313, -0.0257,  ..., -0.6990,  0.0431,  0.4491],\n",
      "        [ 0.1875, -0.6679,  0.0991,  ...,  0.1297,  0.3047,  0.6405],\n",
      "        ...,\n",
      "        [ 0.5742,  1.0545,  0.0640,  ...,  0.3163, -0.1943,  0.3575],\n",
      "        [ 0.4081,  0.5428,  0.3087,  ...,  0.3787,  0.4318, -0.2157],\n",
      "        [-0.2324, -0.1787, -0.0935,  ...,  0.3690, -0.1941,  0.1189]])\n",
      "\n",
      "Name: decoder.block.0.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[ 0.5158,  0.1444, -0.2384,  ..., -0.7576,  0.8005,  0.7932],\n",
      "        [ 0.7771,  0.0988, -0.5275,  ..., -0.1262, -0.3533,  0.3689],\n",
      "        [-0.0135, -0.1853,  0.3923,  ..., -0.8593,  0.1341,  0.1115],\n",
      "        ...,\n",
      "        [-1.2342, -0.1194, -0.4745,  ..., -0.2499, -0.5939, -0.0685],\n",
      "        [ 0.4064, -0.2316, -0.4490,  ...,  0.4665,  0.1458,  0.7653],\n",
      "        [-0.2248, -0.3847, -0.3848,  ..., -0.3987,  0.5276, -0.1209]])\n",
      "\n",
      "Name: decoder.block.0.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[ 0.4880,  0.5706,  0.1657,  ..., -0.0789,  0.4690, -0.1014],\n",
      "        [-0.3415,  0.2034,  0.1419,  ...,  0.2120, -0.1604, -0.4062],\n",
      "        [ 1.2264,  0.7151, -0.0660,  ..., -0.7112,  1.0314,  0.5153],\n",
      "        ...,\n",
      "        [-0.2083,  0.5666, -0.0855,  ..., -0.3479,  0.2796, -0.1751],\n",
      "        [-0.3417,  0.6757, -0.6369,  ...,  0.9573,  0.6678, -0.1286],\n",
      "        [-0.2326,  0.6485,  0.3592,  ...,  0.1495, -1.0237,  0.5862]])\n",
      "\n",
      "Name: decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
      "Weight: tensor([[ 3.5001e+00,  4.5284e-01,  3.1875e+00,  9.7237e-01, -5.4690e+00,\n",
      "          5.1878e+00,  2.1565e+00,  5.3878e-01],\n",
      "        [ 3.9846e+00,  1.2266e+00,  4.3440e+00,  2.0313e+00,  7.9658e-01,\n",
      "          4.9374e+00,  4.7503e+00,  4.5003e+00],\n",
      "        [ 1.4295e+00,  7.2678e-01,  2.9373e+00,  1.5783e+00,  1.0856e+00,\n",
      "          3.2654e+00,  2.2966e+00,  3.5469e+00],\n",
      "        [-2.5978e-01,  2.3755e-01,  2.0310e+00,  1.3127e+00,  1.1638e+00,\n",
      "          2.3122e+00,  1.1872e+00,  2.9373e+00],\n",
      "        [-1.5392e+00, -1.9798e-01,  1.2888e+00,  1.2033e+00,  1.1794e+00,\n",
      "          1.5778e+00,  5.3098e-01,  2.4530e+00],\n",
      "        [-2.6408e+00, -5.5442e-01,  6.2105e-01,  1.0705e+00,  1.1873e+00,\n",
      "          9.5676e-01,  4.8099e-02,  2.0156e+00],\n",
      "        [-3.3752e+00, -9.0988e-01,  1.5516e-01,  9.5723e-01,  1.1482e+00,\n",
      "          5.5051e-01, -1.9556e-01,  1.6405e+00],\n",
      "        [-3.9377e+00, -1.2576e+00, -3.8475e-01,  9.0256e-01,  1.0310e+00,\n",
      "          7.2514e-02, -5.0416e-01,  1.4295e+00],\n",
      "        [-4.3752e+00, -1.5466e+00, -7.6167e-01,  8.1250e-01,  1.0076e+00,\n",
      "         -2.2388e-01, -7.0338e-01,  1.1404e+00],\n",
      "        [-4.7189e+00, -1.7966e+00, -1.1016e+00,  7.5379e-01,  9.6853e-01,\n",
      "         -4.6510e-01, -8.5961e-01,  9.2944e-01],\n",
      "        [-4.9377e+00, -2.0935e+00, -1.3672e+00,  6.6385e-01,  9.0602e-01,\n",
      "         -6.6821e-01, -9.8852e-01,  7.1853e-01],\n",
      "        [-5.2190e+00, -2.3905e+00, -1.6172e+00,  6.0524e-01,  8.6696e-01,\n",
      "         -8.9867e-01, -1.1643e+00,  6.1691e-01],\n",
      "        [-5.3126e+00, -2.6718e+00, -1.8126e+00,  5.7008e-01,  8.0052e-01,\n",
      "         -1.0393e+00, -1.2033e+00,  3.5718e-01],\n",
      "        [-5.4689e+00, -2.9375e+00, -1.9922e+00,  5.3097e-01,  7.4191e-01,\n",
      "         -1.2033e+00, -1.2814e+00,  2.4974e-01],\n",
      "        [-5.6252e+00, -3.1251e+00, -2.1563e+00,  4.8020e-01,  6.9114e-01,\n",
      "         -1.2501e+00, -1.4064e+00,  1.3744e-01],\n",
      "        [-5.6876e+00, -3.3907e+00, -2.3439e+00,  4.4699e-01,  6.4819e-01,\n",
      "         -1.3204e+00, -1.4220e+00, -4.0306e-02],\n",
      "        [-5.8439e+00, -3.8438e+00, -2.5313e+00,  3.3956e-01,  5.4662e-01,\n",
      "         -1.5548e+00, -1.5002e+00, -1.9753e-01],\n",
      "        [-5.9690e+00, -4.3124e+00, -2.8282e+00,  2.7511e-01,  4.1189e-01,\n",
      "         -1.7344e+00, -1.6877e+00, -4.1821e-01],\n",
      "        [-6.0940e+00, -4.6561e+00, -2.9532e+00,  1.9211e-01,  3.0643e-01,\n",
      "         -1.7658e+00, -1.7268e+00, -6.1355e-01],\n",
      "        [-6.1252e+00, -4.9999e+00, -3.1406e+00,  1.3547e-01,  1.3564e-01,\n",
      "         -1.9064e+00, -1.7659e+00, -7.7369e-01],\n",
      "        [-6.2502e+00, -5.3123e+00, -3.3282e+00,  2.3296e-02, -5.1457e-03,\n",
      "         -1.9923e+00, -1.8362e+00, -9.5336e-01],\n",
      "        [-6.2190e+00, -5.4999e+00, -3.3751e+00, -5.0515e-02, -1.4725e-01,\n",
      "         -2.0314e+00, -1.8987e+00, -1.1877e+00],\n",
      "        [-6.2502e+00, -5.7185e+00, -3.4063e+00, -1.6908e-01, -2.9270e-01,\n",
      "         -2.0626e+00, -1.9065e+00, -1.2971e+00],\n",
      "        [-6.2815e+00, -5.9998e+00, -3.5001e+00, -2.5195e-01, -5.0363e-01,\n",
      "         -2.1251e+00, -1.9299e+00, -1.3830e+00],\n",
      "        [-6.2189e+00, -6.2185e+00, -3.5626e+00, -3.9435e-01, -7.2628e-01,\n",
      "         -2.0626e+00, -1.9456e+00, -1.5861e+00],\n",
      "        [-6.1877e+00, -6.3435e+00, -3.5782e+00, -5.0368e-01, -9.2940e-01,\n",
      "         -2.0781e+00, -1.9065e+00, -1.7501e+00],\n",
      "        [-6.1252e+00, -6.3436e+00, -3.5938e+00, -6.4037e-01, -1.2028e+00,\n",
      "         -2.1406e+00, -1.9534e+00, -1.8830e+00],\n",
      "        [-6.0002e+00, -5.9061e+00, -3.5469e+00, -7.8096e-01, -1.4997e+00,\n",
      "         -2.0469e+00, -1.9612e+00, -2.0625e+00],\n",
      "        [-5.8439e+00, -5.0313e+00, -3.4062e+00, -9.7236e-01, -1.8435e+00,\n",
      "         -1.9999e+00, -1.9143e+00, -2.1874e+00],\n",
      "        [-5.6877e+00, -3.6565e+00, -3.2500e+00, -1.1716e+00, -2.1872e+00,\n",
      "         -1.9608e+00, -1.8831e+00, -2.6247e+00],\n",
      "        [-5.5003e+00, -2.6565e+00, -3.0625e+00, -1.3591e+00, -2.3591e+00,\n",
      "         -1.8438e+00, -1.7034e+00, -3.3750e+01],\n",
      "        [ 4.8000e+01,  2.1250e+01,  4.5750e+01, -3.3250e+01,  2.6750e+01,\n",
      "         -3.4500e+01, -3.4000e+01, -3.3250e+01]])\n",
      "\n",
      "Name: decoder.block.0.layer.0.layer_norm.weight\n",
      "Weight: tensor([0.0917, 0.1457, 0.0713, 0.0950, 0.2468, 0.0784, 0.1370, 0.1108, 0.1784,\n",
      "        0.0714, 0.0691, 0.0752, 0.0759, 0.0754, 0.1897, 0.0745, 0.0639, 0.0852,\n",
      "        0.0842, 0.0740, 0.0735, 0.0540, 0.1165, 0.1032, 0.0671, 0.0822, 0.0843,\n",
      "        0.1413, 0.0671, 0.1146, 0.0676, 0.1218, 0.0974, 0.0676, 0.1878, 0.1111,\n",
      "        0.0780, 0.0831, 0.0842, 0.0826, 0.0789, 0.0636, 0.0628, 0.1017, 0.1008,\n",
      "        0.0637, 0.0486, 0.0857, 0.0815, 0.0720, 0.0910, 0.0943, 0.1149, 0.0988,\n",
      "        0.1360, 0.0847, 0.0794, 0.0885, 0.0607, 0.1384, 0.0711, 0.1180, 0.1232,\n",
      "        0.0779, 0.0686, 0.0997, 0.0950, 0.0684, 0.1599, 0.1184, 0.1071, 0.0839,\n",
      "        0.0842, 0.0675, 0.0791, 0.0705, 0.0793, 0.0805, 0.1072, 0.1077, 0.1272,\n",
      "        0.0895, 0.0818, 0.1082, 0.0594, 0.0944, 0.0636, 0.0847, 0.0736, 0.1184,\n",
      "        0.0798, 0.1134, 0.0709, 0.0900, 0.0920, 0.0845, 0.0896, 0.0588, 0.0434,\n",
      "        0.0572, 0.0769, 0.0686, 0.0984, 0.1872, 0.0639, 0.0779, 0.0677, 0.0910,\n",
      "        0.0832, 0.0843, 0.0894, 0.1325, 0.0634, 0.0769, 0.0694, 0.0968, 0.0785,\n",
      "        0.0779, 0.0637, 0.0571, 0.0677, 0.0736, 0.0669, 0.0413, 0.0638, 0.1174,\n",
      "        0.0863, 0.0801, 0.0774, 0.0804, 0.0754, 0.0597, 0.0891, 0.1166, 0.0856,\n",
      "        0.0797, 0.1360, 0.0591, 0.0561, 0.0653, 0.0704, 0.1447, 0.0978, 0.0640,\n",
      "        0.0794, 0.0881, 0.0989, 0.0954, 0.0884, 0.0866, 0.0604, 0.0693, 0.0970,\n",
      "        0.0682, 0.0739, 0.0666, 0.0647, 0.1082, 0.0866, 0.0905, 0.0608, 0.1199,\n",
      "        0.0768, 0.0746, 0.0920, 0.0872, 0.0916, 0.1174, 0.0689, 0.0623, 0.1072,\n",
      "        0.0852, 0.0725, 0.0579, 0.0774, 0.0789, 0.0622, 0.0895, 0.0622, 0.0750,\n",
      "        0.0618, 0.0915, 0.2068, 0.1369, 0.1218, 0.0799, 0.0843, 0.0962, 0.0715,\n",
      "        0.0954, 0.1737, 0.1013, 0.0676, 0.1213, 0.0763, 0.0680, 0.0613, 0.1043,\n",
      "        0.0665, 0.0778, 0.0998, 0.1151, 0.1046, 0.0925, 0.0793, 0.0856, 0.1125,\n",
      "        0.1101, 0.0906, 0.0727, 0.0773, 0.0739, 0.0906, 0.1476, 0.0671, 0.0716,\n",
      "        0.0926, 0.0940, 0.1462, 0.0629, 0.0663, 0.0652, 0.1072, 0.0744, 0.1337,\n",
      "        0.0652, 0.1032, 0.0609, 0.1037, 0.0984, 0.0823, 0.0657, 0.0813, 0.0774,\n",
      "        0.1203, 0.1057, 0.0921, 0.0690, 0.0615, 0.0960, 0.1199, 0.1231, 0.0852,\n",
      "        0.0688, 0.1999, 0.1296, 0.1247, 0.1106, 0.0686, 0.1023, 0.0629, 0.0684,\n",
      "        0.0954, 0.0656, 0.0638, 0.0754, 0.0935, 0.0789, 0.1004, 0.1057, 0.0833,\n",
      "        0.0658, 0.0666, 0.1813, 0.0930, 0.0730, 0.0872, 0.0661, 0.0517, 0.0601,\n",
      "        0.0764, 0.1064, 0.1087, 0.1057, 0.0652, 0.1138, 0.0706, 0.0690, 0.1087,\n",
      "        0.0994, 0.1413, 0.0945, 0.0739, 0.1024, 0.0729, 0.0862, 0.0988, 0.1101,\n",
      "        0.0641, 0.1169, 0.1374, 0.0684, 0.0715, 0.0683, 0.1307, 0.1290, 0.0861,\n",
      "        0.0707, 0.0696, 0.1159, 0.1028, 0.1053, 0.1590, 0.0667, 0.1069, 0.0686,\n",
      "        0.0799, 0.1438, 0.1829, 0.0979, 0.0780, 0.0886, 0.0764, 0.0861, 0.0922,\n",
      "        0.0671, 0.0603, 0.0607, 0.0803, 0.1169, 0.0769, 0.0690, 0.0624, 0.1419,\n",
      "        0.1403, 0.0641, 0.1121, 0.0667, 0.0735, 0.1487, 0.1218, 0.1022, 0.1120,\n",
      "        0.0709, 0.0675, 0.1031, 0.0940, 0.0813, 0.0712, 0.1057, 0.1217, 0.0879,\n",
      "        0.0857, 0.1345, 0.0709, 0.1092, 0.1028, 0.0628, 0.0542, 0.1023, 0.1184,\n",
      "        0.0759, 0.0667, 0.0657, 0.0793, 0.0978, 0.0726, 0.0746, 0.0827, 0.0935,\n",
      "        0.0916, 0.0624, 0.0693, 0.0685, 0.0779, 0.1047, 0.0669, 0.1219, 0.0876,\n",
      "        0.0690, 0.0821, 0.0980, 0.0912, 0.0706, 0.1018, 0.0681, 0.0691, 0.0678,\n",
      "        0.0603, 0.1423, 0.0780, 0.1081, 0.0942, 0.0701, 0.1030, 0.0701, 0.1008,\n",
      "        0.0722, 0.0994, 0.0667, 0.0720, 0.0775, 0.0425, 0.0798, 0.0711, 0.0828,\n",
      "        0.0607, 0.1032, 0.0813, 0.1035, 0.1213, 0.1311, 0.0739, 0.4763, 0.0633,\n",
      "        0.0610, 0.0792, 0.0664, 0.0693, 0.0706, 0.0895, 0.1199, 0.1198, 0.1028,\n",
      "        0.0695, 0.1052, 0.0962, 0.1365, 0.0780, 0.0685, 0.0852, 0.0828, 0.0739,\n",
      "        0.0697, 0.1164, 0.0731, 0.0706, 0.0914, 0.0638, 0.1196, 0.0646, 0.0696,\n",
      "        0.0537, 0.1149, 0.0714, 0.0737, 0.0852, 0.0598, 0.0935, 0.1087, 0.0710,\n",
      "        0.0763, 0.0667, 0.0863, 0.0839, 0.0763, 0.0633, 0.1170, 0.0758, 0.0750,\n",
      "        0.0552, 0.0667, 0.0540, 0.1136, 0.1062, 0.0789, 0.0647, 0.0789, 0.0781,\n",
      "        0.0689, 0.0633, 0.0662, 0.0688, 0.0637, 0.0772, 0.0595, 0.0574, 0.0562,\n",
      "        0.1370, 0.0696, 0.0728, 0.0621, 0.0847, 0.0739, 0.0783, 0.0754, 0.0665,\n",
      "        0.1462, 0.0777, 0.0389, 0.1248, 0.0871, 0.0592, 0.0647, 0.0720, 0.0676,\n",
      "        0.0954, 0.0825, 0.0886, 0.0764, 0.1570, 0.0676, 0.0842, 0.0740, 0.0708,\n",
      "        0.1088, 0.0691, 0.0750, 0.0872, 0.1140, 0.0882, 0.1130, 0.0930, 0.0818,\n",
      "        0.0852, 0.1258, 0.1253, 0.0657, 0.1200, 0.0712, 0.0921, 0.1198])\n",
      "\n",
      "Name: decoder.block.0.layer.1.EncDecAttention.q.weight\n",
      "Weight: tensor([[-0.0593,  0.0425,  0.0591,  ..., -0.0371, -0.0286, -0.0471],\n",
      "        [ 0.0685,  0.0105, -0.0259,  ...,  0.0318,  0.0541, -0.0275],\n",
      "        [-0.1213,  0.0080, -0.0785,  ...,  0.1814,  0.0114, -0.0180],\n",
      "        ...,\n",
      "        [ 0.0748,  0.0126,  0.1115,  ..., -0.0227, -0.0261, -0.0110],\n",
      "        [ 0.0634, -0.0376,  0.0463,  ...,  0.0586,  0.0329, -0.0459],\n",
      "        [-0.0323, -0.0691, -0.0555,  ...,  0.0285, -0.0416,  0.0138]])\n",
      "\n",
      "Name: decoder.block.0.layer.1.EncDecAttention.k.weight\n",
      "Weight: tensor([[ 0.0839, -0.0063, -0.0547,  ..., -0.2275, -0.3299,  0.1291],\n",
      "        [ 0.7341,  0.0842, -0.1643,  ...,  0.1594, -0.1765, -0.1350],\n",
      "        [-0.8245,  0.0155, -0.3458,  ...,  0.1619, -0.4333,  0.0681],\n",
      "        ...,\n",
      "        [-0.1043,  0.2474, -0.3167,  ..., -0.3338, -0.2835,  0.6247],\n",
      "        [-0.1501,  0.0090,  0.6135,  ..., -0.6994,  0.5506,  0.5042],\n",
      "        [-0.1936,  0.5740,  0.5469,  ..., -0.1447, -0.3986, -0.8243]])\n",
      "\n",
      "Name: decoder.block.0.layer.1.EncDecAttention.v.weight\n",
      "Weight: tensor([[-0.2146,  0.1697,  0.5353,  ..., -0.3300,  0.6408,  0.2503],\n",
      "        [ 0.4631,  0.8162, -0.1028,  ...,  0.5781, -0.9021,  0.1643],\n",
      "        [ 0.8474,  1.0467, -0.0464,  ..., -0.8553,  0.4628,  0.0327],\n",
      "        ...,\n",
      "        [-0.6560, -0.8044, -0.1672,  ...,  0.1622,  0.2454,  0.1048],\n",
      "        [ 0.0439, -0.4710,  0.1059,  ..., -0.1360,  0.2971,  0.1386],\n",
      "        [ 0.0847,  0.4001, -0.1541,  ..., -0.2832,  0.1277,  0.6950]])\n",
      "\n",
      "Name: decoder.block.0.layer.1.EncDecAttention.o.weight\n",
      "Weight: tensor([[-0.0280, -0.4651, -0.1657,  ...,  0.1923, -0.0019,  0.1554],\n",
      "        [-0.0681, -0.6878, -0.8084,  ..., -0.2835,  0.3264, -0.2615],\n",
      "        [ 0.6794, -0.1770,  1.2735,  ..., -0.7341,  1.2736,  0.3944],\n",
      "        ...,\n",
      "        [-0.0950, -0.2972, -0.0720,  ..., -0.3968,  0.0155,  0.6524],\n",
      "        [ 0.5198,  0.8128,  1.0153,  ...,  0.3322,  0.9997, -0.5158],\n",
      "        [-0.8049, -0.2693, -0.3616,  ..., -0.0896,  0.2293,  0.2850]])\n",
      "\n",
      "Name: decoder.block.0.layer.1.layer_norm.weight\n",
      "Weight: tensor([0.0870, 0.1823, 0.0802, 0.0828, 0.0317, 0.0828, 0.1248, 0.0739, 0.0589,\n",
      "        0.0774, 0.0828, 0.0386, 0.0764, 0.0793, 0.6995, 0.0735, 0.0769, 0.0789,\n",
      "        0.0820, 0.0789, 0.0891, 0.0685, 0.1214, 0.0282, 0.0796, 0.0821, 0.0865,\n",
      "        0.0764, 0.0833, 0.0984, 0.0813, 0.0769, 0.0919, 0.0734, 0.1358, 0.0807,\n",
      "        0.0851, 0.0940, 0.0842, 0.0867, 0.0876, 0.0774, 0.0452, 0.1059, 0.0891,\n",
      "        0.0779, 0.0239, 0.0861, 0.0949, 0.0818, 0.0984, 0.0953, 0.0894, 0.0344,\n",
      "        0.0754, 0.0906, 0.0766, 0.0915, 0.0784, 0.0832, 0.0817, 0.0910, 0.1213,\n",
      "        0.0856, 0.0975, 0.0965, 0.0838, 0.0769, 0.0341, 0.1170, 0.1063, 0.0750,\n",
      "        0.0788, 0.0739, 0.0813, 0.0808, 0.0808, 0.0759, 0.1277, 0.0870, 0.0991,\n",
      "        0.0870, 0.0875, 0.0901, 0.0694, 0.0891, 0.0783, 0.0652, 0.0842, 0.2952,\n",
      "        0.0793, 0.0847, 0.0861, 0.0828, 0.0906, 0.0847, 0.0955, 0.0655, 0.0847,\n",
      "        0.0764, 0.0842, 0.0772, 0.0871, 0.0837, 0.0772, 0.0846, 0.0706, 0.0955,\n",
      "        0.0847, 0.0784, 0.0818, 0.1165, 0.0798, 0.0801, 0.0802, 0.0916, 0.0832,\n",
      "        0.0871, 0.0754, 0.0705, 0.0729, 0.0826, 0.0775, 0.0811, 0.0785, 0.0445,\n",
      "        0.0954, 0.0857, 0.0867, 0.0950, 0.0889, 0.0790, 0.0940, 0.0653, 0.0820,\n",
      "        0.0890, 0.1132, 0.0818, 0.0672, 0.0823, 0.0804, 0.0404, 0.0974, 0.0734,\n",
      "        0.0850, 0.0798, 0.1092, 0.1261, 0.0901, 0.0229, 0.0808, 0.0765, 0.0783,\n",
      "        0.0733, 0.0865, 0.0801, 0.0790, 0.0701, 0.0984, 0.0676, 0.0763, 0.1074,\n",
      "        0.0794, 0.0739, 0.0945, 0.0975, 0.2278, 0.1132, 0.0808, 0.0746, 0.0803,\n",
      "        0.0842, 0.0857, 0.0845, 0.0769, 0.0751, 0.0916, 0.0750, 0.0794, 0.0794,\n",
      "        0.0749, 0.0877, 0.0975, 0.1618, 0.0442, 0.0882, 0.0818, 0.0906, 0.0783,\n",
      "        0.0964, 0.7190, 0.0774, 0.0785, 0.1584, 0.0925, 0.0798, 0.0737, 0.0969,\n",
      "        0.0747, 0.0830, 0.0896, 0.0911, 0.0917, 0.0876, 0.0784, 0.0818, 0.1194,\n",
      "        0.1072, 0.0842, 0.0827, 0.0798, 0.0798, 0.1047, 0.2372, 0.0836, 0.0816,\n",
      "        0.0877, 0.0857, 0.1211, 0.0739, 0.0759, 0.0783, 0.0962, 0.0802, 0.0949,\n",
      "        0.0764, 0.0735, 0.0772, 0.1023, 0.0960, 0.0882, 0.0784, 0.0396, 0.0798,\n",
      "        0.1512, 0.0946, 0.0851, 0.0706, 0.0725, 0.0789, 0.0906, 0.0980, 0.0891,\n",
      "        0.0697, 0.0843, 0.0567, 0.1121, 0.0861, 0.0813, 0.0984, 0.0752, 0.0840,\n",
      "        0.0961, 0.0812, 0.0753, 0.0794, 0.0921, 0.0632, 0.0690, 0.1017, 0.0849,\n",
      "        0.0745, 0.0794, 0.1399, 0.0886, 0.0845, 0.0883, 0.0774, 0.0857, 0.0760,\n",
      "        0.0808, 0.1039, 0.0948, 0.0363, 0.0764, 0.0802, 0.0895, 0.0717, 0.0876,\n",
      "        0.0936, 0.0667, 0.0833, 0.0759, 0.1045, 0.0759, 0.0872, 0.1181, 0.1009,\n",
      "        0.0749, 0.1013, 0.1419, 0.0759, 0.0760, 0.0812, 0.3675, 0.0908, 0.0827,\n",
      "        0.0785, 0.0781, 0.0715, 0.1052, 0.0981, 0.2012, 0.0803, 0.0535, 0.0836,\n",
      "        0.0740, 0.0400, 0.4319, 0.0957, 0.0790, 0.0794, 0.0596, 0.0815, 0.0978,\n",
      "        0.0805, 0.0734, 0.0789, 0.1356, 0.0983, 0.0778, 0.0828, 0.0706, 0.0376,\n",
      "        0.0460, 0.0791, 0.1009, 0.0711, 0.0764, 0.0750, 0.1209, 0.0878, 0.0872,\n",
      "        0.0671, 0.0723, 0.1057, 0.0887, 0.0942, 0.0735, 0.1053, 0.0526, 0.0893,\n",
      "        0.0900, 0.0798, 0.0799, 0.0591, 0.0942, 0.0704, 0.0662, 0.0819, 0.1141,\n",
      "        0.0853, 0.0838, 0.0822, 0.0872, 0.1397, 0.0793, 0.0884, 0.0850, 0.0963,\n",
      "        0.0881, 0.0788, 0.0783, 0.0525, 0.0848, 0.0901, 0.0798, 0.0430, 0.0827,\n",
      "        0.0769, 0.0881, 0.1000, 0.0940, 0.0867, 0.1429, 0.0794, 0.0799, 0.0761,\n",
      "        0.0762, 0.0641, 0.0764, 0.0564, 0.0963, 0.0753, 0.1173, 0.0727, 0.1251,\n",
      "        0.0758, 0.1006, 0.0833, 0.0784, 0.0787, 0.0681, 0.0862, 0.0760, 0.0925,\n",
      "        0.0798, 0.1057, 0.0825, 0.0991, 0.0852, 0.0642, 0.0877, 0.0364, 0.0749,\n",
      "        0.1018, 0.0769, 0.0871, 0.0779, 0.0753, 0.0792, 0.0844, 0.0935, 0.0544,\n",
      "        0.0779, 0.1021, 0.0918, 0.0535, 0.0759, 0.0710, 0.0856, 0.0845, 0.0769,\n",
      "        0.1167, 0.1132, 0.0809, 0.0762, 0.0949, 0.0788, 0.1086, 0.0746, 0.0711,\n",
      "        0.0758, 0.0910, 0.0816, 0.0732, 0.0914, 0.0768, 0.0818, 0.0960, 0.0852,\n",
      "        0.0842, 0.0737, 0.0910, 0.0803, 0.0835, 0.0736, 0.1164, 0.0816, 0.0847,\n",
      "        0.0724, 0.0793, 0.0339, 0.0632, 0.1006, 0.0800, 0.0750, 0.0867, 0.0757,\n",
      "        0.0764, 0.0781, 0.0469, 0.0764, 0.0778, 0.0814, 0.0755, 0.0813, 0.1170,\n",
      "        0.1418, 0.0784, 0.0797, 0.0749, 0.0862, 0.0871, 0.0794, 0.0410, 0.0738,\n",
      "        0.0735, 0.0833, 0.0952, 0.1287, 0.0837, 0.0794, 0.0729, 0.0737, 0.0794,\n",
      "        0.1023, 0.0829, 0.0899, 0.0833, 0.1215, 0.0730, 0.0828, 0.0876, 0.0733,\n",
      "        0.1053, 0.0777, 0.0955, 0.0979, 0.1083, 0.0869, 0.0467, 0.1028, 0.0876,\n",
      "        0.0784, 0.1142, 0.1120, 0.0826, 0.1077, 0.0798, 0.0828, 0.1301])\n",
      "\n",
      "Name: decoder.block.0.layer.2.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-0.7422, -0.2158,  0.4668,  ...,  0.4218, -0.2520,  0.3944],\n",
      "        [-0.0939, -0.4451,  0.4492,  ...,  0.0186,  0.2716, -0.4847],\n",
      "        [ 1.1094,  0.4942, -0.9804,  ..., -0.5781, -0.3126, -0.9803],\n",
      "        ...,\n",
      "        [ 0.0848, -0.0068, -0.1027,  ..., -0.8709,  0.1079, -0.0381],\n",
      "        [-0.8084, -0.1747, -0.5077,  ...,  0.4921,  0.1222,  0.8202],\n",
      "        [ 0.1236, -1.0159,  0.3279,  ..., -0.3340,  0.1047,  0.1785]])\n",
      "\n",
      "Name: decoder.block.0.layer.2.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.1912,  0.1810, -0.1512,  ...,  0.1985, -0.2888,  0.1448],\n",
      "        [-0.0275,  0.1296, -0.0180,  ..., -0.0719, -0.0600,  0.2127],\n",
      "        [ 0.0205, -0.2253, -0.2638,  ...,  0.1107, -0.2908, -0.1746],\n",
      "        ...,\n",
      "        [-1.2891, -0.1173,  0.0544,  ...,  0.3888,  0.2304, -0.0935],\n",
      "        [-0.2538,  0.0967, -0.0956,  ...,  0.1359,  0.1133, -0.1532],\n",
      "        [-0.2421,  0.3596, -4.5314,  ..., -0.2596,  0.0662,  0.4163]])\n",
      "\n",
      "Name: decoder.block.0.layer.2.layer_norm.weight\n",
      "Weight: tensor([0.6639, 0.9651, 0.5976, 0.8245, 0.3049, 0.6017, 0.7852, 0.6057, 0.4104,\n",
      "        0.6096, 0.5900, 0.3397, 0.5861, 0.6954, 5.2497, 0.6447, 0.5237, 0.6836,\n",
      "        0.6679, 0.5862, 0.5857, 0.4942, 0.9570, 0.2679, 0.5745, 0.5505, 0.7073,\n",
      "        0.4861, 0.5821, 0.8049, 0.5627, 0.6406, 0.8478, 0.5545, 0.7771, 0.6599,\n",
      "        0.6094, 0.6872, 0.7502, 0.6331, 0.6328, 0.5901, 0.2599, 0.8319, 0.8323,\n",
      "        0.5862, 0.1575, 0.6093, 0.6682, 0.6018, 0.7032, 0.7659, 0.6409, 0.3069,\n",
      "        0.5779, 0.6288, 0.5978, 0.6878, 0.5588, 0.5901, 0.7190, 0.6487, 0.9573,\n",
      "        0.6604, 1.1092, 0.6991, 0.6838, 0.5706, 0.2620, 0.8791, 0.8518, 0.5784,\n",
      "        0.6370, 0.5431, 0.6446, 0.5974, 0.6329, 0.5583, 0.9143, 0.5271, 0.7108,\n",
      "        0.8792, 0.6446, 0.6873, 0.5389, 0.6917, 0.6169, 0.5584, 0.6213, 1.2889,\n",
      "        0.5979, 0.5549, 0.7303, 0.6643, 0.7538, 0.7190, 0.6797, 0.4768, 0.8477,\n",
      "        0.6055, 0.6956, 0.5628, 0.6249, 0.4040, 0.4881, 0.6057, 0.5392, 0.8948,\n",
      "        0.6956, 0.5935, 0.7307, 0.8866, 0.6092, 0.7892, 0.6330, 0.7815, 0.7112,\n",
      "        0.6604, 0.5745, 0.5588, 0.5392, 0.6212, 0.5784, 0.5550, 0.5861, 0.3870,\n",
      "        0.6602, 0.7384, 0.6521, 0.8010, 0.7073, 0.5198, 0.7620, 0.4665, 0.7030,\n",
      "        0.6213, 0.8127, 0.4533, 0.5040, 0.5236, 0.5821, 0.2673, 0.8826, 0.4729,\n",
      "        0.6839, 0.6799, 0.8279, 1.0313, 0.7459, 0.1136, 0.5237, 0.5901, 0.5935,\n",
      "        0.5741, 0.5507, 0.5744, 0.5393, 0.4274, 0.7497, 0.3479, 0.5548, 0.7107,\n",
      "        0.5779, 0.5899, 0.7693, 0.6917, 1.8591, 0.8244, 0.5860, 0.5626, 0.5780,\n",
      "        0.7109, 0.6487, 0.5822, 0.6643, 0.5898, 0.6484, 0.4861, 0.5861, 0.6017,\n",
      "        0.5665, 0.7190, 0.4590, 1.0466, 0.2810, 0.6525, 0.6250, 0.8205, 0.5704,\n",
      "        0.6604, 3.5935, 0.4705, 0.5744, 1.0935, 0.6953, 0.5432, 0.5002, 0.8050,\n",
      "        0.5039, 0.6366, 0.7068, 0.7347, 0.8007, 0.7228, 0.6956, 0.7268, 0.6487,\n",
      "        0.7229, 0.8557, 0.5700, 0.6248, 0.6213, 0.8713, 1.6487, 0.6212, 0.5627,\n",
      "        0.7774, 0.7189, 0.8088, 0.5313, 0.5120, 0.5506, 0.7891, 0.6214, 0.5857,\n",
      "        0.5393, 0.5823, 0.5236, 0.8596, 0.8361, 0.6758, 0.5663, 0.3455, 0.6721,\n",
      "        0.8830, 0.8556, 0.7893, 0.5979, 0.5349, 0.8947, 0.5779, 0.7576, 0.7501,\n",
      "        0.5276, 0.6247, 0.3924, 0.8788, 0.7658, 0.4317, 0.8047, 0.5665, 0.7229,\n",
      "        0.8552, 0.5236, 0.5196, 0.6328, 0.7893, 0.5003, 0.5236, 0.7540, 0.5897,\n",
      "        0.5588, 0.6211, 0.7692, 0.8635, 0.6602, 0.6838, 0.5274, 0.6993, 0.5940,\n",
      "        0.5627, 0.9534, 0.7693, 0.2698, 0.6174, 0.6643, 0.6291, 0.5742, 0.6487,\n",
      "        0.6718, 0.5466, 0.6409, 0.6760, 0.7966, 0.6054, 0.6873, 0.9065, 0.8479,\n",
      "        0.5784, 0.7385, 0.8831, 0.5508, 0.5466, 0.6291, 2.4372, 0.4925, 0.7188,\n",
      "        0.6368, 0.6135, 0.4040, 0.8049, 0.7776, 1.7893, 0.5822, 0.3532, 0.5628,\n",
      "        0.5505, 0.3024, 3.1247, 0.8167, 0.6134, 0.5862, 0.3421, 0.7422, 0.7070,\n",
      "        0.5744, 0.4999, 0.5978, 0.6370, 0.7654, 0.6094, 0.6131, 0.5271, 0.2932,\n",
      "        0.3538, 0.5586, 0.7581, 0.6448, 0.5901, 0.8006, 0.8244, 0.8438, 0.6017,\n",
      "        0.6213, 0.5276, 0.8870, 0.7190, 0.7069, 0.4981, 0.9102, 0.3772, 0.7380,\n",
      "        0.6253, 0.5231, 0.5818, 0.4548, 0.7616, 0.5158, 0.4412, 0.8401, 0.7773,\n",
      "        0.6171, 0.6679, 0.5627, 0.7073, 0.7969, 0.5899, 0.6642, 0.6330, 0.8123,\n",
      "        0.7932, 0.5428, 0.5545, 0.5472, 0.6523, 0.6487, 0.6524, 0.2204, 0.5779,\n",
      "        0.6289, 0.6564, 0.8401, 0.8831, 0.6797, 0.8792, 0.5664, 0.6718, 0.5588,\n",
      "        0.5472, 0.4821, 0.6641, 0.3323, 0.7147, 0.5822, 0.8164, 0.5584, 0.9416,\n",
      "        0.5628, 0.6171, 0.6018, 0.5745, 0.6720, 0.4919, 0.5899, 0.6717, 0.6364,\n",
      "        0.5079, 0.9494, 0.7304, 0.9494, 0.5076, 0.4513, 0.6604, 0.1341, 0.5628,\n",
      "        0.9958, 0.7502, 0.5744, 0.5432, 0.5822, 0.6872, 0.6130, 0.6717, 0.3672,\n",
      "        0.6017, 0.8557, 0.8909, 0.3733, 0.6367, 0.6054, 0.6405, 0.6873, 0.6330,\n",
      "        1.0237, 0.7814, 0.5940, 0.5154, 0.8006, 0.5740, 0.9807, 0.5432, 0.5783,\n",
      "        0.5589, 0.7072, 0.6093, 0.5197, 0.7034, 0.5706, 0.7499, 0.7693, 0.6016,\n",
      "        0.6565, 0.6291, 0.6914, 0.6292, 0.6407, 0.5666, 0.9220, 0.6252, 0.6600,\n",
      "        0.5036, 0.5744, 0.3713, 0.4822, 0.7771, 0.7422, 0.5784, 0.6487, 0.6213,\n",
      "        0.6328, 0.5626, 0.5784, 0.5861, 0.6214, 0.6249, 0.5704, 0.6292, 0.9417,\n",
      "        0.9924, 0.5822, 0.6760, 0.5745, 0.7854, 0.6057, 0.6018, 0.3650, 0.5002,\n",
      "        0.5198, 0.5743, 0.6917, 0.8399, 0.7306, 0.5351, 0.5545, 0.5861, 0.5744,\n",
      "        0.7932, 0.6367, 0.6564, 0.6133, 1.2967, 0.5858, 0.5510, 0.6954, 0.5666,\n",
      "        0.7537, 0.5627, 0.8787, 0.7263, 0.7971, 0.7893, 0.3518, 0.8634, 0.6409,\n",
      "        0.6759, 0.8162, 0.8753, 0.6252, 0.9727, 0.5862, 0.9182, 0.9333])\n",
      "\n",
      "Name: decoder.block.1.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[-0.0241,  0.0662, -0.0140,  ...,  0.0104,  0.0886, -0.0034],\n",
      "        [-0.0094, -0.0100, -0.0561,  ..., -0.0223,  0.0519, -0.1057],\n",
      "        [ 0.0317, -0.0788,  0.0656,  ...,  0.0469,  0.0243, -0.0138],\n",
      "        ...,\n",
      "        [-0.0315,  0.0508, -0.0310,  ..., -0.0123,  0.0617,  0.0143],\n",
      "        [-0.0722,  0.1211, -0.0233,  ..., -0.0005,  0.0015,  0.0474],\n",
      "        [ 0.0241,  0.0132, -0.0118,  ...,  0.0147,  0.0459,  0.0441]])\n",
      "\n",
      "Name: decoder.block.1.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 0.5546, -0.3164,  0.3026,  ...,  0.0446,  0.2014, -0.5897],\n",
      "        [ 0.8907, -0.2245, -0.0268,  ...,  0.5978, -0.3283,  0.2815],\n",
      "        [ 0.3164, -0.5859, -0.7342,  ...,  0.0910, -0.4710, -0.4063],\n",
      "        ...,\n",
      "        [ 0.0539,  0.0798,  0.2274,  ...,  0.0273,  0.0172,  0.1370],\n",
      "        [ 0.2889, -0.1728,  0.0206,  ...,  0.5781,  0.1307,  0.1435],\n",
      "        [-0.0800,  0.4783,  0.1535,  ..., -0.0324,  0.2062, -0.2122]])\n",
      "\n",
      "Name: decoder.block.1.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[-0.0116, -0.1140, -0.4551,  ..., -0.5584,  0.2655, -0.4961],\n",
      "        [-1.3361,  1.0075,  0.4434,  ..., -0.0692, -0.5393,  1.8123],\n",
      "        [-1.1405,  0.4021, -0.0076,  ..., -0.4178, -0.5666,  0.3438],\n",
      "        ...,\n",
      "        [-0.5272,  0.3089,  0.0245,  ...,  0.9177,  0.6956, -1.2031],\n",
      "        [ 0.5427, -0.0392,  0.4843,  ...,  0.2639,  0.1551,  0.1923],\n",
      "        [ 0.4006, -0.0420, -0.8201,  ..., -0.0396, -0.1062, -1.2654]])\n",
      "\n",
      "Name: decoder.block.1.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-0.0985,  0.1731, -0.1849,  ..., -1.1956, -0.5589,  0.2619],\n",
      "        [ 0.6131, -0.0425,  0.1281,  ...,  0.1679,  0.8243, -0.3944],\n",
      "        [-0.1150,  0.3929, -0.7386,  ...,  0.7732,  0.5544, -0.2988],\n",
      "        ...,\n",
      "        [-0.0456, -0.2713,  0.5232,  ...,  1.5155,  1.1716, -0.1161],\n",
      "        [-0.0339,  0.1375, -0.4119,  ...,  1.2736,  0.5471, -0.6486],\n",
      "        [-0.2851,  0.0891, -1.2190,  ...,  0.2312, -1.9300,  0.9920]])\n",
      "\n",
      "Name: decoder.block.1.layer.0.layer_norm.weight\n",
      "Weight: tensor([0.1229, 0.2161, 0.1033, 0.1765, 0.0637, 0.1413, 0.1591, 0.0734, 0.0612,\n",
      "        0.1406, 0.1389, 0.0600, 0.1184, 0.1462, 0.1062, 0.1131, 0.1242, 0.1238,\n",
      "        0.1465, 0.1247, 0.1184, 0.1104, 0.1766, 0.0586, 0.1356, 0.1028, 0.1570,\n",
      "        0.0769, 0.1385, 0.1581, 0.1351, 0.0891, 0.1800, 0.1321, 0.1229, 0.0911,\n",
      "        0.1385, 0.1404, 0.1614, 0.1169, 0.1417, 0.1267, 0.0730, 0.1809, 0.1487,\n",
      "        0.1132, 0.0549, 0.1173, 0.1350, 0.1336, 0.1595, 0.1619, 0.1267, 0.0686,\n",
      "        0.0954, 0.1604, 0.1278, 0.1370, 0.1282, 0.0935, 0.1482, 0.1111, 0.2067,\n",
      "        0.1543, 0.1413, 0.1454, 0.1404, 0.1399, 0.0705, 0.1897, 0.1721, 0.1183,\n",
      "        0.1405, 0.1261, 0.1345, 0.1101, 0.1516, 0.0964, 0.1198, 0.1053, 0.1526,\n",
      "        0.1614, 0.1414, 0.1544, 0.1101, 0.1072, 0.1150, 0.0910, 0.1503, 0.2985,\n",
      "        0.1257, 0.1125, 0.0886, 0.1599, 0.0975, 0.1624, 0.0450, 0.0950, 0.1667,\n",
      "        0.1253, 0.1591, 0.1329, 0.1169, 0.0833, 0.1306, 0.1399, 0.1130, 0.1960,\n",
      "        0.1552, 0.1062, 0.1575, 0.1914, 0.1320, 0.1678, 0.1418, 0.1564, 0.1711,\n",
      "        0.1496, 0.1086, 0.1213, 0.1223, 0.1300, 0.1388, 0.0964, 0.1360, 0.2175,\n",
      "        0.1482, 0.1532, 0.1282, 0.1673, 0.1407, 0.1214, 0.1453, 0.1057, 0.0808,\n",
      "        0.1380, 0.1473, 0.1091, 0.0996, 0.1414, 0.1220, 0.0576, 0.1780, 0.1130,\n",
      "        0.1486, 0.1316, 0.1387, 0.1403, 0.1585, 0.0351, 0.1247, 0.1321, 0.0769,\n",
      "        0.1301, 0.1154, 0.1221, 0.1321, 0.1214, 0.1594, 0.1145, 0.1218, 0.1592,\n",
      "        0.1155, 0.1125, 0.1238, 0.1701, 0.1481, 0.1317, 0.1312, 0.1219, 0.0989,\n",
      "        0.1777, 0.0975, 0.1355, 0.1542, 0.1073, 0.0896, 0.0794, 0.1155, 0.1437,\n",
      "        0.1288, 0.1682, 0.2424, 0.2556, 0.0691, 0.1316, 0.1321, 0.1563, 0.1194,\n",
      "        0.1546, 0.1276, 0.0852, 0.1237, 0.1497, 0.1267, 0.1336, 0.1203, 0.1546,\n",
      "        0.1135, 0.1565, 0.1360, 0.1316, 0.1423, 0.1259, 0.1582, 0.1277, 0.1862,\n",
      "        0.1506, 0.1872, 0.1389, 0.1423, 0.1452, 0.1321, 0.2488, 0.1462, 0.1379,\n",
      "        0.1726, 0.1033, 0.1487, 0.1164, 0.1341, 0.1233, 0.1261, 0.1517, 0.1209,\n",
      "        0.1272, 0.0915, 0.1350, 0.1769, 0.1457, 0.1409, 0.1259, 0.0537, 0.1013,\n",
      "        0.1521, 0.1872, 0.1892, 0.0715, 0.1209, 0.0485, 0.0928, 0.1271, 0.1086,\n",
      "        0.1169, 0.0809, 0.0359, 0.1721, 0.1761, 0.1023, 0.1497, 0.1189, 0.1407,\n",
      "        0.1604, 0.1208, 0.1296, 0.1356, 0.1872, 0.0778, 0.0786, 0.1433, 0.1291,\n",
      "        0.1327, 0.1481, 0.0891, 0.1858, 0.1477, 0.1447, 0.1377, 0.0842, 0.1004,\n",
      "        0.1160, 0.1974, 0.1379, 0.0612, 0.1485, 0.0799, 0.1436, 0.1399, 0.1328,\n",
      "        0.1223, 0.0676, 0.1131, 0.1497, 0.1423, 0.1399, 0.1350, 0.1651, 0.1770,\n",
      "        0.1330, 0.1516, 0.1111, 0.1360, 0.1136, 0.1315, 0.2888, 0.1124, 0.1688,\n",
      "        0.1425, 0.1623, 0.0828, 0.1787, 0.1507, 0.2908, 0.1413, 0.0592, 0.1389,\n",
      "        0.1072, 0.0692, 0.1901, 0.1020, 0.1545, 0.1292, 0.0994, 0.1639, 0.1448,\n",
      "        0.1140, 0.1155, 0.1466, 0.0945, 0.1272, 0.1434, 0.1407, 0.1309, 0.0686,\n",
      "        0.0993, 0.1302, 0.1467, 0.1407, 0.1580, 0.0792, 0.1335, 0.1712, 0.1193,\n",
      "        0.1438, 0.1238, 0.1550, 0.1379, 0.1601, 0.1067, 0.1667, 0.0803, 0.1105,\n",
      "        0.1553, 0.0745, 0.1262, 0.0714, 0.1360, 0.1121, 0.0901, 0.1985, 0.1965,\n",
      "        0.1245, 0.1376, 0.1281, 0.1331, 0.1204, 0.1118, 0.1555, 0.1130, 0.1446,\n",
      "        0.1750, 0.1282, 0.1325, 0.0734, 0.1433, 0.1340, 0.1389, 0.0437, 0.1130,\n",
      "        0.1398, 0.1504, 0.1673, 0.1663, 0.1268, 0.1608, 0.1408, 0.1531, 0.1121,\n",
      "        0.1278, 0.0764, 0.1643, 0.0819, 0.1404, 0.1413, 0.1458, 0.1317, 0.0881,\n",
      "        0.1280, 0.1104, 0.1438, 0.1404, 0.1438, 0.0532, 0.1507, 0.0916, 0.1394,\n",
      "        0.1066, 0.1413, 0.1536, 0.1834, 0.0988, 0.0696, 0.0754, 0.0368, 0.1291,\n",
      "        0.1086, 0.1580, 0.1291, 0.1223, 0.1224, 0.0905, 0.0852, 0.0964, 0.0794,\n",
      "        0.1386, 0.1673, 0.1379, 0.0666, 0.1487, 0.1536, 0.1368, 0.1481, 0.1364,\n",
      "        0.1111, 0.1633, 0.1374, 0.1233, 0.1735, 0.1302, 0.2019, 0.1194, 0.1030,\n",
      "        0.1155, 0.1379, 0.1252, 0.1130, 0.1282, 0.1272, 0.1117, 0.1526, 0.1292,\n",
      "        0.1594, 0.1464, 0.1331, 0.1643, 0.1413, 0.1247, 0.1673, 0.1593, 0.1746,\n",
      "        0.1121, 0.1321, 0.0593, 0.0784, 0.1633, 0.1622, 0.1328, 0.1546, 0.1233,\n",
      "        0.1321, 0.1289, 0.0803, 0.1360, 0.1355, 0.1497, 0.1331, 0.1162, 0.0783,\n",
      "        0.1330, 0.1316, 0.1542, 0.1239, 0.1394, 0.1477, 0.1438, 0.0815, 0.1262,\n",
      "        0.0484, 0.1464, 0.0998, 0.1259, 0.1545, 0.1184, 0.1356, 0.1360, 0.1291,\n",
      "        0.1682, 0.1249, 0.1278, 0.1253, 0.2540, 0.1390, 0.1442, 0.1428, 0.1356,\n",
      "        0.1663, 0.1286, 0.0777, 0.1093, 0.1524, 0.1846, 0.0671, 0.1589, 0.1448,\n",
      "        0.1311, 0.1761, 0.1560, 0.0885, 0.2039, 0.1326, 0.1780, 0.0732])\n",
      "\n",
      "Name: decoder.block.1.layer.1.EncDecAttention.q.weight\n",
      "Weight: tensor([[ 0.0191,  0.1018,  0.0786,  ..., -0.0550,  0.0604,  0.0802],\n",
      "        [-0.0057,  0.0740,  0.0284,  ..., -0.0329, -0.0549, -0.1194],\n",
      "        [-0.0950,  0.0230,  0.0293,  ..., -0.0074,  0.0564, -0.0305],\n",
      "        ...,\n",
      "        [-0.1356,  0.0170,  0.0390,  ...,  0.0016,  0.0489, -0.0741],\n",
      "        [ 0.0137, -0.0042, -0.0890,  ...,  0.1414,  0.0798, -0.2147],\n",
      "        [ 0.0725, -0.0540, -0.0330,  ...,  0.0308, -0.0570,  0.0271]])\n",
      "\n",
      "Name: decoder.block.1.layer.1.EncDecAttention.k.weight\n",
      "Weight: tensor([[ 0.2556,  0.0637,  0.3221,  ..., -0.2156,  0.2888, -0.2029],\n",
      "        [-0.4275,  0.5310, -0.0740,  ...,  0.3397,  0.5276,  0.2676],\n",
      "        [-0.1864,  0.0603, -0.1895,  ..., -0.1125, -0.1717, -0.5588],\n",
      "        ...,\n",
      "        [-0.5001, -0.1457,  0.2237,  ...,  0.1039,  0.1068,  0.0114],\n",
      "        [ 0.1648, -0.2655,  0.1054,  ..., -0.1358, -0.4296,  0.0582],\n",
      "        [ 0.0246, -0.5663,  0.2159,  ...,  0.1084, -0.4687,  0.3143]])\n",
      "\n",
      "Name: decoder.block.1.layer.1.EncDecAttention.v.weight\n",
      "Weight: tensor([[-0.0026,  0.4392,  0.8049,  ...,  0.5037,  0.2053, -0.1585],\n",
      "        [-0.0939,  0.2334, -0.4415,  ..., -0.6874,  0.1824,  0.2989],\n",
      "        [-0.5354, -0.7581, -0.4060,  ...,  0.5349,  0.2483, -0.3889],\n",
      "        ...,\n",
      "        [-0.5588, -0.3436, -0.4865,  ...,  0.2295,  0.4883,  0.0413],\n",
      "        [-0.2462, -0.0133, -0.3381,  ...,  1.0159,  0.4963, -0.3243],\n",
      "        [-0.2792, -1.2107,  0.1139,  ...,  0.0122,  0.3828, -0.2295]])\n",
      "\n",
      "Name: decoder.block.1.layer.1.EncDecAttention.o.weight\n",
      "Weight: tensor([[ 0.0891,  0.5270, -1.0159,  ...,  0.1242, -0.2239, -0.5036],\n",
      "        [ 0.2395, -0.6487, -0.0226,  ..., -0.1496, -0.2415, -0.5544],\n",
      "        [ 0.0202, -0.2239, -1.3519,  ..., -0.0867, -0.0696,  0.0823],\n",
      "        ...,\n",
      "        [-0.1288, -0.4632,  1.3200,  ...,  0.5271, -0.2352, -0.4685],\n",
      "        [ 0.6521,  0.2444,  0.2171,  ..., -0.1338, -0.1184, -0.1428],\n",
      "        [-0.8206,  0.7614,  0.4509,  ..., -0.0101, -0.5393, -0.1668]])\n",
      "\n",
      "Name: decoder.block.1.layer.1.layer_norm.weight\n",
      "Weight: tensor([ 0.0813,  0.1846,  0.0735,  0.1135,  0.0603,  0.0951,  0.1152,  0.0667,\n",
      "         0.0652,  0.1185,  0.1013,  0.0402,  0.0954,  0.1018,  0.0788,  0.0837,\n",
      "         0.1017,  0.0820,  0.1032,  0.0881,  0.0807,  0.0895,  0.1109,  0.0332,\n",
      "         0.1094,  0.0698,  0.1130,  0.0530,  0.1028,  0.1056,  0.0908,  0.0779,\n",
      "         0.1132,  0.0970,  0.0895,  0.0696,  0.0980,  0.1012,  0.1067,  0.0758,\n",
      "         0.0955,  0.0967,  0.0530,  0.1207,  0.0955,  0.0842,  0.0289,  0.0783,\n",
      "         0.0974,  0.0953,  0.1033,  0.1140,  0.0896,  0.0530,  0.0779,  0.1094,\n",
      "         0.0965,  0.1150,  0.0983,  0.0900,  0.1212,  0.0838,  0.1331,  0.1099,\n",
      "         0.1301,  0.1034,  0.0927,  0.1114,  0.0579,  0.1150,  0.1317,  0.0831,\n",
      "         0.1032,  0.0932,  0.0907,  0.0978,  0.1066,  0.0734,  0.0964,  0.0716,\n",
      "         0.0871,  0.1083,  0.0933,  0.1135,  0.0877,  0.0814,  0.0853,  0.0665,\n",
      "         0.1067,  0.1619,  0.0946,  0.0759,  0.0789,  0.1164,  0.1003,  0.1063,\n",
      "         0.1575,  0.0792,  0.0950,  0.0857,  0.1174,  0.1042,  0.0772,  0.0799,\n",
      "         0.1013,  0.0967,  0.0791,  0.1233,  0.0993,  0.0735,  0.1101,  0.1364,\n",
      "         0.1072,  0.1204,  0.1101,  0.1066,  0.1427,  0.1169,  0.0820,  0.0901,\n",
      "         0.0870,  0.0998,  0.1038,  0.0892,  0.0965,  0.0584,  0.0979,  0.1130,\n",
      "         0.1013,  0.1115,  0.0941,  0.1049,  0.1145,  0.0696,  0.0725,  0.1085,\n",
      "         0.0959,  0.0720,  0.0700,  0.1046,  0.0899,  0.0564,  0.1233,  0.0852,\n",
      "         0.1082,  0.0837,  0.1257,  0.1140,  0.1116,  0.0462,  0.0910,  0.0994,\n",
      "         0.0598,  0.0927,  0.0839,  0.1042,  0.1064,  0.0833,  0.1271,  0.1053,\n",
      "         0.1059,  0.1096,  0.0917,  0.0818,  0.0974,  0.1199,  0.1042,  0.0931,\n",
      "         0.1052,  0.0958,  0.0774,  0.1399,  0.0925,  0.1247,  0.1218,  0.0763,\n",
      "         0.1028,  0.0577,  0.0951,  0.1101,  0.0949,  0.1170,  0.0755,  0.1973,\n",
      "         0.0691,  0.0929,  0.0932,  0.1048,  0.0898,  0.1155,  0.1008,  0.0644,\n",
      "         0.0985,  0.1116,  0.0944,  0.1125,  0.0901,  0.1076,  0.0906,  0.1041,\n",
      "         0.0969,  0.0988,  0.1021,  0.0899,  0.0984,  0.0852,  0.1981,  0.1106,\n",
      "         0.1236,  0.1035,  0.1073,  0.1200,  0.0893,  0.1555,  0.1130,  0.1106,\n",
      "         0.1196,  0.0759,  0.1091,  0.0882,  0.1013,  0.0876,  0.0891,  0.1027,\n",
      "         0.0831,  0.0965,  0.0857,  0.1093,  0.1349,  0.0931,  0.1109,  0.0886,\n",
      "         0.0550,  0.0800,  0.1770,  0.1277,  0.1086,  0.0506,  0.0785,  0.1004,\n",
      "         0.0683,  0.0855,  0.0985,  0.0773,  0.0715,  0.0686,  0.1176,  0.1170,\n",
      "         0.0562,  0.1091,  0.0979,  0.1052,  0.1169,  0.0883,  0.0974,  0.0886,\n",
      "         0.1288,  0.0720,  0.0542,  0.0964,  0.0849,  0.1007,  0.1052,  0.0619,\n",
      "         0.1112,  0.1207,  0.0954,  0.1067, -0.0789,  0.0755,  0.0859,  0.1216,\n",
      "         0.0837,  0.0389,  0.0981,  0.0557,  0.1109,  0.1077,  0.0892,  0.0863,\n",
      "         0.0730,  0.0697,  0.1047,  0.1114,  0.1005,  0.0935,  0.1336,  0.1377,\n",
      "         0.1012,  0.1042,  0.0875,  0.0963,  0.0885,  0.0926,  0.1077,  0.0901,\n",
      "         0.1159,  0.0965,  0.1249,  0.0561,  0.1147,  0.0930,  0.1677,  0.1013,\n",
      "         0.0478,  0.1079,  0.0783,  0.0486,  0.1727,  0.1248,  0.1185,  0.0928,\n",
      "         0.0745,  0.1259,  0.0969,  0.0995,  0.0905,  0.1105,  0.0814,  0.0871,\n",
      "         0.0955,  0.1099,  0.1089,  0.0706,  0.0999,  0.1066,  0.0930,  0.1069,\n",
      "         0.1151, -0.0674,  0.0998,  0.1143,  0.0809,  0.1062,  0.0927,  0.1134,\n",
      "         0.0896,  0.1053,  0.0738,  0.1140,  0.0562,  0.0925,  0.1101,  0.0604,\n",
      "         0.0882,  0.0538,  0.1048,  0.0794,  0.0671,  0.1367,  0.1404,  0.0950,\n",
      "         0.0911,  0.1073,  0.0892,  0.0887,  0.0941,  0.1133,  0.0754,  0.1137,\n",
      "         0.1163,  0.0969,  0.1038,  0.0657,  0.1048,  0.0877,  0.0998,  0.0425,\n",
      "         0.0882,  0.1066,  0.1153,  0.1062,  0.1223,  0.1057,  0.0874,  0.1060,\n",
      "         0.1155,  0.0756,  0.1086,  0.0528,  0.1155,  0.0701,  0.1023,  0.1115,\n",
      "         0.1057,  0.0900,  0.0750,  0.1044,  0.0798,  0.1101,  0.1021,  0.0993,\n",
      "         0.0905,  0.1074,  0.0831,  0.1009,  0.0707,  0.0970,  0.1084,  0.1359,\n",
      "         0.0691,  0.0576,  0.0979,  0.0318,  0.0979,  0.0930,  0.1095,  0.0949,\n",
      "         0.0909,  0.0950,  0.0911,  0.0652,  0.0815,  0.0544,  0.1055,  0.1175,\n",
      "         0.0898,  0.0696,  0.1086,  0.1114,  0.0962,  0.1086,  0.0847,  0.1224,\n",
      "         0.1059,  0.1084,  0.0979,  0.1416,  0.0963,  0.1404,  0.1027,  0.0756,\n",
      "         0.0967,  0.1027,  0.1083,  0.0746,  0.0849,  0.0947,  0.0823,  0.0982,\n",
      "         0.1116,  0.1242,  0.1062,  0.0914,  0.1152,  0.1091,  0.0950,  0.0999,\n",
      "         0.1128,  0.1148,  0.0871,  0.1015,  0.0354,  0.0637,  0.1208,  0.1219,\n",
      "         0.1026,  0.1043,  0.0848,  0.1008,  0.1162,  0.0445,  0.0985,  0.0998,\n",
      "         0.1033,  0.1082,  0.0929,  0.1678,  0.1009,  0.0989,  0.1121,  0.0964,\n",
      "         0.1073,  0.1028,  0.0963,  0.0503,  0.0981,  0.1101,  0.1203,  0.1145,\n",
      "         0.0915,  0.1268,  0.0920,  0.1013,  0.1096,  0.0986,  0.1042,  0.0925,\n",
      "         0.0879,  0.0951,  0.1941,  0.1038,  0.0891,  0.1072,  0.1080,  0.1172,\n",
      "         0.0976,  0.0916,  0.0882,  0.1021,  0.1215,  0.0559,  0.1052,  0.1089,\n",
      "         0.0930,  0.1209,  0.1027,  0.0959,  0.1385,  0.0906,  0.0891,  0.0549])\n",
      "\n",
      "Name: decoder.block.1.layer.2.DenseReluDense.wi.weight\n",
      "Weight: tensor([[ 1.1954, -0.5196,  0.5235,  ...,  0.1767, -0.0496,  0.3789],\n",
      "        [-0.4784, -0.5115,  0.3689,  ..., -0.0068, -1.2265, -0.1084],\n",
      "        [-0.1357,  0.0713, -0.5782,  ..., -0.1952, -0.4939,  0.6837],\n",
      "        ...,\n",
      "        [ 1.3828,  1.5625, -0.3926,  ...,  0.3671, -0.0596,  0.4550],\n",
      "        [-0.1796,  0.0649,  0.8242,  ..., -0.5194, -0.0470,  0.6642],\n",
      "        [-0.4921, -0.5858, -0.6835,  ..., -0.2304, -0.1307, -0.7773]])\n",
      "\n",
      "Name: decoder.block.1.layer.2.DenseReluDense.wo.weight\n",
      "Weight: tensor([[ 0.2072, -0.0245,  0.9846,  ...,  0.2813,  0.0925, -0.2078],\n",
      "        [ 0.0831,  0.0949,  0.1370,  ..., -0.5780, -0.2947, -0.3709],\n",
      "        [ 0.0135, -0.1824,  0.0906,  ..., -0.1806,  0.1691,  0.1827],\n",
      "        ...,\n",
      "        [ 0.2413,  0.0163, -0.2321,  ...,  0.2559, -0.5468, -0.0285],\n",
      "        [-0.0630,  0.4318, -0.0686,  ...,  0.0408,  0.0441, -0.0160],\n",
      "        [-0.5351, -0.3259, -0.0393,  ...,  0.3439, -0.5232, -1.1874]])\n",
      "\n",
      "Name: decoder.block.1.layer.2.layer_norm.weight\n",
      "Weight: tensor([0.9372, 1.1409, 1.1487, 1.5315, 0.4299, 1.1562, 1.1171, 1.1794, 1.1015,\n",
      "        1.3986, 1.1873, 0.7732, 1.1643, 1.3752, 1.2112, 1.2737, 1.0940, 1.1091,\n",
      "        1.1014, 1.0704, 1.0079, 0.9807, 1.2659, 0.6951, 1.2657, 0.8714, 1.3127,\n",
      "        0.7966, 1.1564, 1.2654, 1.0783, 0.8591, 1.5940, 1.1640, 1.1252, 1.0154,\n",
      "        1.1330, 1.2425, 1.4065, 0.9100, 1.1409, 1.2346, 0.5583, 1.4377, 1.3752,\n",
      "        0.9065, 0.4646, 0.9495, 1.1018, 1.1409, 1.1092, 1.3284, 0.9647, 1.0779,\n",
      "        0.8903, 1.1094, 1.0389, 1.1640, 1.1487, 0.9998, 1.6409, 0.9806, 1.2893,\n",
      "        1.2659, 1.8987, 1.1643, 1.1250, 1.3283, 0.9963, 1.3204, 1.4221, 1.0237,\n",
      "        1.1643, 1.0705, 1.2108, 1.0858, 1.3515, 0.8903, 1.0002, 0.8006, 1.1794,\n",
      "        1.3987, 1.2190, 1.1169, 1.0862, 0.9763, 1.1485, 0.8515, 1.1953, 0.6755,\n",
      "        0.9883, 0.9611, 1.1174, 1.2971, 1.2187, 1.4062, 1.7185, 0.9299, 1.6800,\n",
      "        1.0704, 1.5081, 1.2421, 0.9846, 0.7658, 1.0860, 1.1565, 0.9611, 1.5548,\n",
      "        1.2424, 0.9221, 1.2190, 1.2112, 1.0939, 1.5861, 1.3673, 1.2657, 1.7580,\n",
      "        1.2503, 1.0076, 1.1564, 0.9923, 1.1408, 1.3672, 0.9841, 1.1716, 1.5394,\n",
      "        1.1406, 1.2500, 1.1326, 1.3284, 1.2034, 1.1018, 1.2972, 0.8435, 0.9842,\n",
      "        1.2815, 1.1643, 0.6643, 0.8517, 1.0470, 1.0390, 0.8908, 1.5159, 0.9416,\n",
      "        1.3675, 1.1721, 1.1484, 1.8122, 1.1877, 0.3884, 1.1253, 1.1799, 0.9023,\n",
      "        1.2576, 0.9492, 1.0862, 1.1717, 0.7737, 1.2107, 1.6175, 1.1565, 1.1017,\n",
      "        1.0155, 0.9064, 1.2503, 1.2347, 1.1794, 1.0857, 1.1330, 1.1796, 0.9025,\n",
      "        1.4607, 1.1638, 1.2425, 1.5003, 0.9805, 1.3126, 0.7541, 1.0549, 1.2659,\n",
      "        1.1955, 1.2503, 0.6214, 1.2892, 0.8748, 1.1248, 1.1249, 1.3283, 1.1565,\n",
      "        1.1564, 1.1091, 0.7419, 1.1325, 1.2107, 1.1721, 1.2503, 0.9886, 1.3514,\n",
      "        0.9845, 1.2424, 1.1953, 1.2893, 1.2034, 1.0705, 1.2815, 1.0862, 0.8359,\n",
      "        1.1249, 1.7189, 1.2346, 1.3753, 1.3206, 1.2185, 0.8047, 1.2815, 1.2346,\n",
      "        1.4061, 0.9651, 1.0706, 1.0623, 1.1173, 0.9885, 1.1487, 1.1484, 0.9026,\n",
      "        1.1408, 1.0081, 1.2034, 1.3753, 1.2657, 1.2029, 1.0940, 0.9294, 1.1014,\n",
      "        1.2577, 1.7498, 1.4138, 0.8675, 0.9378, 1.3747, 0.8595, 1.1329, 1.0002,\n",
      "        1.0783, 1.2732, 1.4060, 1.2893, 1.5393, 0.5662, 1.1327, 1.0392, 1.3907,\n",
      "        1.2815, 0.9494, 1.1409, 1.1014, 1.4143, 1.0544, 0.7890, 1.1716, 1.0391,\n",
      "        1.2345, 1.2734, 0.7851, 1.5393, 1.2970, 1.1170, 1.0315, 1.3279, 0.9217,\n",
      "        0.8830, 1.3987, 1.1639, 0.7849, 1.2424, 1.2497, 1.2346, 1.3909, 1.0313,\n",
      "        1.0003, 1.0784, 0.9260, 1.5158, 1.1722, 1.2033, 1.1096, 1.2190, 1.3513,\n",
      "        1.2502, 1.1797, 1.0081, 1.2425, 1.0705, 1.1956, 0.9061, 0.8515, 1.4143,\n",
      "        1.2888, 1.4065, 0.9416, 1.2815, 1.1877, 1.2891, 1.3284, 0.7424, 1.1643,\n",
      "        0.9494, 0.7930, 1.2892, 1.8124, 1.4456, 1.0158, 0.8206, 1.2190, 1.0623,\n",
      "        1.0393, 1.0471, 1.2501, 0.9222, 1.1018, 1.0940, 1.3127, 1.3674, 1.2732,\n",
      "        1.7581, 1.2892, 1.1330, 1.6018, 1.2735, 1.2575, 1.0935, 1.4377, 0.9414,\n",
      "        1.4609, 1.1096, 1.2889, 1.1482, 1.2186, 0.8674, 1.5471, 1.0079, 1.1018,\n",
      "        1.2892, 0.8122, 1.0859, 0.7735, 1.2112, 0.8987, 0.7893, 1.6878, 1.2503,\n",
      "        1.0547, 1.1483, 1.1487, 1.1565, 1.0544, 0.9140, 1.3280, 0.9416, 1.2501,\n",
      "        1.5237, 1.1406, 1.1560, 1.1484, 1.1796, 1.0857, 1.3909, 0.6169, 0.9573,\n",
      "        1.2189, 1.2815, 1.2810, 1.3050, 1.2190, 0.9847, 1.2267, 1.3050, 0.9690,\n",
      "        1.3049, 0.9024, 1.4219, 0.8948, 1.1175, 1.2345, 1.1017, 1.0862, 1.1015,\n",
      "        1.1561, 0.8635, 1.3049, 1.1330, 1.3284, 0.8318, 1.1487, 1.0393, 1.0545,\n",
      "        0.8712, 1.3517, 1.1878, 1.6018, 0.8320, 0.6682, 1.3591, 0.3044, 1.2654,\n",
      "        1.2267, 1.6721, 1.1797, 1.1247, 1.0784, 1.4217, 0.9299, 0.8674, 0.7150,\n",
      "        1.1722, 1.5003, 1.2112, 1.2029, 1.3362, 1.4690, 1.1327, 1.3126, 1.0393,\n",
      "        1.9997, 1.2264, 1.2265, 1.0466, 1.4299, 1.2346, 1.4847, 1.1875, 0.9727,\n",
      "        1.1408, 1.1643, 1.2654, 0.9339, 1.0076, 1.1173, 0.9689, 1.0939, 1.1018,\n",
      "        1.4768, 1.3831, 1.2187, 1.3909, 1.2502, 1.1872, 1.3751, 1.3831, 1.4451,\n",
      "        0.9101, 1.2421, 0.7810, 0.7850, 1.2815, 1.4065, 1.2503, 1.2500, 1.1170,\n",
      "        1.3830, 1.2033, 1.3279, 1.1721, 1.2345, 1.2109, 1.3284, 1.1642, 1.4919,\n",
      "        1.0780, 1.1565, 1.4143, 1.2268, 1.1565, 1.0705, 1.1331, 0.6722, 1.0080,\n",
      "        1.3825, 1.2109, 1.2735, 0.9532, 1.4686, 1.0628, 1.2971, 1.3908, 1.1560,\n",
      "        1.2972, 1.0471, 1.0158, 1.0311, 2.2659, 1.3206, 0.9338, 1.2659, 1.2112,\n",
      "        1.2814, 1.1720, 1.2186, 1.0471, 1.2267, 1.5862, 0.9378, 1.2576, 1.2654,\n",
      "        1.1955, 1.2185, 1.2893, 1.0154, 1.4844, 1.0003, 1.1873, 0.8595])\n",
      "\n",
      "Name: decoder.block.2.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[-0.0396,  0.0086,  0.0074,  ..., -0.0089, -0.0057, -0.0383],\n",
      "        [-0.0608, -0.0197,  0.0076,  ...,  0.0080, -0.0725,  0.0236],\n",
      "        [-0.0329, -0.0122, -0.0540,  ...,  0.0312,  0.0087, -0.0562],\n",
      "        ...,\n",
      "        [ 0.1633, -0.0392,  0.0129,  ...,  0.0262, -0.0686,  0.0633],\n",
      "        [ 0.0920,  0.0501, -0.0178,  ...,  0.0537,  0.0003, -0.0276],\n",
      "        [ 0.0281,  0.0316,  0.1180,  ..., -0.0568, -0.0383,  0.0281]])\n",
      "\n",
      "Name: decoder.block.2.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 8.8693e-01,  2.5212e-01, -2.5377e-01,  ...,  1.2278e-01,\n",
      "         -1.3748e-01,  1.3454e-01],\n",
      "        [-3.7465e-02, -1.3984e-01, -4.4156e-01,  ..., -5.4316e-01,\n",
      "         -8.5565e-01,  1.1405e+00],\n",
      "        [ 4.2639e-04,  1.1217e-02, -3.0642e-01,  ...,  3.4159e-01,\n",
      "          3.6743e-01,  4.4702e-01],\n",
      "        ...,\n",
      "        [ 1.1260e-03, -4.6486e-01, -1.9523e-01,  ...,  8.5790e-02,\n",
      "          7.6589e-01, -6.0953e-01],\n",
      "        [ 3.4153e-01,  1.7882e-01, -6.9919e-01,  ...,  1.0118e-01,\n",
      "         -4.8810e-01,  1.1098e-01],\n",
      "        [-1.2963e-01, -2.2665e-01, -4.2378e-01,  ..., -4.9008e-01,\n",
      "          3.6500e-01,  4.0248e-01]])\n",
      "\n",
      "Name: decoder.block.2.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[ 0.3225, -0.3868, -0.5936,  ..., -0.3533, -0.1847, -1.6799],\n",
      "        [ 0.6370, -1.1092, -0.0041,  ..., -0.5390,  0.0667,  0.9841],\n",
      "        [ 0.5977,  1.5081, -0.7889,  ..., -0.5547,  0.4256,  1.1721],\n",
      "        ...,\n",
      "        [ 1.1799, -0.2757,  0.1817,  ..., -1.5393,  1.2659, -0.1223],\n",
      "        [-0.4494,  0.5584,  0.9803,  ...,  0.3496, -0.2187, -0.1028],\n",
      "        [-1.1252,  0.1682,  0.2090,  ...,  0.2083,  0.2019,  0.3298]])\n",
      "\n",
      "Name: decoder.block.2.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-0.8357,  0.0944,  0.1662,  ...,  0.5544,  0.3304,  1.0310],\n",
      "        [-0.0753, -1.0626, -0.1278,  ...,  0.1433,  0.3792, -0.3108],\n",
      "        [-0.0131, -0.6761, -0.9333,  ...,  0.0038,  0.5862, -1.4300],\n",
      "        ...,\n",
      "        [ 0.4749, -0.6370,  0.4709,  ..., -0.2796,  0.3049, -1.8362],\n",
      "        [ 0.8635,  0.9612,  0.0705,  ..., -0.1960, -0.4515, -0.5896],\n",
      "        [-0.0998,  0.7497,  0.4007,  ..., -0.5198, -0.8630,  0.0563]])\n",
      "\n",
      "Name: decoder.block.2.layer.0.layer_norm.weight\n",
      "Weight: tensor([ 0.1238,  0.1799,  0.1159,  0.1941,  0.0676,  0.1595,  0.1697,  0.0880,\n",
      "         0.0739,  0.1624,  0.1673,  0.0700,  0.1521,  0.1736,  0.1028,  0.1208,\n",
      "         0.1462,  0.1419,  0.1521,  0.1442,  0.1380,  0.1247,  0.1882,  0.0581,\n",
      "         0.1622,  0.1190,  0.1760,  0.0882,  0.1545,  0.1726,  0.1514,  0.1019,\n",
      "         0.1897,  0.1532,  0.1369,  0.1009,  0.1634,  0.1589,  0.1765,  0.1132,\n",
      "         0.1491,  0.1609,  0.0794,  0.2073,  0.1550,  0.1301,  0.0427,  0.1326,\n",
      "         0.1614,  0.1491,  0.1638,  0.1628,  0.1292,  0.0730,  0.1028,  0.1735,\n",
      "         0.1424,  0.1520,  0.1492,  0.1008,  0.1775,  0.1230,  0.2042,  0.1623,\n",
      "         0.1618,  0.1599,  0.1565,  0.1798,  0.0778,  0.1745,  0.1873,  0.1345,\n",
      "         0.1463,  0.1425,  0.1516,  0.1309,  0.1751,  0.1209,  0.1296,  0.1054,\n",
      "         0.1238,  0.1697,  0.1483,  0.1541,  0.1350,  0.1174,  0.1360,  0.1164,\n",
      "         0.1599,  0.1787,  0.1267,  0.1238,  0.1009,  0.1599,  0.1120,  0.1755,\n",
      "         0.0390,  0.1233,  0.1882,  0.1331,  0.1867,  0.1550,  0.1179,  0.0957,\n",
      "         0.1560,  0.1531,  0.1329,  0.2024,  0.1720,  0.1170,  0.1668,  0.1804,\n",
      "         0.1511,  0.1765,  0.1722,  0.1643,  0.2109,  0.1768,  0.1218,  0.1472,\n",
      "         0.1413,  0.1551,  0.1661,  0.0988,  0.1495,  0.1247,  0.1575,  0.1540,\n",
      "         0.1435,  0.1794,  0.1477,  0.1589,  0.1551,  0.1286,  0.0989,  0.1663,\n",
      "         0.1581,  0.1125,  0.1199,  0.1521,  0.1316,  0.0767,  0.2005,  0.1367,\n",
      "         0.1755,  0.1300,  0.1553,  0.1233,  0.1677,  0.0302,  0.1463,  0.1553,\n",
      "         0.0899,  0.1565,  0.1296,  0.1524,  0.1561,  0.1184,  0.1550,  0.1374,\n",
      "         0.1473,  0.1667,  0.1340,  0.1160,  0.1364,  0.1809,  0.1331,  0.1329,\n",
      "         0.1504,  0.1399,  0.1165,  0.1736,  0.1130,  0.1565,  0.1769,  0.1296,\n",
      "         0.1047,  0.0933,  0.1448,  0.1638,  0.1443,  0.1731,  0.3044,  0.2147,\n",
      "         0.1077,  0.1462,  0.1492,  0.1580,  0.1428,  0.1670,  0.1272,  0.0965,\n",
      "         0.1516,  0.1478,  0.1475,  0.1638,  0.1434,  0.1698,  0.1300,  0.1669,\n",
      "         0.1595,  0.1390,  0.1573,  0.1409,  0.1770,  0.1286,  0.1853,  0.1702,\n",
      "         0.1970,  0.1624,  0.1827,  0.1790,  0.1364,  0.1360,  0.1657,  0.1648,\n",
      "         0.1780,  0.1120,  0.1481,  0.1457,  0.1667,  0.1355,  0.1398,  0.1590,\n",
      "         0.1193,  0.1458,  0.1130,  0.1413,  0.1775,  0.1554,  0.1600,  0.1374,\n",
      "         0.0598,  0.1193,  0.1546,  0.2063,  0.1814,  0.0832,  0.1374,  0.0466,\n",
      "         0.1108,  0.1306,  0.1157,  0.1448,  0.0926,  0.0346,  0.1804,  0.2151,\n",
      "         0.0979,  0.1599,  0.1380,  0.1565,  0.1670,  0.1355,  0.1522,  0.1497,\n",
      "         0.1945,  0.0852,  0.0947,  0.1482,  0.1406,  0.1609,  0.1687,  0.0974,\n",
      "         0.1960,  0.1712,  0.1463,  0.1570,  0.0900,  0.1149,  0.1380,  0.1893,\n",
      "         0.1374,  0.0534,  0.1609,  0.1042,  0.1700,  0.1735,  0.1454,  0.1277,\n",
      "         0.0798,  0.1218,  0.1738,  0.1589,  0.1613,  0.1502,  0.1622,  0.1722,\n",
      "         0.1584,  0.1517,  0.1257,  0.1731,  0.1389,  0.1444,  0.1765,  0.1184,\n",
      "         0.1896,  0.1613,  0.2048,  0.0862,  0.1838,  0.1573,  0.1643,  0.1770,\n",
      "         0.0739,  0.1648,  0.1282,  0.0749,  0.1375,  0.1062,  0.1838,  0.1417,\n",
      "         0.0993,  0.1570,  0.1543,  0.1348,  0.1409,  0.1563,  0.1047,  0.1349,\n",
      "         0.1466,  0.1600,  0.1799,  0.0852,  0.1091,  0.1638,  0.1397,  0.1818,\n",
      "         0.1866,  0.0916,  0.1458,  0.1790,  0.1257,  0.1748,  0.1443,  0.1512,\n",
      "         0.1355,  0.1829,  0.1247,  0.1907,  0.0817,  0.1248,  0.1697,  0.0961,\n",
      "         0.1394,  0.0813,  0.1495,  0.1203,  0.1067,  0.2146,  0.2054,  0.1312,\n",
      "         0.1403,  0.1473,  0.1358,  0.1184,  0.1164,  0.1756,  0.1223,  0.1608,\n",
      "         0.2009,  0.1541,  0.1452,  0.0820,  0.1632,  0.1233,  0.1609,  0.0358,\n",
      "         0.1223,  0.1595,  0.1622,  0.1712,  0.1651,  0.1468,  0.1325,  0.1679,\n",
      "         0.1643,  0.1192,  0.1592,  0.0876,  0.1896,  0.0764,  0.1550,  0.1594,\n",
      "         0.1516,  0.1506,  0.0871,  0.1497,  0.1164,  0.1628,  0.1550,  0.1570,\n",
      "         0.0681,  0.1643,  0.1052,  0.1394,  0.1199,  0.1335,  0.1546,  0.1980,\n",
      "         0.1062,  0.0726,  0.0862,  0.0327,  0.1417,  0.1289,  0.1911,  0.1574,\n",
      "         0.1394,  0.1345,  0.0949,  0.0911,  0.1164,  0.0910,  0.1525,  0.1826,\n",
      "         0.1429,  0.0764,  0.1629,  0.1819,  0.1661,  0.1629,  0.1408,  0.1159,\n",
      "         0.1766,  0.1599,  0.1448,  0.1804,  0.1575,  0.2058,  0.1445,  0.1174,\n",
      "         0.1399,  0.1540,  0.1533,  0.1325,  0.1379,  0.1462,  0.1262,  0.1467,\n",
      "         0.1497,  0.1823,  0.1741,  0.1570,  0.1921,  0.1522,  0.1575,  0.1672,\n",
      "         0.1817,  0.1878,  0.1330,  0.1661,  0.0798,  0.0847,  0.1804,  0.1853,\n",
      "         0.1603,  0.1692,  0.1390,  0.1660,  0.1435,  0.1003,  0.1516,  0.1580,\n",
      "         0.1614,  0.1673,  0.1307,  0.0915,  0.1228,  0.1521,  0.1872,  0.1399,\n",
      "         0.1407,  0.1687,  0.1502,  0.0954,  0.1536,  0.0500,  0.1756,  0.1120,\n",
      "         0.1302,  0.1777,  0.1346,  0.1614,  0.1653,  0.1504,  0.1696,  0.1399,\n",
      "         0.1405,  0.1406,  0.0819,  0.1722,  0.1579,  0.1472,  0.1653,  0.1777,\n",
      "         0.1526, -0.0866,  0.1278,  0.1600,  0.2091,  0.0769,  0.1594,  0.1580,\n",
      "         0.1475,  0.1858,  0.1565,  0.0984,  0.1970,  0.1482,  0.1946,  0.0930])\n",
      "\n",
      "Name: decoder.block.2.layer.1.EncDecAttention.q.weight\n",
      "Weight: tensor([[ 0.0236,  0.0080,  0.0249,  ...,  0.1181,  0.0744,  0.0176],\n",
      "        [-0.0181,  0.0215,  0.0215,  ..., -0.0103, -0.0623,  0.0535],\n",
      "        [ 0.1034,  0.0083, -0.0393,  ..., -0.0162,  0.0882, -0.0092],\n",
      "        ...,\n",
      "        [ 0.1096,  0.0534, -0.0393,  ..., -0.0921,  0.0368, -0.0155],\n",
      "        [ 0.0740,  0.1808, -0.0633,  ..., -0.0705,  0.0237, -0.1319],\n",
      "        [-0.0134, -0.0789,  0.0043,  ..., -0.0647, -0.1246, -0.0033]])\n",
      "\n",
      "Name: decoder.block.2.layer.1.EncDecAttention.k.weight\n",
      "Weight: tensor([[ 9.6588e-02, -2.5416e-01, -3.5131e-01,  ..., -2.9286e-01,\n",
      "         -1.0898e-01, -4.6264e-01],\n",
      "        [ 9.0599e-02,  5.0389e-01, -4.9418e-01,  ..., -6.3803e-02,\n",
      "         -5.4147e-05, -7.4200e-01],\n",
      "        [ 2.3152e-01,  5.1198e-01,  4.4507e-01,  ...,  3.0455e-01,\n",
      "          1.4251e-01, -1.8667e-02],\n",
      "        ...,\n",
      "        [-4.2759e-01,  3.3997e-01, -7.0238e-02,  ..., -2.6151e-01,\n",
      "         -4.4357e-01, -1.3102e-01],\n",
      "        [ 2.2479e-01, -1.0670e-01, -6.6368e-02,  ...,  2.2869e-01,\n",
      "         -6.6036e-01,  4.4167e-01],\n",
      "        [-4.4354e-01,  2.3736e-02, -3.7299e-01,  ..., -4.4988e-02,\n",
      "          1.5509e-01, -3.4948e-02]])\n",
      "\n",
      "Name: decoder.block.2.layer.1.EncDecAttention.v.weight\n",
      "Weight: tensor([[-0.4196,  0.9495,  0.5466,  ..., -1.0388,  0.3670, -0.1082],\n",
      "        [-0.3884, -1.1794, -1.3362,  ..., -1.1872,  0.5544,  0.6136],\n",
      "        [ 1.7263, -1.1565,  0.7385,  ...,  0.4177, -1.9295, -0.7971],\n",
      "        ...,\n",
      "        [-0.5313,  0.1927, -0.2023,  ..., -0.7302, -1.2737,  0.4553],\n",
      "        [ 0.7577, -1.3591,  0.2597,  ...,  0.5354, -0.1613,  1.5628],\n",
      "        [ 0.9685,  0.7341, -0.8282,  ...,  0.7226, -0.7228,  0.4411]])\n",
      "\n",
      "Name: decoder.block.2.layer.1.EncDecAttention.o.weight\n",
      "Weight: tensor([[ 0.1702, -1.6325, -0.5276,  ..., -0.2093, -1.3831, -0.0268],\n",
      "        [ 0.5823, -0.6560, -2.0471,  ...,  0.8161,  0.1267, -0.3459],\n",
      "        [-0.2497, -0.6091,  0.4841,  ...,  0.9333, -0.9886,  0.3454],\n",
      "        ...,\n",
      "        [-0.2849,  1.0706,  0.3083,  ..., -0.2737,  0.8161, -0.1741],\n",
      "        [-0.4085, -0.2815, -0.3200,  ..., -0.2731, -0.1560, -0.1980],\n",
      "        [ 0.3362,  0.3851,  0.1530,  ..., -1.0081, -0.5511,  0.7302]])\n",
      "\n",
      "Name: decoder.block.2.layer.1.layer_norm.weight\n",
      "Weight: tensor([ 0.0772,  0.1159,  0.0729,  0.1111,  0.0490,  0.0916,  0.0975, -0.0701,\n",
      "         0.0686,  0.0871,  0.0891,  0.0396,  0.0904,  0.0980,  0.0691,  0.0837,\n",
      "         0.0875,  0.0832,  0.0910,  0.0894,  0.0793,  0.0788,  0.0969,  0.0362,\n",
      "         0.0974,  0.0764,  0.0960,  0.0572,  0.0925,  0.1018,  0.0829,  0.0666,\n",
      "         0.1106,  0.0837,  0.0847,  0.0664,  0.0878,  0.0832,  0.1113,  0.0744,\n",
      "         0.0806,  0.0891,  0.0750,  0.1110,  0.0886,  0.0774,  0.0295,  0.0778,\n",
      "         0.0857,  0.0859,  0.0989,  0.0965,  0.0808,  0.0442,  0.0710,  0.1019,\n",
      "         0.0841,  0.0993,  0.0828,  0.0804,  0.1102,  0.0742,  0.1121,  0.0955,\n",
      "         0.1129,  0.0916,  0.0842,  0.1015,  0.0638,  0.1064,  0.1155,  0.0752,\n",
      "         0.0893,  0.0910,  0.0817,  0.0915,  0.1043,  0.0715,  0.0784,  0.0676,\n",
      "         0.0832,  0.1032,  0.0847,  0.1018,  0.0783,  0.0794,  0.0799,  0.0664,\n",
      "         0.0949,  0.0750,  0.0720,  0.0798,  0.0715,  0.1003,  0.0804,  0.0951,\n",
      "         0.1214,  0.0718,  0.1189,  0.0730,  0.0989,  0.0901,  0.0745,  0.0788,\n",
      "         0.0896,  0.0868,  0.0744,  0.1150,  0.0979,  0.0758,  0.1033,  0.1038,\n",
      "         0.0950,  0.1050,  0.0984,  0.1043,  0.1145,  0.1121,  0.0766,  0.0776,\n",
      "         0.0762,  0.0833,  0.0900,  0.0745,  0.0803,  0.0955,  0.1018,  0.0891,\n",
      "         0.1008,  0.1043,  0.0827,  0.0958,  0.0935,  0.0710,  0.0716,  0.0996,\n",
      "         0.0854,  0.1175,  0.0746,  0.0891,  0.0819,  0.0642,  0.1167,  0.0807,\n",
      "         0.1042,  0.0768,  0.1096,  0.0960,  0.1029,  0.0340,  0.0856,  0.1021,\n",
      "         0.0725,  0.0832,  0.0708,  0.0865,  0.0904,  0.0856,  0.1047,  0.1331,\n",
      "         0.0961,  0.0984,  0.0765,  0.0740,  0.0901,  0.1136,  0.0828,  0.0769,\n",
      "         0.0897,  0.0812,  0.0695,  0.1247,  0.0794,  0.1043,  0.1048,  0.0784,\n",
      "         0.0896,  0.0628,  0.0876,  0.0954,  0.0849,  0.1111,  0.1571,  0.1375,\n",
      "         0.0833,  0.0803,  0.0861,  0.0927,  0.0892,  0.0955,  0.0911,  0.0720,\n",
      "         0.0862,  0.0827,  0.0871,  0.1038,  0.0781,  0.0917,  0.0778,  0.0968,\n",
      "         0.0925,  0.0849,  0.0989,  0.0881,  0.0964,  0.0797,  0.2581,  0.1024,\n",
      "         0.1100,  0.0868,  0.0954,  0.1091,  0.0867,  0.0706,  0.0954,  0.0975,\n",
      "         0.1003,  0.0770,  0.0926,  0.0776,  0.0933,  0.0827,  0.0813,  0.1008,\n",
      "         0.0901,  0.0847,  0.0804,  0.0910,  0.1125,  0.0876,  0.0847,  0.0877,\n",
      "         0.0511,  0.0735,  0.1148,  0.1243,  0.1174,  0.0448,  0.0872,  0.0701,\n",
      "         0.0686,  0.0842,  0.0838,  0.0724,  0.0737, -0.0555,  0.0964,  0.1135,\n",
      "         0.0716,  0.0891,  0.0841,  0.1033,  0.1007,  0.0788,  0.0881,  0.0867,\n",
      "         0.1279,  0.0745,  0.0532,  0.0906,  0.0910,  0.0931,  0.1018,  0.0569,\n",
      "         0.1060,  0.1003,  0.0843,  0.0954,  0.0677,  0.0668,  0.0867,  0.0930,\n",
      "         0.0784,  0.0413,  0.0916,  0.0711,  0.0890,  0.0920,  0.0940,  0.0803,\n",
      "         0.0633,  0.0657,  0.1023,  0.0909,  0.0945,  0.0842,  0.0965,  0.1085,\n",
      "         0.0926,  0.0862,  0.0647,  0.0933,  0.0882,  0.0818,  0.1062,  0.0913,\n",
      "         0.1194,  0.0999,  0.1135,  0.0647,  0.1028,  0.0798,  0.0871,  0.0984,\n",
      "         0.0526,  0.0940,  0.0769,  0.0478,  0.0853,  0.1063,  0.1135,  0.0826,\n",
      "         0.1292,  0.0984,  0.0887,  0.0804,  0.0798,  0.0943,  0.0667,  0.0872,\n",
      "         0.0813,  0.1023,  0.0993,  0.0730,  0.1312,  0.0994,  0.0799,  0.1057,\n",
      "         0.1013,  0.0735,  0.0867,  0.0975,  0.0813,  0.1019,  0.0778,  0.0951,\n",
      "         0.0853,  0.1042,  0.0735,  0.1149,  0.0601,  0.0836,  0.1047,  0.0575,\n",
      "         0.0818,  0.0559,  0.0906,  0.0788,  0.0665,  0.1211,  0.1175,  0.0715,\n",
      "         0.0862,  0.0925,  0.0905,  0.0817,  0.0666,  0.1047,  0.0808,  0.0993,\n",
      "         0.1208,  0.0798,  0.0940,  0.0681,  0.0925,  0.0823,  0.0872,  0.0379,\n",
      "         0.0798,  0.0866,  0.0955,  0.1047,  0.1101,  0.0866,  0.0988,  0.0999,\n",
      "         0.1059,  0.0744,  0.1072,  0.0582,  0.1142,  0.1136,  0.0912,  0.0876,\n",
      "         0.0936,  0.0880,  0.0755,  0.0873,  0.0722,  0.0940,  0.0891,  0.0880,\n",
      "         0.0784,  0.0944,  0.0788,  0.0950,  0.0740,  0.0793,  0.0921,  0.1204,\n",
      "         0.0730,  0.0532,  0.0696,  0.0304,  0.0794,  0.0873,  0.1058,  0.0853,\n",
      "         0.0803,  0.0867,  0.0745,  0.0534,  0.0774,  0.0590,  0.0911,  0.1053,\n",
      "         0.0837,  0.0591,  0.0983,  0.1004,  0.0951,  0.1008,  0.0820,  0.1004,\n",
      "         0.0940,  0.1038,  0.0867,  0.1145,  0.0910,  0.1218,  0.0813,  0.0711,\n",
      "         0.0823,  0.0988,  0.0926,  0.0754,  0.0749,  0.0867,  0.0700,  0.0862,\n",
      "         0.1028,  0.1091,  0.1027,  0.0945,  0.1078,  0.0881,  0.0970,  0.0921,\n",
      "         0.1002,  0.1121,  0.0730,  0.0954,  0.0383,  0.0564,  0.1081,  0.1021,\n",
      "         0.0970,  0.0980,  0.0750,  0.0934,  0.0842,  0.0576,  0.0837,  0.0939,\n",
      "         0.0910,  0.0930,  0.0848,  0.0964,  0.0745,  0.0798,  0.0945,  0.0881,\n",
      "         0.0930,  0.0974,  0.0863,  0.1063,  0.0910,  0.0862,  0.1044,  0.0973,\n",
      "         0.0814,  0.1100,  0.0862,  0.0886,  0.0954,  0.0960,  0.0902,  0.0881,\n",
      "         0.0848,  0.0759,  0.0404,  0.0959,  0.0876,  0.0899,  0.1014,  0.0989,\n",
      "         0.0852,  0.0789,  0.0829,  0.0901,  0.1240,  0.0599,  0.0900,  0.0935,\n",
      "         0.0919,  0.1004,  0.0811,  0.0760,  0.1169,  0.0823,  0.1062,  0.0494])\n",
      "\n",
      "Name: decoder.block.2.layer.2.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-0.4904, -0.1903, -0.3709,  ...,  0.3477,  0.1476, -0.0301],\n",
      "        [ 0.6484,  0.1503,  0.1195,  ...,  1.2811, -0.6056,  0.8554],\n",
      "        [-0.4023, -0.1670, -1.8907,  ..., -1.0547, -1.2500,  0.7617],\n",
      "        ...,\n",
      "        [-1.0078, -0.5392, -0.3222,  ..., -0.4238, -0.0670, -0.2276],\n",
      "        [-0.4510, -1.1408, -0.8399,  ..., -0.2732, -0.1935,  0.2712],\n",
      "        [ 0.3594, -0.3047,  0.6836,  ..., -0.1718, -1.9921, -0.2109]])\n",
      "\n",
      "Name: decoder.block.2.layer.2.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.0771, -0.3143, -0.0273,  ...,  0.7072, -0.4549, -0.3808],\n",
      "        [-0.3299, -0.9334, -0.1067,  ..., -0.2303,  0.0186, -0.1298],\n",
      "        [-0.1405, -0.7888, -0.2469,  ...,  0.2619,  0.0882, -0.8710],\n",
      "        ...,\n",
      "        [ 0.0292, -0.2021, -0.6639,  ...,  0.7384,  0.1815, -0.1523],\n",
      "        [ 0.0542,  0.1083,  0.2081,  ...,  0.0946,  0.0842, -0.4961],\n",
      "        [ 0.0359,  0.5978, -0.1815,  ...,  0.2198,  0.3106, -0.1650]])\n",
      "\n",
      "Name: decoder.block.2.layer.2.layer_norm.weight\n",
      "Weight: tensor([1.2815, 1.4063, 1.4768, 1.7737, 0.4651, 1.3828, 1.5315, 1.5935, 1.7185,\n",
      "        1.6253, 1.4925, 1.2268, 1.4925, 1.5940, 1.7815, 1.4611, 1.3753, 1.3828,\n",
      "        1.4456, 1.4531, 1.2581, 1.2659, 1.5388, 0.8593, 1.6175, 1.1643, 1.4456,\n",
      "        1.2653, 1.4143, 1.6331, 1.4846, 1.1328, 1.8596, 1.5315, 1.5236, 1.4060,\n",
      "        1.4456, 1.5003, 1.5549, 1.1795, 1.4144, 1.5081, 0.8245, 1.7187, 1.5936,\n",
      "        1.1565, 0.5857, 1.2893, 1.4143, 1.4378, 1.3518, 1.5627, 1.3046, 1.6486,\n",
      "        1.2269, 1.4143, 1.3674, 1.4534, 1.3831, 1.3669, 1.8439, 1.2891, 1.5080,\n",
      "        1.4768, 1.7891, 1.4378, 1.4060, 1.7424, 1.5154, 1.4925, 1.6253, 1.2971,\n",
      "        1.4143, 1.4300, 1.5003, 1.4456, 1.6799, 1.1643, 1.3597, 1.1722, 1.2892,\n",
      "        1.6954, 1.3831, 1.3674, 1.4300, 1.3513, 1.4143, 1.1794, 1.4300, 0.9610,\n",
      "        1.2737, 1.2971, 1.4534, 1.4534, 1.4529, 1.5940, 2.1560, 1.3440, 1.9222,\n",
      "        1.2893, 1.7112, 1.5862, 1.2033, 1.2112, 1.4216, 1.4690, 1.2346, 1.6327,\n",
      "        1.5549, 1.2581, 1.5159, 1.4533, 1.4220, 1.6487, 1.5938, 1.5394, 2.0003,\n",
      "        1.4690, 1.3045, 1.3987, 1.3362, 1.4764, 1.6799, 1.2732, 1.4060, 2.0935,\n",
      "        1.4925, 1.4999, 1.4378, 1.5627, 1.4222, 1.4532, 1.6407, 1.2579, 1.3674,\n",
      "        1.5781, 1.4455, 1.0544, 1.1718, 1.3986, 1.3050, 1.5550, 1.6643, 1.3206,\n",
      "        1.6173, 1.4220, 1.3907, 1.8122, 1.4768, 0.3806, 1.3987, 1.4923, 1.3357,\n",
      "        1.5627, 1.2658, 1.5002, 1.4612, 1.1093, 1.3201, 2.7185, 1.4297, 1.4065,\n",
      "        1.2893, 1.1175, 1.5394, 1.6019, 1.3284, 1.4296, 1.4846, 1.4533, 1.2111,\n",
      "        1.6171, 1.3283, 1.6169, 1.7581, 1.2893, 1.5937, 1.1094, 1.4612, 1.5783,\n",
      "        1.5393, 1.5468, 1.1096, 1.4296, 1.7263, 1.3831, 1.4456, 1.5393, 1.4534,\n",
      "        1.4455, 1.6716, 1.1092, 1.4456, 1.4063, 1.3513, 1.5784, 1.3128, 1.5628,\n",
      "        1.3048, 1.4924, 1.4534, 1.5315, 1.6956, 1.2733, 1.5548, 1.2971, 1.4216,\n",
      "        1.4220, 1.8357, 1.5703, 1.6331, 1.6404, 1.4533, 0.7458, 1.5466, 1.6172,\n",
      "        1.5706, 1.2893, 1.3126, 1.3206, 1.4534, 1.3518, 1.3987, 1.3987, 1.2264,\n",
      "        1.4690, 1.5700, 1.5003, 1.5471, 1.4142, 1.4063, 1.4378, 1.3669, 1.3284,\n",
      "        1.3908, 1.9533, 1.6327, 1.3747, 1.2734, 1.7341, 1.1249, 1.4846, 1.2267,\n",
      "        1.4455, 1.9530, 1.5700, 1.5315, 1.9376, 0.9255, 1.3909, 1.3752, 1.5622,\n",
      "        1.5079, 1.2263, 1.3831, 1.3284, 1.5549, 1.5388, 1.2502, 1.4065, 1.3440,\n",
      "        1.4925, 1.5783, 1.2346, 1.7263, 1.6251, 1.4141, 1.3986, 1.6403, 1.1169,\n",
      "        1.1873, 1.4456, 1.4300, 1.3903, 1.4143, 2.0003, 1.5939, 1.7425, 1.4221,\n",
      "        1.2346, 1.4060, 1.1878, 1.8753, 1.4065, 1.5003, 1.3987, 1.3596, 1.4295,\n",
      "        1.5159, 1.3591, 1.2894, 1.6330, 1.3674, 1.4300, 1.4065, 1.1643, 1.7811,\n",
      "        1.5315, 1.7112, 1.5236, 1.5628, 1.4534, 0.8513, 1.6878, 1.1409, 1.4300,\n",
      "        1.3050, 1.3206, 1.4300, 1.9919, 1.8205, 1.3517, 1.2737, 1.3280, 1.2889,\n",
      "        1.3518, 1.4529, 1.4612, 1.3204, 1.4456, 1.3908, 1.6565, 1.9065, 2.2966,\n",
      "        3.0935, 1.6329, 1.3440, 2.0784, 1.7424, 1.6169, 1.3905, 1.6092, 1.1719,\n",
      "        1.7268, 1.3673, 1.4300, 1.4612, 1.4534, 1.1956, 1.7343, 1.4296, 1.3440,\n",
      "        1.5940, 1.2112, 1.3753, 1.1331, 1.4143, 1.1878, 1.0315, 1.9378, 1.5706,\n",
      "        1.3206, 1.3669, 1.4769, 1.3831, 1.3753, 1.1721, 1.5940, 1.2345, 1.3987,\n",
      "        1.7190, 1.3831, 1.3592, 1.6013, 1.4451, 1.3435, 1.6487, 0.6560, 1.2893,\n",
      "        1.5003, 1.5001, 1.4920, 1.3909, 1.4456, 1.4685, 1.5628, 1.4300, 1.2581,\n",
      "        1.6800, 1.5081, 1.6485, 1.3669, 1.4060, 1.4922, 1.3440, 1.4300, 1.6247,\n",
      "        1.5313, 1.1878, 1.5237, 1.3518, 1.5156, 1.1481, 1.4218, 1.3201, 1.2971,\n",
      "        1.2425, 1.5935, 1.4607, 1.8127, 1.1564, 1.0159, 1.6091, 0.3103, 1.4690,\n",
      "        1.3436, 1.7815, 1.4847, 1.4222, 1.3675, 1.6403, 1.2581, 1.2502, 1.0857,\n",
      "        1.4218, 1.7424, 1.4143, 1.8201, 1.6096, 1.6956, 1.3904, 1.5705, 1.3122,\n",
      "        1.9372, 1.4612, 1.5627, 1.3830, 1.4846, 1.5628, 1.5623, 1.5080, 1.2419,\n",
      "        1.4690, 1.5003, 1.5390, 1.2889, 1.3124, 1.4221, 1.2346, 1.3206, 1.3128,\n",
      "        1.6721, 1.5861, 1.5392, 1.6875, 1.4765, 1.5081, 1.5549, 1.7107, 1.6955,\n",
      "        1.2581, 1.4299, 1.2966, 1.1800, 1.5627, 1.7503, 1.6252, 1.5391, 1.4378,\n",
      "        1.7503, 1.4377, 1.8044, 1.4455, 1.4763, 1.5157, 1.5315, 1.3128, 1.6717,\n",
      "        1.2266, 1.4690, 1.6169, 1.4925, 1.3048, 1.2659, 1.4377, 0.9963, 1.3362,\n",
      "        1.9216, 1.5627, 1.5155, 1.2190, 1.7111, 1.2893, 1.6018, 1.7190, 1.4690,\n",
      "        1.4376, 1.3362, 1.3127, 1.3206, 0.4671, 1.6175, 1.2576, 1.4845, 1.5862,\n",
      "        1.5706, 1.5550, 1.5781, 1.2737, 1.5549, 1.9533, 1.5310, 1.3982, 1.4924,\n",
      "        1.5472, 1.5159, 1.4612, 1.2503, 1.5940, 1.2347, 1.4920, 1.3122])\n",
      "\n",
      "Name: decoder.block.3.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[ 2.2496e-02,  6.0511e-02,  2.8621e-05,  ...,  3.9534e-02,\n",
      "          3.3907e-02, -1.3628e-03],\n",
      "        [ 6.5169e-02,  9.6882e-02, -1.3410e-02,  ..., -6.2196e-03,\n",
      "          2.5135e-02,  5.6184e-02],\n",
      "        [ 2.5521e-02,  4.2194e-02,  3.4630e-02,  ...,  8.9606e-02,\n",
      "          1.2180e-01, -1.6078e-02],\n",
      "        ...,\n",
      "        [ 3.8006e-02, -5.9849e-02,  1.0783e-02,  ..., -2.3481e-02,\n",
      "         -4.7713e-03, -9.2048e-02],\n",
      "        [ 4.5583e-02,  4.4715e-02,  2.7279e-03,  ..., -2.4411e-02,\n",
      "          5.5938e-02,  6.7632e-02],\n",
      "        [ 1.6300e-02, -2.6669e-02, -6.3889e-02,  ..., -4.5297e-02,\n",
      "          3.7788e-02,  9.0765e-02]])\n",
      "\n",
      "Name: decoder.block.3.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[-0.4568,  0.8868,  0.2073,  ...,  0.0181,  0.9299,  0.7888],\n",
      "        [ 0.6213, -0.1104,  0.1839,  ...,  0.2737,  0.3849,  0.2556],\n",
      "        [-0.3631,  0.4883,  0.6409,  ..., -0.9685,  0.8518, -0.3753],\n",
      "        ...,\n",
      "        [-0.4902, -0.1257,  0.5627,  ..., -0.3555,  0.7226,  0.0947],\n",
      "        [-0.6799, -0.2829, -0.3183,  ...,  0.0868, -0.4963,  0.1149],\n",
      "        [ 0.1652,  0.3025,  0.4433,  ..., -1.1797, -0.0472,  0.0328]])\n",
      "\n",
      "Name: decoder.block.3.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[-1.4607, -0.0520, -0.5705,  ..., -0.1121, -1.2971,  0.0681],\n",
      "        [ 0.2366,  0.2080, -1.1325,  ..., -0.9138, -0.7499, -0.9534],\n",
      "        [-0.1428,  0.4412, -0.0667,  ..., -1.1175,  0.4060, -0.4372],\n",
      "        ...,\n",
      "        [ 0.1672, -0.8909, -0.0931,  ...,  2.7654,  0.1033,  0.6175],\n",
      "        [-0.5036,  0.0546, -0.2317,  ..., -1.8596,  0.2830,  0.3597],\n",
      "        [-0.7932, -0.3669, -1.2575,  ...,  0.4065, -0.5349,  1.1794]])\n",
      "\n",
      "Name: decoder.block.3.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-0.2366,  1.3436,  0.3850,  ...,  0.9099, -0.5511,  0.7497],\n",
      "        [ 0.7930,  0.3831,  0.4006,  ..., -1.1169,  0.9026, -1.4607],\n",
      "        [-0.3343,  0.0764, -0.4708,  ..., -1.1956, -0.8440, -1.1331],\n",
      "        ...,\n",
      "        [-0.5628, -0.1624,  0.1521,  ...,  1.4919, -1.9456,  0.5349],\n",
      "        [ 0.8044,  1.4531, -1.0157,  ..., -0.1573,  0.6169, -0.7073],\n",
      "        [ 0.4377, -0.4509,  0.8440,  ...,  0.4632,  0.5392,  0.0168]])\n",
      "\n",
      "Name: decoder.block.3.layer.0.layer_norm.weight\n",
      "Weight: tensor([ 0.1384,  0.1673,  0.1374,  0.1994,  0.0964,  0.1634,  0.1813,  0.1120,\n",
      "         0.0847,  0.1643,  0.1633,  0.0867,  0.1628,  0.1770,  0.1158,  0.1336,\n",
      "         0.1585,  0.1595,  0.1663,  0.1599,  0.1477,  0.1423,  0.1692,  0.0759,\n",
      "         0.1770,  0.1297,  0.1683,  0.1096,  0.1653,  0.1886,  0.1702,  0.1097,\n",
      "         0.1966,  0.1692,  0.1560,  0.1180,  0.1760,  0.1770,  0.1692,  0.1258,\n",
      "         0.1604,  0.1768,  0.1038,  0.2053,  0.1668,  0.1388,  0.0563,  0.1358,\n",
      "         0.1668,  0.1643,  0.1805,  0.1690,  0.1453,  0.0954,  0.1165,  0.1677,\n",
      "         0.1535,  0.1595,  0.1536,  0.1189,  0.2019,  0.1331,  0.2087,  0.1575,\n",
      "         0.1692,  0.1648,  0.1632,  0.1849,  0.1032,  0.1794,  0.1927,  0.1467,\n",
      "         0.1572,  0.1604,  0.1575,  0.1472,  0.1903,  0.1300,  0.1403,  0.1319,\n",
      "         0.1390,  0.1677,  0.1605,  0.1677,  0.1437,  0.1247,  0.1455,  0.1292,\n",
      "         0.1677,  0.1585,  0.1419,  0.1423,  0.1233,  0.1629,  0.1364,  0.1805,\n",
      "         0.0496,  0.1507,  0.2448,  0.1355,  0.1875,  0.1784,  0.1311,  0.1126,\n",
      "         0.1761,  0.1672,  0.1472,  0.1980,  0.1771,  0.1279,  0.1823,  0.1780,\n",
      "         0.1692,  0.1838,  0.1800,  0.1682,  0.2219,  0.1853,  0.1321,  0.1614,\n",
      "         0.1555,  0.1701,  0.1849,  0.1072,  0.1565,  0.2409,  0.1837,  0.1599,\n",
      "         0.1570,  0.1716,  0.1442,  0.1709,  0.1570,  0.1418,  0.1194,  0.1621,\n",
      "         0.1638,  0.1374,  0.1350,  0.1712,  0.1448,  0.0954,  0.2014,  0.1560,\n",
      "         0.1804,  0.1438,  0.1726,  0.1472,  0.1716,  0.0344,  0.1614,  0.1737,\n",
      "         0.1145,  0.1771,  0.1462,  0.1751,  0.1692,  0.1466,  0.1507,  0.1999,\n",
      "         0.1533,  0.1673,  0.1468,  0.1223,  0.1491,  0.1921,  0.1399,  0.1408,\n",
      "         0.1718,  0.1487,  0.1291,  0.1751,  0.1251,  0.1712,  0.1883,  0.1493,\n",
      "         0.1311,  0.1012,  0.1700,  0.1827,  0.1691,  0.1936,  0.3792,  0.2013,\n",
      "         0.1622,  0.1565,  0.1716,  0.1687,  0.1561,  0.1770,  0.1486,  0.1141,\n",
      "         0.1761,  0.1517,  0.1497,  0.1788,  0.1574,  0.1738,  0.1477,  0.1769,\n",
      "         0.1644,  0.1555,  0.1692,  0.1390,  0.1927,  0.1389,  0.2771,  0.1741,\n",
      "         0.2088,  0.1702,  0.1868,  0.1936,  0.1491,  0.0916,  0.1731,  0.1746,\n",
      "         0.1849,  0.1310,  0.1540,  0.1487,  0.1800,  0.1403,  0.1512,  0.1897,\n",
      "         0.1286,  0.1624,  0.1413,  0.1672,  0.1857,  0.1565,  0.1634,  0.1614,\n",
      "         0.0701,  0.1286,  0.1399,  0.2127,  0.1945,  0.0876,  0.1564,  0.0586,\n",
      "         0.1282,  0.1462,  0.1374,  0.1653,  0.1101,  0.0393,  0.1780,  0.2170,\n",
      "         0.1101,  0.1570,  0.1555,  0.1663,  0.1775,  0.1526,  0.1526,  0.1614,\n",
      "         0.1960,  0.1007,  0.1145,  0.1579,  0.1634,  0.1677,  0.1878,  0.1189,\n",
      "         0.1963,  0.1795,  0.1515,  0.1673,  0.1108,  0.1248,  0.1507,  0.1737,\n",
      "         0.1409,  0.0764,  0.1756,  0.1229,  0.1845,  0.1853,  0.1565,  0.1360,\n",
      "         0.1037,  0.1225,  0.1887,  0.1594,  0.1798,  0.1599,  0.1585,  0.1768,\n",
      "         0.1673,  0.1614,  0.1272,  0.1878,  0.1546,  0.1453,  0.1745,  0.1331,\n",
      "         0.2034,  0.1731,  0.2093,  0.1141,  0.1824,  0.1550,  0.1057,  0.1848,\n",
      "         0.0911,  0.1691,  0.1487,  0.0949,  0.1170,  0.1286,  0.2052,  0.1595,\n",
      "         0.1364,  0.1604,  0.1624,  0.1433,  0.1692,  0.1614,  0.1208,  0.1423,\n",
      "         0.1614,  0.1780,  0.2054,  0.1155,  0.1735,  0.1806,  0.1444,  0.2030,\n",
      "         0.2048, -0.1038,  0.1536,  0.1810,  0.1326,  0.1814,  0.1585,  0.1599,\n",
      "         0.1579,  0.1749,  0.1423,  0.2034,  0.1037,  0.1260,  0.1946,  0.1057,\n",
      "         0.1608,  0.0999,  0.1565,  0.1331,  0.1146,  0.2293,  0.2112,  0.1418,\n",
      "         0.1546,  0.1579,  0.1345,  0.1515,  0.1258,  0.1888,  0.1404,  0.1632,\n",
      "         0.2034,  0.1631,  0.1609,  0.1022,  0.1759,  0.1316,  0.1819,  0.0534,\n",
      "         0.1306,  0.1731,  0.1593,  0.1731,  0.1667,  0.1556,  0.1419,  0.1828,\n",
      "         0.1619,  0.1350,  0.1775,  0.1086,  0.2024,  0.0998,  0.1687,  0.1721,\n",
      "         0.1555,  0.1683,  0.0978,  0.1614,  0.1286,  0.1726,  0.1683,  0.1650,\n",
      "         0.0789,  0.1673,  0.1306,  0.1565,  0.1345,  0.1370,  0.1517,  0.1945,\n",
      "         0.1199,  0.0945,  0.1018,  0.0393,  0.1511,  0.1351,  0.1897,  0.1729,\n",
      "         0.1556,  0.1472,  0.1221,  0.1142,  0.1388,  0.1126,  0.1648,  0.1878,\n",
      "         0.1418,  0.0998,  0.1804,  0.1897,  0.1756,  0.1717,  0.1526,  0.1316,\n",
      "         0.1823,  0.1745,  0.1604,  0.1780,  0.1683,  0.2005,  0.1687,  0.1282,\n",
      "         0.1595,  0.1751,  0.1585,  0.1507,  0.1436,  0.1634,  0.1340,  0.1505,\n",
      "         0.1687,  0.1862,  0.1765,  0.1702,  0.2000,  0.1662,  0.1560,  0.1663,\n",
      "         0.1956,  0.2092,  0.1497,  0.1642,  0.1111,  0.1043,  0.1833,  0.1922,\n",
      "         0.1663,  0.1775,  0.1560,  0.1838,  0.1476,  0.1330,  0.1624,  0.1643,\n",
      "         0.1722,  0.1726,  0.1487,  0.0999,  0.1292,  0.1610,  0.1868,  0.1580,\n",
      "         0.1533,  0.1670,  0.1599,  0.1364,  0.1658,  0.0618,  0.1905,  0.1180,\n",
      "         0.1350,  0.1829,  0.1408,  0.1682,  0.1888,  0.1589,  0.1780,  0.1501,\n",
      "         0.1506,  0.1541,  0.0627,  0.1833,  0.1784,  0.1526,  0.1823,  0.1735,\n",
      "         0.1667,  0.1189,  0.1443,  0.1736,  0.2138,  0.1003,  0.1448,  0.1690,\n",
      "         0.1589,  0.1849,  0.1629,  0.1126,  0.1751,  0.1572,  0.2751,  0.1042])\n",
      "\n",
      "Name: decoder.block.3.layer.1.EncDecAttention.q.weight\n",
      "Weight: tensor([[-0.0533,  0.0725,  0.0069,  ..., -0.0109,  0.0759, -0.0001],\n",
      "        [-0.0462, -0.0886,  0.0089,  ...,  0.0422, -0.0296, -0.0703],\n",
      "        [ 0.0127, -0.0754,  0.0399,  ..., -0.0217,  0.0137,  0.0251],\n",
      "        ...,\n",
      "        [ 0.0360,  0.0123, -0.0648,  ...,  0.0452, -0.0182, -0.0191],\n",
      "        [-0.0935,  0.0764,  0.0029,  ...,  0.0262, -0.0369, -0.0576],\n",
      "        [-0.0138, -0.0170, -0.0429,  ..., -0.0009, -0.0579, -0.0278]])\n",
      "\n",
      "Name: decoder.block.3.layer.1.EncDecAttention.k.weight\n",
      "Weight: tensor([[-1.5234,  0.4084, -0.3711,  ..., -0.3572, -0.9727, -1.3595],\n",
      "        [-0.2814,  0.3240,  0.3338,  ...,  0.2186, -0.3537, -1.0079],\n",
      "        [-0.0277,  0.4552,  0.6446,  ..., -0.4415,  0.0850, -0.3712],\n",
      "        ...,\n",
      "        [-0.4138,  0.1071, -0.6057,  ...,  0.0596, -0.1262,  0.1419],\n",
      "        [ 0.0297, -0.0347,  0.2297,  ...,  0.4357,  0.5079, -1.1018],\n",
      "        [ 0.2434,  1.2890, -0.1775,  ...,  0.2889,  0.2353,  0.1070]])\n",
      "\n",
      "Name: decoder.block.3.layer.1.EncDecAttention.v.weight\n",
      "Weight: tensor([[-0.6366,  0.5623,  0.0348,  ...,  0.6954, -0.7463,  0.2966],\n",
      "        [ 0.7618,  1.0626, -0.3437,  ..., -1.1717,  1.5624,  1.3202],\n",
      "        [-0.3026, -0.9964,  0.0047,  ...,  0.6055, -1.5468,  0.1365],\n",
      "        ...,\n",
      "        [-1.0860,  0.0700,  2.5935,  ..., -0.0945,  0.3202, -0.0808],\n",
      "        [ 2.7342,  0.8515, -0.7503,  ..., -0.4765, -1.6017, -0.8357],\n",
      "        [-0.1837, -0.0876,  2.1873,  ..., -1.1327,  0.2755, -0.1745]])\n",
      "\n",
      "Name: decoder.block.3.layer.1.EncDecAttention.o.weight\n",
      "Weight: tensor([[ 4.2211e-01,  3.0692e-01,  1.0717e-01,  ..., -8.7920e-01,\n",
      "          2.2034e+00, -1.0884e-02],\n",
      "        [ 3.7317e-01,  1.1170e+00,  8.3619e-01,  ...,  2.1404e+00,\n",
      "          8.4351e-01,  3.3966e-01],\n",
      "        [ 2.2388e-01, -6.5987e-01,  9.9975e-01,  ...,  6.6768e-01,\n",
      "         -6.2862e-01,  1.8987e+00],\n",
      "        ...,\n",
      "        [-3.6515e-01, -9.8021e-01,  3.0444e-01,  ...,  4.6850e-01,\n",
      "          1.5393e+00, -1.3645e-01],\n",
      "        [ 6.6431e-01,  1.6908e-03, -7.2256e-01,  ..., -4.0458e-01,\n",
      "         -9.6066e-01,  2.5615e-01],\n",
      "        [ 1.8747e-01,  1.1170e+00,  1.8771e-01,  ...,  1.1326e+00,\n",
      "         -4.4540e-01,  8.5552e-01]])\n",
      "\n",
      "Name: decoder.block.3.layer.1.layer_norm.weight\n",
      "Weight: tensor([ 0.1111,  0.1370,  0.0926,  0.1511,  0.0603,  0.1370,  0.1419,  0.0784,\n",
      "         0.0833,  0.1272,  0.1302,  0.0661,  0.1185,  0.1443,  0.0677,  0.1008,\n",
      "         0.1447,  0.1301,  0.1340,  0.1189,  0.1043,  0.1023,  0.1281, -0.0400,\n",
      "         0.1399,  0.1121,  0.1308,  0.0769,  0.1286,  0.1419,  0.1184,  0.0929,\n",
      "         0.1515,  0.1237,  0.0925,  0.0852,  0.1310,  0.1233,  0.1673,  0.1023,\n",
      "         0.1210,  0.1238,  0.0999,  0.1536,  0.1232,  0.1111, -0.0334,  0.1077,\n",
      "         0.1360,  0.1140,  0.1497,  0.1257,  0.1119,  0.0676,  0.0849,  0.1478,\n",
      "         0.1097,  0.1317,  0.1170,  0.0881,  0.1446,  0.1017,  0.1525,  0.1189,\n",
      "         0.1360,  0.1267,  0.1189,  0.1477,  0.0642,  0.1555,  0.1494,  0.1246,\n",
      "         0.1276,  0.1277,  0.1111,  0.1088,  0.1708,  0.1033,  0.1224,  0.0881,\n",
      "         0.0993,  0.1282,  0.1081,  0.1739,  0.1174,  0.0998,  0.1048,  0.1033,\n",
      "         0.1405,  0.0842,  0.1086,  0.1087,  0.0944,  0.1405,  0.0910,  0.1438,\n",
      "         0.0900,  0.1199,  0.1662,  0.0960,  0.1237,  0.1224,  0.0965,  0.0950,\n",
      "         0.1389,  0.1370,  0.1072,  0.1517,  0.1564,  0.1027,  0.1633,  0.1453,\n",
      "         0.1277,  0.1331,  0.1355,  0.1409,  0.1560,  0.1413,  0.0969,  0.1189,\n",
      "         0.1164,  0.1311,  0.1347,  0.0798,  0.1178,  0.1154,  0.1389,  0.1120,\n",
      "         0.1292,  0.1292,  0.1072,  0.1227,  0.1086,  0.1032,  0.0833,  0.1369,\n",
      "         0.1365,  0.1618,  0.1106,  0.1409,  0.1165,  0.0881,  0.1561,  0.1262,\n",
      "         0.1438,  0.1067,  0.1399,  0.0920,  0.1408, -0.0286,  0.1253,  0.1325,\n",
      "         0.0964,  0.1111,  0.1047,  0.1263,  0.1214,  0.1428,  0.1101,  0.1237,\n",
      "         0.1317,  0.1429,  0.1171,  0.0994,  0.1194,  0.1516,  0.1130,  0.1117,\n",
      "         0.1413,  0.1097,  0.1028,  0.1472,  0.0780,  0.1237,  0.1475,  0.1311,\n",
      "         0.0803,  0.1053,  0.1184,  0.1311,  0.1213,  0.1629,  0.4354,  0.1380,\n",
      "         0.1106,  0.1238,  0.1419,  0.1458,  0.1281,  0.1409,  0.1095,  0.1062,\n",
      "         0.1281,  0.1155,  0.1069,  0.1339,  0.1279,  0.1417,  0.1140,  0.1292,\n",
      "         0.1301,  0.1097,  0.1452,  0.1106,  0.1409,  0.1121,  0.4294,  0.1448,\n",
      "         0.1419,  0.1243,  0.1475,  0.1731,  0.1023,  0.0632,  0.1300,  0.1399,\n",
      "         0.1434,  0.1003,  0.1125,  0.1223,  0.1388,  0.1067,  0.1091,  0.1497,\n",
      "         0.1013,  0.1350,  0.0930,  0.1203,  0.1517,  0.1178,  0.1203,  0.1230,\n",
      "         0.0690,  0.0962,  0.1171,  0.1800,  0.1785,  0.0687,  0.1330, -0.0661,\n",
      "         0.0960,  0.1018,  0.0935,  0.1060,  0.1280, -0.0485,  0.1310,  0.1858,\n",
      "         0.0939,  0.1231,  0.1301,  0.1135,  0.1306,  0.1399,  0.1164,  0.1399,\n",
      "         0.1658,  0.0876,  0.0993,  0.1158,  0.1565,  0.1399,  0.1331,  0.0842,\n",
      "         0.1604,  0.1438,  0.1048,  0.1409, -0.0789,  0.0979,  0.1145,  0.1238,\n",
      "         0.1160,  0.0600,  0.1188,  0.1081,  0.1317,  0.1477,  0.1223,  0.1042,\n",
      "         0.0832,  0.0969,  0.1418,  0.1272,  0.1448,  0.1260,  0.1272,  0.1370,\n",
      "         0.1282,  0.1228,  0.0970,  0.1380,  0.1292,  0.1017,  0.1755,  0.1179,\n",
      "         0.1668,  0.1331,  0.1604,  0.1042,  0.1360,  0.1037,  0.0558,  0.1398,\n",
      "         0.0655,  0.1306,  0.1204,  0.0690,  0.0891,  0.0969,  0.1673,  0.1261,\n",
      "         0.1501,  0.1375,  0.1341,  0.1130,  0.1145,  0.1296,  0.0779,  0.1062,\n",
      "         0.1224,  0.1399,  0.1380,  0.0793,  0.1022,  0.1497,  0.1062,  0.1711,\n",
      "         0.1560,  0.0817,  0.1199,  0.1320,  0.1071,  0.1487,  0.1126,  0.1179,\n",
      "         0.1184,  0.1198,  0.1135,  0.1721,  0.0715,  0.0906,  0.1507,  0.0823,\n",
      "         0.1277,  0.0793,  0.1253,  0.1033,  0.0960,  0.1779,  0.1726,  0.1146,\n",
      "         0.1228,  0.1168,  0.1033,  0.1037,  0.1075,  0.1351,  0.1116,  0.1356,\n",
      "         0.1751,  0.1203,  0.1360,  0.0855,  0.1399,  0.1023,  0.1155,  0.0356,\n",
      "         0.1047,  0.1350,  0.1213,  0.1419,  0.1487,  0.1121,  0.1292,  0.1556,\n",
      "         0.1291,  0.0983,  0.1482,  0.0862,  0.1662,  0.1110,  0.1292,  0.1263,\n",
      "         0.1252,  0.1288,  0.0842,  0.1243,  0.0984,  0.1282,  0.1346,  0.1213,\n",
      "         0.0773,  0.1331,  0.1023,  0.1394,  0.1080,  0.0984,  0.1106,  0.1638,\n",
      "         0.1012,  0.0769,  0.0774,  0.0261,  0.1213,  0.0901,  0.1428,  0.1302,\n",
      "         0.1160,  0.1120, -0.0746,  0.0788,  0.1058,  0.0932,  0.1286,  0.1467,\n",
      "         0.1302,  0.0793,  0.1276,  0.1477,  0.1512,  0.1407,  0.1062,  0.0818,\n",
      "         0.1248,  0.1467,  0.1242,  0.1379,  0.1248,  0.1604,  0.1130,  0.0973,\n",
      "         0.1140,  0.1442,  0.1082,  0.1173,  0.1036,  0.1248,  0.0979,  0.1174,\n",
      "         0.1555,  0.1398,  0.1370,  0.1140,  0.1652,  0.1272,  0.1292,  0.1086,\n",
      "         0.1355,  0.1702,  0.1189,  0.1350,  0.0823,  0.0798,  0.1428,  0.1385,\n",
      "         0.1428,  0.1350,  0.1223,  0.1331,  0.1170,  0.1185,  0.1150,  0.1337,\n",
      "         0.1247,  0.1238,  0.1042,  0.1175,  0.0967,  0.1252,  0.1277,  0.1218,\n",
      "         0.1150,  0.1355,  0.1185,  0.1306,  0.1399,  0.0754,  0.1673,  0.0936,\n",
      "         0.1096,  0.1428,  0.1009,  0.1312,  0.1390,  0.1379,  0.1272,  0.1384,\n",
      "         0.1155,  0.1185,  0.0339,  0.1428,  0.1526,  0.1253,  0.1515,  0.1326,\n",
      "         0.1272,  0.0803,  0.1091,  0.1198,  0.1956,  0.0622,  0.1058,  0.1281,\n",
      "         0.1194,  0.1481,  0.1192,  0.0872,  0.1584,  0.1135,  0.1853,  0.0819])\n",
      "\n",
      "Name: decoder.block.3.layer.2.DenseReluDense.wi.weight\n",
      "Weight: tensor([[ 0.1483, -0.2595, -0.5119,  ...,  0.2323,  0.3457, -0.6057],\n",
      "        [-0.1135, -0.1560,  0.5978,  ...,  0.2235, -0.0152,  0.3987],\n",
      "        [-0.7773, -0.9452,  0.6640,  ...,  0.2988, -0.7695, -0.3301],\n",
      "        ...,\n",
      "        [ 0.0421, -1.0234,  1.0313,  ..., -1.5235, -1.2735, -0.2423],\n",
      "        [-1.1329, -0.2637, -1.3593,  ...,  0.8828, -0.1583,  0.2969],\n",
      "        [ 0.7773,  0.3907, -0.4729,  ...,  0.0227,  0.0461,  0.0393]])\n",
      "\n",
      "Name: decoder.block.3.layer.2.DenseReluDense.wo.weight\n",
      "Weight: tensor([[-0.1032, -0.1770, -0.0384,  ..., -0.4060, -0.1825, -0.3630],\n",
      "        [ 0.0744,  0.0886,  0.2696,  ..., -0.0741,  0.2248, -0.2595],\n",
      "        [-0.1345,  0.1248, -0.0426,  ...,  0.4944,  0.3693,  0.2581],\n",
      "        ...,\n",
      "        [ 0.0495,  0.2304,  0.4023,  ...,  0.6485,  0.2833, -0.0894],\n",
      "        [-0.1209, -0.0288,  0.0645,  ...,  0.0618,  0.0807,  0.0576],\n",
      "        [-0.0510, -0.5196, -0.0487,  ...,  0.1515, -0.3906,  0.1028]])\n",
      "\n",
      "Name: decoder.block.3.layer.2.layer_norm.weight\n",
      "Weight: tensor([1.7888, 1.8981, 1.9065, 2.2185, 0.4397, 1.7815, 2.0938, 1.9138, 2.4528,\n",
      "        1.9138, 1.9060, 2.0472, 1.9138, 1.9685, 2.4998, 1.9295, 1.8672, 1.9847,\n",
      "        1.8201, 1.9378, 1.6716, 1.5157, 1.8435, 1.0628, 2.1092, 1.7190, 1.7731,\n",
      "        1.9143, 1.7034, 2.2341, 1.9061, 1.5159, 2.3279, 1.9294, 2.4065, 2.0466,\n",
      "        1.8357, 1.8202, 1.9685, 1.6872, 1.8357, 1.9060, 1.4300, 2.1716, 2.0310,\n",
      "        1.5626, 0.7972, 1.7425, 1.8049, 1.8206, 1.9139, 1.9690, 1.7653, 2.8284,\n",
      "        1.6171, 1.7966, 1.8122, 1.8513, 1.7500, 1.8284, 2.1873, 1.8128, 2.0310,\n",
      "        1.8201, 2.0627, 1.8356, 1.8357, 2.1722, 2.0472, 1.9060, 2.0159, 1.8435,\n",
      "        1.9454, 1.8513, 1.8436, 1.9064, 2.1565, 1.5628, 1.8127, 1.8200, 1.8200,\n",
      "        2.2186, 1.7810, 2.0935, 1.8669, 1.8670, 1.8440, 1.7815, 1.8044, 1.3831,\n",
      "        1.7419, 1.7888, 1.8672, 1.8904, 1.8825, 1.9295, 1.9608, 1.9216, 2.6878,\n",
      "        1.6794, 2.1872, 2.0159, 1.6956, 1.7888, 2.0003, 1.8128, 1.7110, 1.9143,\n",
      "        2.1560, 1.8126, 2.1091, 1.9451, 1.8050, 1.8903, 1.8204, 2.0315, 2.4842,\n",
      "        1.9060, 1.5862, 1.7737, 1.8050, 1.9216, 2.1252, 1.7575, 1.7190, 3.6722,\n",
      "        2.0935, 1.7653, 1.8903, 1.9378, 1.7575, 1.8670, 2.1404, 1.8206, 1.9841,\n",
      "        1.9924, 2.0159, 1.8826, 1.5706, 1.7892, 1.6794, 2.1097, 2.1091, 1.7888,\n",
      "        1.9919, 1.8591, 1.8518, 1.9685, 2.0470, 0.3929, 1.6950, 1.9138, 1.9378,\n",
      "        1.8513, 1.7109, 1.9065, 1.7966, 1.6950, 1.6800, 3.9534, 1.7112, 1.8435,\n",
      "        1.8122, 1.5315, 1.9456, 2.0784, 1.8435, 2.0313, 1.8903, 1.7734, 1.6481,\n",
      "        1.8206, 1.5940, 1.9763, 2.2971, 1.8200, 1.8831, 1.8128, 1.9534, 1.9294,\n",
      "        1.9997, 1.9220, 2.1403, 1.8674, 3.0159, 1.8278, 1.8591, 1.9377, 1.8518,\n",
      "        1.9216, 2.6095, 1.8122, 1.9998, 1.9216, 1.6952, 2.1092, 1.8128, 1.9919,\n",
      "        1.6404, 1.7971, 1.9456, 2.0627, 2.2653, 1.7972, 2.0003, 1.7185, 1.9378,\n",
      "        1.9450, 2.1717, 1.9451, 2.1872, 2.1560, 1.8591, 0.8474, 1.9690, 1.8986,\n",
      "        1.9295, 1.6562, 1.8909, 1.7031, 1.9687, 1.7581, 1.8281, 1.8044, 1.7581,\n",
      "        1.9143, 2.5315, 1.9220, 1.9294, 1.8752, 1.9294, 1.8909, 2.3278, 1.8045,\n",
      "        1.9451, 2.4222, 2.2029, 2.1247, 1.7575, 1.9612, 1.6874, 2.1565, 1.6953,\n",
      "        1.8669, 3.2810, 1.3986, 2.0628, 2.4373, 1.5314, 1.8200, 1.7734, 1.9139,\n",
      "        2.0472, 1.7185, 1.7970, 1.8519, 1.9144, 2.1716, 2.0313, 1.9690, 1.8828,\n",
      "        1.7815, 1.8513, 1.9612, 2.2498, 2.0159, 1.8206, 1.7653, 2.1253, 1.6175,\n",
      "        1.6329, 1.8981, 1.8279, 2.3903, 1.6253, 3.5778, 1.8905, 2.1716, 2.0779,\n",
      "        1.7424, 2.1560, 1.6800, 2.2341, 1.7966, 1.9611, 1.8127, 1.7341, 1.8830,\n",
      "        1.9763, 1.8206, 1.8753, 2.0778, 1.9685, 1.8279, 2.6247, 1.7658, 2.1872,\n",
      "        1.8669, 2.0467, 2.5154, 2.0315, 1.8747, 0.7269, 2.1095, 1.7580, 1.7419,\n",
      "        1.8279, 1.9841, 1.8206, 2.2659, 2.4378, 1.7811, 2.1409, 1.6487, 1.8200,\n",
      "        1.7032, 1.8984, 1.8435, 1.9686, 2.0159, 1.7888, 2.0311, 2.2972, 3.0628,\n",
      "        4.7190, 2.0466, 1.7737, 2.5472, 2.2341, 2.1091, 1.8747, 1.9997, 1.6403,\n",
      "        2.1716, 1.8122, 1.8825, 1.9685, 1.8205, 1.5545, 2.2341, 2.0472, 1.8044,\n",
      "        2.0310, 1.7503, 1.8591, 1.7268, 1.8357, 1.6403, 1.4222, 2.3123, 2.0310,\n",
      "        1.6403, 1.8050, 1.9299, 1.7815, 2.2345, 1.6095, 1.9606, 1.6169, 1.8513,\n",
      "        2.2497, 1.8982, 1.8126, 2.2347, 1.8904, 1.7578, 2.0625, 0.5042, 1.7425,\n",
      "        1.8435, 1.8357, 2.0778, 1.7810, 1.8200, 2.1565, 1.9845, 1.7890, 1.6091,\n",
      "        2.0622, 2.1407, 2.0784, 2.0784, 1.9450, 1.8753, 1.8518, 1.9456, 2.4685,\n",
      "        2.0466, 1.7971, 1.9919, 1.6956, 1.8675, 1.6018, 1.8518, 1.7503, 1.7659,\n",
      "        1.8987, 2.0159, 1.8356, 2.2815, 1.7425, 1.6404, 1.8987, 0.3323, 1.7575,\n",
      "        1.7737, 2.1565, 1.8981, 1.7732, 1.8044, 2.1560, 1.8122, 1.6485, 1.7420,\n",
      "        1.8513, 2.2966, 1.8903, 2.3753, 1.8831, 2.0466, 1.8435, 2.0310, 1.8513,\n",
      "        1.8909, 1.9373, 1.9923, 1.7815, 1.7892, 1.8200, 1.9450, 1.9534, 1.6562,\n",
      "        1.8987, 2.2814, 1.8044, 1.7657, 1.7737, 1.9689, 1.8201, 1.8206, 1.7654,\n",
      "        1.9765, 1.8905, 1.9450, 2.1404, 1.8122, 1.8050, 2.0310, 2.2185, 2.0940,\n",
      "        1.7425, 1.8283, 2.0627, 1.8591, 2.0628, 2.1253, 1.9997, 1.9767, 1.9924,\n",
      "        2.1717, 1.8827, 3.7341, 1.7813, 1.8747, 1.9925, 1.9450, 1.6721, 1.3747,\n",
      "        1.6795, 1.8518, 1.8513, 1.8591, 1.8044, 1.6325, 1.9217, 2.0003, 1.9372,\n",
      "        2.3284, 2.0310, 1.6872, 1.7653, 2.0311, 1.6795, 1.8987, 2.1091, 1.9298,\n",
      "        1.8984, 1.9294, 1.7497, 1.7811, 0.4395, 2.0154, 1.9299, 1.7737, 2.0468,\n",
      "        1.9138, 1.9842, 2.3597, 1.8125, 2.1249, 2.5002, 2.2659, 1.8591, 1.7419,\n",
      "        1.9919, 1.9450, 2.0314, 1.6248, 1.9294, 1.6874, 2.5003, 2.3284])\n",
      "\n",
      "Name: decoder.block.4.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[ 0.0743, -0.0068, -0.0019,  ...,  0.0725,  0.0169,  0.0108],\n",
      "        [ 0.0140,  0.0014,  0.0060,  ...,  0.0716, -0.1360, -0.0367],\n",
      "        [-0.0779, -0.0449,  0.0255,  ..., -0.0023,  0.0685, -0.0415],\n",
      "        ...,\n",
      "        [ 0.0364, -0.0838, -0.0179,  ..., -0.0549,  0.0756, -0.0084],\n",
      "        [-0.0775,  0.0117, -0.0004,  ...,  0.0052,  0.0392,  0.0162],\n",
      "        [ 0.0217, -0.0391, -0.0282,  ...,  0.0455, -0.0276,  0.0567]])\n",
      "\n",
      "Name: decoder.block.4.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[-0.2197, -0.0510, -0.0783,  ..., -0.1038,  0.2117, -0.2341],\n",
      "        [ 1.1409,  0.0925,  0.1238,  ..., -0.6403, -0.5974,  0.1198],\n",
      "        [ 0.2258,  0.2835,  0.3206,  ..., -0.3220, -0.4021,  0.2731],\n",
      "        ...,\n",
      "        [ 0.2654,  0.3984, -0.0321,  ..., -0.1512,  0.3300,  0.4941],\n",
      "        [-0.3807, -0.2479,  1.0313,  ..., -0.0345, -0.2636, -0.2391],\n",
      "        [ 0.1397,  0.0514,  0.3788,  ..., -1.1719, -0.0555, -0.1974]])\n",
      "\n",
      "Name: decoder.block.4.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[-1.2108,  0.2636, -0.0811,  ...,  0.6679,  0.6641, -0.4729],\n",
      "        [ 0.1306,  0.1940, -0.1907,  ..., -0.9065, -0.8831,  0.4456],\n",
      "        [ 0.6330,  0.4882,  0.6485,  ...,  0.8671, -0.4826,  0.6991],\n",
      "        ...,\n",
      "        [ 0.2012, -0.1251,  1.0156,  ...,  0.1224, -0.2100,  0.3789],\n",
      "        [ 0.0184, -0.4647, -0.2288,  ..., -0.3006,  0.6057, -1.1328],\n",
      "        [ 0.5507, -0.5427,  1.4768,  ...,  0.1174, -0.1863, -0.8284]])\n",
      "\n",
      "Name: decoder.block.4.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[-1.6095,  1.2576,  1.3044,  ...,  1.4529, -1.1716,  0.5862],\n",
      "        [ 1.7891, -0.3870,  0.6132,  ..., -0.4372, -0.4514,  1.4297],\n",
      "        [-1.5237, -1.7500,  0.0294,  ...,  1.6169, -0.3200,  1.7737],\n",
      "        ...,\n",
      "        [ 0.2948, -1.7034,  1.9138,  ..., -0.8362,  0.9808,  1.3597],\n",
      "        [-0.6211, -2.4846,  0.1115,  ..., -0.3928, -0.0245, -0.1657],\n",
      "        [-0.2814,  1.1326,  0.2469,  ...,  0.5042, -1.6326, -0.1257]])\n",
      "\n",
      "Name: decoder.block.4.layer.0.layer_norm.weight\n",
      "Weight: tensor([ 0.1662,  0.1536,  0.1711,  0.2058,  0.1306,  0.1730,  0.2014,  0.1468,\n",
      "         0.1272,  0.1702,  0.1847,  0.1370,  0.2014,  0.1815,  0.1239,  0.1541,\n",
      "         0.1829,  0.1741,  0.1780,  0.1931,  0.1663,  0.1501,  0.1673,  0.0876,\n",
      "         0.2128,  0.1683,  0.1731,  0.1462,  0.1700,  0.2034,  0.1848,  0.1331,\n",
      "         0.2042,  0.2073,  0.1893,  0.1394,  0.1819,  0.1761,  0.1971,  0.1472,\n",
      "         0.1751,  0.1858,  0.1219,  0.1979,  0.1682,  0.1533,  0.0612,  0.1591,\n",
      "         0.1751,  0.1795,  0.1823,  0.1905,  0.1579,  0.1492,  0.1473,  0.1757,\n",
      "         0.1804,  0.1731,  0.1663,  0.1475,  0.2019,  0.1523,  0.1868,  0.1683,\n",
      "         0.1863,  0.1775,  0.1701,  0.2102,  0.1560,  0.1936,  0.1897,  0.1819,\n",
      "         0.1862,  0.1876,  0.1624,  0.1688,  0.2199,  0.1573,  0.1543,  0.1536,\n",
      "         0.1516,  0.1775,  0.1614,  0.1971,  0.1809,  0.1453,  0.1659,  0.1639,\n",
      "         0.1892,  0.1374,  0.1604,  0.1648,  0.1438,  0.1785,  0.1623,  0.1790,\n",
      "         0.0549,  0.2146,  0.2558,  0.1448,  0.1824,  0.1897,  0.1599,  0.1523,\n",
      "         0.2049,  0.1873,  0.1702,  0.1795,  0.2005,  0.1599,  0.2033,  0.1756,\n",
      "         0.1985,  0.1839,  0.1895,  0.1872,  0.2216,  0.1892,  0.1564,  0.1804,\n",
      "         0.1776,  0.1748,  0.2024,  0.1292,  0.1644,  0.2370,  0.2093,  0.1505,\n",
      "         0.1755,  0.1731,  0.1516,  0.1794,  0.1679,  0.1707,  0.1477,  0.1843,\n",
      "         0.1835,  0.1495,  0.1590,  0.1848,  0.1692,  0.1466,  0.1984,  0.1953,\n",
      "         0.1873,  0.1497,  0.1784,  0.1540,  0.1794,  0.0422,  0.1706,  0.1926,\n",
      "         0.1403,  0.1877,  0.1620,  0.2039,  0.1823,  0.1795,  0.1555,  0.3323,\n",
      "         0.1677,  0.1878,  0.1750,  0.1483,  0.1726,  0.2024,  0.1438,  0.1706,\n",
      "         0.1794,  0.1707,  0.1573,  0.1706,  0.1475,  0.1692,  0.1975,  0.1729,\n",
      "         0.1475,  0.1439,  0.1931,  0.1955,  0.1981,  0.1971,  0.5315,  0.1653,\n",
      "         0.2360,  0.1634,  0.1790,  0.1846,  0.1731,  0.1936,  0.1863,  0.1507,\n",
      "         0.1935,  0.1722,  0.1580,  0.2118,  0.1798,  0.1943,  0.1653,  0.1750,\n",
      "         0.1892,  0.1741,  0.1955,  0.1605,  0.1892,  0.1569,  0.3142,  0.1819,\n",
      "         0.1897,  0.2021,  0.2073,  0.2132,  0.1560,  0.0720,  0.1804,  0.1975,\n",
      "         0.1933,  0.1477,  0.1687,  0.1779,  0.1961,  0.1680,  0.1584,  0.2024,\n",
      "         0.1491,  0.1798,  0.1833,  0.2034,  0.1819,  0.1457,  0.1750,  0.1917,\n",
      "         0.1238,  0.1556,  0.1409,  0.2288,  0.2146,  0.1329,  0.1907,  0.0696,\n",
      "         0.1649,  0.1775,  0.1672,  0.1965,  0.1423,  0.0471,  0.1960,  0.2434,\n",
      "         0.1082,  0.1727,  0.1916,  0.1673,  0.1874,  0.1780,  0.1770,  0.1814,\n",
      "         0.1835,  0.1380,  0.1658,  0.1799,  0.1837,  0.1746,  0.1936,  0.1589,\n",
      "         0.2009,  0.1936,  0.1572,  0.1955,  0.1482,  0.1457,  0.1731,  0.1741,\n",
      "         0.1497,  0.0978,  0.1614,  0.1390,  0.1751,  0.2083,  0.2131,  0.1634,\n",
      "         0.1403,  0.1394,  0.1921,  0.1780,  0.1975,  0.1731,  0.1599,  0.1780,\n",
      "         0.1867,  0.1765,  0.1536,  0.1985,  0.1787,  0.1513,  0.1413,  0.1572,\n",
      "         0.2097,  0.1790,  0.2053,  0.1550,  0.1917,  0.1687,  0.0597,  0.2058,\n",
      "         0.1224,  0.1778,  0.1710,  0.1370,  0.1003,  0.1540,  0.2337,  0.1849,\n",
      "         0.1413,  0.1517,  0.1770,  0.1614,  0.2000,  0.1857,  0.1589,  0.1650,\n",
      "         0.1682,  0.2050,  0.2237,  0.1726,  0.2497,  0.2060,  0.1672,  0.2224,\n",
      "         0.2259,  0.1364,  0.1790,  0.1804,  0.1521,  0.1989,  0.1774,  0.1536,\n",
      "         0.1883,  0.1775,  0.1638,  0.2205,  0.1442,  0.1429,  0.2070,  0.1495,\n",
      "         0.1800,  0.1341,  0.1648,  0.1575,  0.1497,  0.2165,  0.1985,  0.1585,\n",
      "         0.1639,  0.1729,  0.1521,  0.1814,  0.1452,  0.1823,  0.1530,  0.1766,\n",
      "         0.2077,  0.1745,  0.1823,  0.1565,  0.1836,  0.1474,  0.1839, -0.0686,\n",
      "         0.1594,  0.1711,  0.1667,  0.1819,  0.1737,  0.1683,  0.1595,  0.2048,\n",
      "         0.1740,  0.1565,  0.1915,  0.1609,  0.2005,  0.1286,  0.1761,  0.1897,\n",
      "         0.1721,  0.1809,  0.1159,  0.2117,  0.1648,  0.1911,  0.1729,  0.1731,\n",
      "         0.1194,  0.1839,  0.1546,  0.1731,  0.1550,  0.1435,  0.1565,  0.2011,\n",
      "         0.1476,  0.1189,  0.1278,  0.0457,  0.1609,  0.1575,  0.1913,  0.1972,\n",
      "         0.1642,  0.1670,  0.1497,  0.1516,  0.1659,  0.1613,  0.1892,  0.2033,\n",
      "         0.1678,  0.1493,  0.1971,  0.2034,  0.1848,  0.1951,  0.1659,  0.1561,\n",
      "         0.1956,  0.1985,  0.1916,  0.1663,  0.1785,  0.1804,  0.1921,  0.1501,\n",
      "         0.1809,  0.2151,  0.1614,  0.1776,  0.1585,  0.1858,  0.1570,  0.1650,\n",
      "         0.1799,  0.1956,  0.1824,  0.1837,  0.2277,  0.1692,  0.1829,  0.1634,\n",
      "         0.2090,  0.2024,  0.1712,  0.1809,  0.1696,  0.1429,  0.1927,  0.1883,\n",
      "         0.1936,  0.1814,  0.1921,  0.2043,  0.1745,  0.2581,  0.1728,  0.1790,\n",
      "         0.1819,  0.1823,  0.1614,  0.1014,  0.1390,  0.1818,  0.1774,  0.1721,\n",
      "         0.1565,  0.1751,  0.1799,  0.1516,  0.1961,  0.0762,  0.2204,  0.1351,\n",
      "         0.1517,  0.1985,  0.1560,  0.1878,  0.2054,  0.1917,  0.1835,  0.1809,\n",
      "         0.1649,  0.1673,  0.0527,  0.2073,  0.1980,  0.1599,  0.2132,  0.1833,\n",
      "         0.1862,  0.1481,  0.1643,  0.1838,  0.2175,  0.1399,  0.1458,  0.1707,\n",
      "         0.1816,  0.2014,  0.1730,  0.1463,  0.1787,  0.1746,  0.3182,  0.1492])\n",
      "\n",
      "Name: decoder.block.4.layer.1.EncDecAttention.q.weight\n",
      "Weight: tensor([[-0.1018, -0.0248,  0.0313,  ...,  0.1057, -0.0114,  0.0442],\n",
      "        [-0.0544, -0.0128,  0.0473,  ..., -0.0268, -0.0051, -0.0158],\n",
      "        [ 0.0063,  0.0109,  0.0218,  ..., -0.0503,  0.1013,  0.0209],\n",
      "        ...,\n",
      "        [-0.0005, -0.0752,  0.0608,  ..., -0.0793,  0.0575, -0.0691],\n",
      "        [-0.0871, -0.0345,  0.0354,  ..., -0.0366, -0.0054, -0.0090],\n",
      "        [-0.0243, -0.0156, -0.0522,  ...,  0.0627,  0.0348, -0.0567]])\n",
      "\n",
      "Name: decoder.block.4.layer.1.EncDecAttention.k.weight\n",
      "Weight: tensor([[-0.9490, -0.2102,  0.0662,  ...,  0.1142,  0.0239, -0.2361],\n",
      "        [-0.4958, -0.1101,  0.2659,  ..., -0.0866, -0.0268,  0.0208],\n",
      "        [-0.1091,  0.0074,  0.0066,  ..., -0.2909, -0.3415,  0.3011],\n",
      "        ...,\n",
      "        [ 0.3143,  0.4510,  0.0363,  ..., -0.4315,  0.4568, -0.8518],\n",
      "        [-1.0549,  0.0503, -0.1435,  ..., -1.0312, -0.1650,  1.0314],\n",
      "        [ 0.2431,  0.0390, -0.6524,  ...,  0.2325,  0.1492, -0.0208]])\n",
      "\n",
      "Name: decoder.block.4.layer.1.EncDecAttention.v.weight\n",
      "Weight: tensor([[-2.3123,  2.4064, -1.4609,  ...,  1.6797, -1.0548,  0.6487],\n",
      "        [ 2.1716, -0.5237,  0.6761,  ...,  1.8278,  0.9495, -1.6170],\n",
      "        [ 0.1051,  0.6877,  1.2576,  ...,  0.3908,  2.3904,  0.2219],\n",
      "        ...,\n",
      "        [ 0.3513, -0.6448, -0.8787,  ..., -0.3948, -2.1561, -0.6955],\n",
      "        [-1.3596,  2.1091,  1.0471,  ..., -1.0783, -1.1795,  0.1085],\n",
      "        [-0.2052, -2.0471, -1.4763,  ...,  0.3084,  0.6993,  2.5936]])\n",
      "\n",
      "Name: decoder.block.4.layer.1.EncDecAttention.o.weight\n",
      "Weight: tensor([[-0.1775,  1.4138,  0.1824,  ..., -0.0107,  1.1253,  0.4632],\n",
      "        [ 0.8436,  0.8865, -0.2375,  ..., -1.2033, -1.0936, -0.3650],\n",
      "        [-0.8435, -0.0191,  0.1593,  ..., -1.9534,  0.0838,  1.2972],\n",
      "        ...,\n",
      "        [ 2.1096, -2.2347, -0.9727,  ...,  1.8044,  0.4046, -1.1560],\n",
      "        [ 0.1072,  2.2341,  0.9296,  ..., -0.6018,  0.4612, -1.3044],\n",
      "        [-0.9299,  0.1067, -0.9104,  ..., -0.5743,  0.5003, -0.4685]])\n",
      "\n",
      "Name: decoder.block.4.layer.1.layer_norm.weight\n",
      "Weight: tensor([ 0.0647,  0.0862,  0.0613,  0.0808,  0.0535,  0.0755,  0.1013,  0.0691,\n",
      "         0.0589,  0.0586,  0.0797,  0.0550,  0.0647,  0.0706,  0.0571,  0.0626,\n",
      "         0.0764,  0.0662,  0.0715,  0.0806,  0.0620,  0.0559,  0.0681,  0.0427,\n",
      "         0.0789,  0.0673,  0.0664,  0.0770,  0.0714,  0.0916,  0.0632, -0.0561,\n",
      "         0.0911,  0.0803,  0.1037,  0.0637,  0.0641,  0.0646,  0.0793,  0.0633,\n",
      "         0.0586,  0.0638,  0.0682,  0.0812,  0.0641,  0.0584,  0.0342,  0.0585,\n",
      "         0.0701,  0.0573,  0.0818,  0.0822,  0.0632,  0.0769,  0.0686,  0.0706,\n",
      "         0.0613,  0.0735,  0.0598, -0.0615,  0.0705,  0.0567,  0.0804,  0.0670,\n",
      "         0.0745,  0.0735,  0.0778,  0.0707,  0.0749,  0.0794,  0.0715,  0.0738,\n",
      "         0.0642,  0.0676,  0.0564,  0.0598,  0.0886,  0.0579,  0.0623,  0.0925,\n",
      "         0.0769,  0.0734,  0.0591,  0.0935,  0.0680,  0.0677,  0.0577,  0.0674,\n",
      "         0.0700,  0.0691,  0.0572,  0.0793,  0.0611,  0.0671,  0.0706,  0.0623,\n",
      "         0.1232,  0.0789,  0.1780,  0.0568,  0.0608,  0.0603, -0.0574,  0.0691,\n",
      "         0.0789,  0.0687,  0.0696,  0.0700,  0.0852,  0.0681,  0.0837,  0.0676,\n",
      "         0.0906,  0.0652,  0.0610,  0.0740,  0.0710,  0.0738,  0.0594,  0.0602,\n",
      "         0.0651,  0.0669,  0.0586,  0.0579,  0.0540,  0.2770,  0.0818,  0.0603,\n",
      "         0.0872,  0.0623,  0.0554,  0.0652,  0.0652,  0.0789,  0.0730,  0.0676,\n",
      "         0.0773,  0.1706,  0.0603,  0.0745,  0.0623,  0.0744,  0.0862,  0.0776,\n",
      "         0.0750,  0.0547,  0.0729,  0.0710,  0.0720, -0.0245,  0.0647,  0.0710,\n",
      "         0.0690,  0.0570,  0.0533,  0.0705,  0.0754,  0.0799,  0.0704,  0.2116,\n",
      "         0.0632,  0.0857,  0.0616,  0.0624,  0.0686,  0.0847,  0.0664,  0.0861,\n",
      "         0.0681,  0.0605,  0.0638,  0.0715,  0.0696,  0.0622,  0.0769,  0.0642,\n",
      "         0.0790,  0.0620,  0.0794,  0.0638,  0.0578,  0.0818,  0.3206,  0.0785,\n",
      "         0.1374,  0.0600,  0.0691,  0.0664,  0.0637,  0.0725,  0.0769,  0.0779,\n",
      "         0.0652,  0.0955,  0.0550,  0.0785,  0.0671,  0.0720,  0.0617,  0.0681,\n",
      "         0.0711,  0.0628,  0.0769,  0.0571,  0.0700,  0.0640,  0.4646,  0.0882,\n",
      "         0.0808,  0.0662,  0.0686,  0.0779,  0.0640,  0.0371,  0.0615,  0.0735,\n",
      "         0.0736,  0.0601,  0.0721,  0.0635,  0.0694,  0.0605,  0.0635,  0.0755,\n",
      "         0.0627,  0.0632,  0.1066,  0.0581,  0.0784,  0.0637,  0.0676,  0.0676,\n",
      "         0.0750,  0.0628,  0.0629,  0.0852,  0.1018,  0.0681,  0.0764,  0.0628,\n",
      "         0.0926,  0.0744,  0.0686,  0.0652,  0.0595,  0.0473,  0.0671,  0.0898,\n",
      "         0.0940,  0.0657,  0.0725,  0.0632,  0.0720,  0.0799,  0.0618,  0.0760,\n",
      "         0.0915,  0.0657,  0.0678,  0.0690,  0.0804,  0.0647,  0.0593,  0.0989,\n",
      "         0.0862,  0.0685,  0.0652,  0.0784,  0.0581,  0.0547,  0.0784,  0.0720,\n",
      "         0.0619,  0.0464,  0.0610,  0.0690,  0.0598,  0.0739,  0.0903,  0.0701,\n",
      "         0.0739,  0.0555,  0.0662,  0.0683,  0.0691,  0.0686,  0.0652,  0.0764,\n",
      "         0.0633,  0.0657,  0.0623,  0.0730,  0.0703,  0.0559,  0.1618,  0.0769,\n",
      "         0.0896,  0.0677,  0.0750,  0.0642,  0.0666,  0.0643,  0.0216,  0.0677,\n",
      "         0.0624,  0.0651,  0.0657,  0.0632,  0.0479,  0.0667,  0.0911,  0.0743,\n",
      "         0.1696,  0.0662,  0.0828,  0.0562,  0.0633,  0.0642,  0.0896,  0.0745,\n",
      "         0.0613,  0.0632,  0.0698,  0.0788,  0.1569,  0.0779,  0.0589,  0.1017,\n",
      "         0.0705,  0.0617,  0.0802,  0.0727,  0.0651,  0.0676,  0.0661,  0.0581,\n",
      "         0.0813,  0.0596,  0.0637,  0.1004,  0.0671,  0.0769,  0.0729,  0.0552,\n",
      "         0.0671,  0.0613,  0.0608,  0.0603,  0.0569,  0.0949,  0.0866,  0.0632,\n",
      "         0.0629,  0.0636,  0.0603,  0.1277,  0.0593,  0.0586,  0.0591,  0.0724,\n",
      "         0.0887,  0.0637,  0.0719,  0.0618,  0.0706,  0.0662,  0.0540,  0.0349,\n",
      "         0.0592,  0.0637,  0.0637,  0.1033,  0.0797,  0.0633,  0.0725,  0.0813,\n",
      "         0.0725,  0.0569,  0.0788,  0.0862,  0.0876,  0.1481,  0.0763,  0.0633,\n",
      "         0.0724,  0.0635,  0.0524,  0.0681,  0.0896,  0.0676,  0.0704,  0.0638,\n",
      "         0.0731,  0.0735,  0.0624,  0.0823,  0.0672, -0.0541,  0.0562,  0.0809,\n",
      "         0.0769,  0.0532,  0.0549,  0.0224,  0.0583,  0.1028,  0.0769,  0.0662,\n",
      "         0.0591,  0.0642,  0.0667,  0.0753,  0.0600,  0.0940,  0.0813,  0.0769,\n",
      "         0.0701, -0.0808,  0.0622,  0.0801,  0.0706,  0.0627,  0.0629,  0.0700,\n",
      "         0.0728,  0.0857,  0.0687,  0.0642,  0.0591,  0.0798,  0.0608,  0.0542,\n",
      "         0.0663,  0.1022,  0.0718,  0.0643,  0.0628,  0.0643,  0.0637,  0.0635,\n",
      "         0.0872,  0.0720,  0.0637,  0.0676,  0.0868,  0.0677,  0.0601,  0.0687,\n",
      "         0.0701,  0.0881,  0.0652,  0.0608,  0.0682,  0.0578,  0.0706,  0.0680,\n",
      "         0.0716,  0.0696,  0.0657,  0.0667,  0.0642,  0.1101,  0.0762,  0.0625,\n",
      "         0.0667,  0.0559,  0.0602,  0.0586,  0.0618,  0.0745,  0.0637,  0.0598,\n",
      "         0.0789,  0.0672,  0.0706,  0.2253,  0.0725,  0.0778,  0.0804,  0.0496,\n",
      "         0.0642,  0.0711,  0.0562,  0.0625,  0.0627,  0.0792,  0.0701,  0.0808,\n",
      "         0.0862,  0.0636, -0.0211,  0.0662,  0.0799,  0.0652,  0.0699,  0.0715,\n",
      "         0.0669,  0.0730,  0.0587,  0.0622,  0.0925,  0.0848,  0.0623,  0.0652,\n",
      "         0.0661,  0.0848,  0.0734,  0.0487,  0.0783,  0.0644,  0.1456,  0.0755])\n",
      "\n",
      "Name: decoder.block.4.layer.2.DenseReluDense.wi.weight\n",
      "Weight: tensor([[ 0.2392, -0.7344,  0.6757,  ..., -0.5196,  1.0234,  0.6641],\n",
      "        [ 0.3848, -1.1641, -0.2677,  ..., -1.2345,  0.1258,  0.9570],\n",
      "        [ 0.2053,  0.5470,  0.8555,  ...,  0.2130,  0.0963,  0.0437],\n",
      "        ...,\n",
      "        [-0.0376, -0.7852, -1.2735,  ..., -0.3808, -1.3594, -0.3398],\n",
      "        [-2.2345, -0.3438,  0.3164,  ...,  0.7031, -0.5702, -0.1631],\n",
      "        [-1.1875, -0.4570,  0.2694,  ..., -0.8555, -0.7579,  0.5702]])\n",
      "\n",
      "Name: decoder.block.4.layer.2.DenseReluDense.wo.weight\n",
      "Weight: tensor([[ 1.0624, -0.2519,  0.1189,  ..., -0.2695,  0.3671,  0.1894],\n",
      "        [ 0.1197, -0.1630, -0.5389,  ..., -0.1973,  0.2061, -0.1864],\n",
      "        [-0.0958, -0.0884,  0.1389,  ...,  0.7148, -0.3673,  0.2889],\n",
      "        ...,\n",
      "        [-0.3438,  0.8984,  0.1054,  ...,  0.0913,  0.8438,  0.1533],\n",
      "        [-0.1484, -0.3847,  0.1555,  ..., -0.0972, -0.1407, -0.1187],\n",
      "        [ 0.4669,  0.1059, -0.0187,  ...,  0.1787, -0.1885, -0.1582]])\n",
      "\n",
      "Name: decoder.block.4.layer.2.layer_norm.weight\n",
      "Weight: tensor([2.5314, 2.7497, 2.3122, 2.6560, 0.5974, 2.1564, 2.9846, 2.6560, 3.7028,\n",
      "        2.0623, 2.2658, 2.8903, 2.3435, 2.1404, 3.6873, 2.2030, 2.2653, 2.6097,\n",
      "        2.4060, 2.4217, 2.0782, 1.7264, 2.3435, 1.6484, 2.2968, 2.3435, 2.0779,\n",
      "        3.0003, 2.0158, 2.9528, 2.0466, 2.2659, 2.9372, 2.3439, 3.4065, 2.6565,\n",
      "        2.2185, 2.1873, 2.7034, 2.1877, 2.1409, 1.9454, 2.3123, 2.6721, 2.4221,\n",
      "        1.8825, 1.2894, 2.2188, 2.2815, 1.9845, 2.6247, 2.5940, 2.5628, 4.5315,\n",
      "        2.4221, 2.2034, 2.4216, 2.2659, 1.9847, 2.6253, 2.1716, 2.4685, 2.6409,\n",
      "        2.2347, 2.6721, 2.2658, 2.3127, 2.0935, 2.9372, 2.7028, 2.7028, 2.5466,\n",
      "        2.2967, 1.9998, 2.0940, 2.2030, 2.4060, 2.2189, 2.4221, 2.5940, 2.3435,\n",
      "        2.5778, 2.0622, 2.6091, 2.2657, 2.2810, 2.0780, 2.6722, 1.9685, 2.1878,\n",
      "        2.0466, 2.3903, 2.2343, 2.2971, 2.4685, 2.2654, 2.0935, 2.3591, 4.4376,\n",
      "        1.9372, 2.2029, 1.9764, 2.2659, 2.6097, 2.2503, 2.2345, 2.1247, 2.2966,\n",
      "        2.8592, 2.4222, 2.6721, 2.5310, 2.0628, 2.2034, 1.9920, 2.5472, 2.6560,\n",
      "        2.2346, 1.8440, 1.9610, 2.1091, 2.3125, 2.1095, 2.2347, 1.8356, 6.2815,\n",
      "        2.8906, 2.0466, 2.7184, 2.3278, 1.9765, 1.9606, 2.6091, 2.4378, 2.5935,\n",
      "        2.1722, 2.7815, 3.9060, 1.9528, 1.9685, 2.0623, 2.8128, 2.6878, 2.2970,\n",
      "        2.2341, 2.2186, 2.3122, 2.4532, 2.5159, 0.4730, 1.8903, 2.2810, 2.7028,\n",
      "        2.0155, 2.0314, 2.1561, 2.0310, 2.3747, 2.2658, 6.5310, 1.9456, 2.4841,\n",
      "        2.1404, 1.9065, 2.5002, 2.5466, 2.6403, 2.7190, 2.0937, 1.9765, 2.2966,\n",
      "        2.0628, 2.0779, 1.9684, 2.4685, 2.3127, 2.1253, 2.7188, 2.1247, 2.2028,\n",
      "        2.0466, 2.2029, 2.4997, 2.1560, 4.0315, 2.2185, 2.2498, 2.2815, 2.1250,\n",
      "        2.4060, 4.0003, 3.0622, 2.3436, 2.7342, 2.0779, 2.3283, 2.1561, 2.5783,\n",
      "        1.9924, 2.0159, 2.6095, 2.4687, 2.9221, 2.5466, 2.3128, 2.2500, 2.0628,\n",
      "        2.4372, 2.4060, 2.0472, 2.5000, 2.5622, 2.4376, 1.0156, 2.0466, 2.0940,\n",
      "        2.4062, 2.2187, 2.4843, 2.1716, 2.2346, 1.9216, 2.4534, 2.1565, 2.7966,\n",
      "        2.1873, 3.7034, 1.9924, 2.5153, 2.2503, 2.2815, 2.1878, 3.6719, 2.4841,\n",
      "        2.8440, 3.0153, 2.8747, 3.3747, 1.9999, 2.3905, 2.5935, 3.0315, 2.1878,\n",
      "        2.3122, 5.4372, 1.6639, 2.7659, 3.1565, 2.9378, 2.3278, 2.1561, 2.1408,\n",
      "        2.4377, 2.0310, 2.0153, 2.4690, 2.3436, 2.5935, 3.0315, 2.8283, 2.6560,\n",
      "        2.0940, 2.0311, 2.9222, 2.9065, 2.2499, 2.2656, 2.0940, 2.4375, 2.3122,\n",
      "        2.0940, 2.3122, 2.1872, 3.4847, 1.7892, 6.7185, 1.9763, 2.2346, 2.9532,\n",
      "        2.2344, 3.4065, 2.2034, 2.4372, 2.1565, 2.3591, 2.2341, 2.0779, 2.2972,\n",
      "        2.0315, 2.5784, 2.7971, 2.3436, 2.3596, 1.9846, 5.1247, 2.5000, 2.7028,\n",
      "        2.0467, 2.2657, 4.8440, 2.5466, 2.3440, 0.5784, 2.3284, 2.7190, 1.8981,\n",
      "        2.3284, 3.0003, 3.0315, 2.6097, 2.9378, 2.4685, 4.5628, 2.0622, 2.4534,\n",
      "        1.8362, 2.0778, 1.9845, 3.0315, 2.8281, 2.0940, 2.1091, 2.3435, 4.0315,\n",
      "        7.6565, 1.9143, 2.4378, 2.8747, 2.4060, 2.9685, 2.6408, 2.4685, 2.0778,\n",
      "        2.2341, 2.0778, 2.4218, 2.6872, 2.0310, 2.0783, 2.9690, 2.7028, 2.2346,\n",
      "        2.3435, 2.5158, 2.1403, 2.4061, 2.3748, 2.0622, 1.9690, 2.7810, 2.4216,\n",
      "        1.9768, 2.1252, 1.9373, 2.0936, 3.2503, 2.0159, 2.0466, 2.0466, 2.4377,\n",
      "        2.9065, 1.8122, 2.0628, 2.9686, 2.3752, 2.2190, 1.9295, 0.4997, 2.0156,\n",
      "        2.0780, 2.2966, 2.8909, 2.2346, 2.0935, 3.9060, 2.2346, 2.0622, 1.9534,\n",
      "        2.2028, 3.1716, 2.2658, 3.4532, 2.5002, 2.1250, 2.3753, 2.1403, 4.2815,\n",
      "        2.4220, 2.8440, 2.1716, 2.0158, 2.0940, 2.3435, 2.2346, 2.3747, 2.2341,\n",
      "        2.6406, 2.6409, 2.1253, 2.7033, 2.4534, 2.7034, 2.3278, 0.3753, 1.8518,\n",
      "        2.3903, 2.5315, 2.1872, 1.9453, 2.1097, 2.7814, 2.5311, 2.2344, 2.7969,\n",
      "        2.0622, 2.9847, 2.5310, 3.1878, 2.2811, 2.1091, 2.3594, 2.4219, 2.5935,\n",
      "        2.1409, 2.9060, 2.2499, 2.2031, 2.0935, 1.9841, 2.3435, 2.1565, 1.9060,\n",
      "        2.0468, 3.0783, 2.0778, 2.2966, 2.4685, 2.2190, 2.5940, 2.4065, 2.0778,\n",
      "        2.1091, 2.0471, 2.4530, 2.5935, 2.0311, 1.9997, 2.5315, 2.3440, 2.4065,\n",
      "        1.9217, 1.9841, 3.1716, 2.5154, 2.4528, 2.4685, 2.1091, 2.3122, 2.6878,\n",
      "        2.3591, 1.9998, 6.9061, 1.9690, 2.1719, 2.3123, 1.9064, 1.8749, 1.6091,\n",
      "        2.3748, 2.2656, 1.9687, 2.1091, 2.1721, 1.9612, 2.3126, 4.4378, 2.1721,\n",
      "        3.5159, 2.4060, 1.6169, 2.4997, 2.2966, 1.9062, 1.9847, 2.0466, 2.1560,\n",
      "        2.3283, 2.5153, 2.2967, 2.2190, 0.5041, 2.0622, 2.7185, 1.9920, 2.3122,\n",
      "        2.4997, 2.2812, 3.2347, 2.3591, 2.8123, 3.2341, 3.4534, 2.3591, 1.9377,\n",
      "        2.3904, 2.6872, 2.6405, 2.0940, 2.4221, 1.9534, 4.3440, 3.7658])\n",
      "\n",
      "Name: decoder.block.5.layer.0.SelfAttention.q.weight\n",
      "Weight: tensor([[-0.0369, -0.0088, -0.0589,  ..., -0.0662,  0.0627, -0.0313],\n",
      "        [ 0.0342,  0.0341, -0.0009,  ...,  0.0690, -0.0700,  0.0347],\n",
      "        [-0.0532,  0.0163, -0.0214,  ...,  0.0058,  0.0025,  0.0064],\n",
      "        ...,\n",
      "        [ 0.0037,  0.0032, -0.0010,  ..., -0.0035, -0.0177, -0.0153],\n",
      "        [ 0.0198,  0.0641,  0.0195,  ...,  0.0121,  0.0749, -0.0067],\n",
      "        [-0.0196, -0.0309,  0.0439,  ..., -0.0490, -0.0275,  0.0172]])\n",
      "\n",
      "Name: decoder.block.5.layer.0.SelfAttention.k.weight\n",
      "Weight: tensor([[ 0.6443, -0.0415, -0.9297,  ..., -0.2581,  0.4939,  0.8127],\n",
      "        [ 0.5432, -1.0393, -0.7810,  ..., -0.2102, -0.1924,  0.7424],\n",
      "        [-0.2258,  0.3418,  0.5349,  ..., -0.6916, -0.1721,  0.2186],\n",
      "        ...,\n",
      "        [-0.4255, -0.2063, -0.2058,  ...,  0.0832, -0.7614, -0.1897],\n",
      "        [-0.3225, -0.1941,  0.0833,  ...,  0.0087, -0.9026,  0.3224],\n",
      "        [ 0.1423, -0.7264, -0.0590,  ...,  0.3280, -0.0094, -0.2400]])\n",
      "\n",
      "Name: decoder.block.5.layer.0.SelfAttention.v.weight\n",
      "Weight: tensor([[ 0.2481,  1.4924,  1.3674,  ...,  1.1721,  0.1897,  1.2657],\n",
      "        [ 0.0970,  0.1132,  1.0779,  ...,  0.6404, -0.3108, -0.6757],\n",
      "        [ 0.2595,  0.9495, -0.1364,  ...,  1.1565, -0.6169,  0.5740],\n",
      "        ...,\n",
      "        [-0.3088, -1.2424, -0.3239,  ..., -2.3597,  0.0958, -1.0310],\n",
      "        [ 0.7458, -0.0653,  0.6600,  ...,  0.4163, -0.4118, -0.8479],\n",
      "        [-0.3030,  0.4299,  1.9763,  ..., -0.4900,  0.1120,  0.2038]])\n",
      "\n",
      "Name: decoder.block.5.layer.0.SelfAttention.o.weight\n",
      "Weight: tensor([[ 0.1619,  0.5271,  1.7892,  ...,  0.3943, -2.2503, -0.7106],\n",
      "        [-0.3049, -0.9651, -1.4294,  ..., -0.7618, -0.0344, -0.6052],\n",
      "        [-0.0573,  0.6169,  0.1259,  ...,  0.5193, -0.5979, -2.1560],\n",
      "        ...,\n",
      "        [ 0.4431, -1.8050,  0.9416,  ...,  1.5701, -0.6136,  2.4534],\n",
      "        [ 0.0775,  0.1579,  0.3928,  ...,  0.8005,  0.3552,  0.4671],\n",
      "        [-0.9726,  0.2308, -0.0288,  ..., -0.2039,  1.2659, -0.1946]])\n",
      "\n",
      "Name: decoder.block.5.layer.0.layer_norm.weight\n",
      "Weight: tensor([ 0.2373,  0.2522,  0.2077,  0.2483,  0.2126,  0.1829,  0.3065,  0.2600,\n",
      "         0.2581,  0.1794,  0.2185,  0.2639,  0.2239,  0.1966,  0.1966,  0.1872,\n",
      "         0.2058,  0.2444,  0.2390,  0.2351,  0.1972,  0.1700,  0.2151, -0.1560,\n",
      "         0.2210,  0.2283,  0.1956,  0.2952,  0.1991,  0.2932,  0.1897,  0.2220,\n",
      "         0.2737,  0.2138,  0.3460,  0.2239,  0.2034,  0.1956,  0.2620,  0.2097,\n",
      "         0.2122,  0.1804,  0.2698,  0.2344,  0.2132,  0.1887,  0.1452,  0.1999,\n",
      "         0.2263,  0.1765,  0.2517,  0.2238,  0.2176, -0.3421,  0.2401,  0.2010,\n",
      "         0.2005,  0.2219,  0.1853,  0.2483,  0.2087,  0.2341,  0.2464,  0.1917,\n",
      "         0.2718,  0.2107,  0.2312,  0.1854,  0.2717,  0.2874,  0.2459,  0.2536,\n",
      "         0.1965,  0.1892,  0.1897,  0.2170,  0.2433,  0.2117,  0.2346,  0.2796,\n",
      "         0.2522,  0.2282,  0.1795,  0.2600,  0.2033,  0.2053,  0.1981,  0.2522,\n",
      "         0.1765,  0.2038,  0.1769,  0.2292,  0.2190,  0.2043,  0.2637,  0.1936,\n",
      "         0.1038,  0.2244,  0.5901,  0.1981,  0.2028,  0.1761,  0.2209,  0.2517,\n",
      "         0.2288,  0.2038,  0.2014,  0.2102,  0.2776,  0.2361,  0.2556,  0.2122,\n",
      "         0.2063,  0.2190,  0.1843,  0.2395,  0.2405,  0.2010,  0.1778,  0.1960,\n",
      "         0.2122,  0.2063,  0.1985,  0.1907,  0.1780,  0.6292,  0.2756,  0.1980,\n",
      "         0.2757,  0.2292,  0.1758,  0.1872,  0.2097,  0.2888,  0.2498,  0.1985,\n",
      "         0.2835,  0.4060,  0.1872,  0.1916,  0.1923,  0.2503,  0.2317,  0.2195,\n",
      "         0.2004,  0.2161,  0.2404,  0.2337,  0.2272, -0.0788,  0.1722,  0.1995,\n",
      "         0.2517,  0.1868,  0.1794,  0.2005,  0.1897,  0.2634,  0.2034,  0.5388,\n",
      "         0.1807,  0.2597,  0.1897,  0.1809,  0.2409,  0.2391,  0.2277,  0.2600,\n",
      "         0.2038,  0.1779,  0.2259,  0.1795,  0.2196,  0.1683,  0.2229,  0.2136,\n",
      "         0.2161,  0.2337,  0.2058,  0.2024,  0.1936,  0.2175,  0.7776,  0.2335,\n",
      "         0.3337,  0.2102,  0.2110,  0.2386,  0.1818,  0.2206,  0.3513,  0.2557,\n",
      "         0.2033,  0.2849,  0.1824,  0.2254,  0.2081,  0.2521,  0.1887,  0.1907,\n",
      "         0.2479,  0.2503,  0.2497,  0.2249,  0.2180,  0.2082,  0.4553,  0.2503,\n",
      "         0.2419,  0.1994,  0.2171,  0.2383,  0.2366,  0.0993,  0.2011,  0.2028,\n",
      "         0.2171,  0.2283,  0.2600,  0.1966,  0.1980,  0.1833,  0.2165,  0.2158,\n",
      "         0.2454,  0.1973,  0.3323,  0.1749,  0.2278,  0.2185,  0.2014,  0.2019,\n",
      "        -0.2600,  0.2229,  0.2425,  0.2776,  0.2776,  0.2678,  0.2151,  0.1282,\n",
      "         0.2790,  0.2712,  0.2249,  0.2156,  0.2269, -0.0750,  0.2366,  0.2751,\n",
      "         0.2874,  0.2288,  0.2136,  0.2131,  0.2224,  0.1955,  0.1848,  0.2292,\n",
      "         0.2312,  0.2054,  0.2911,  0.2461,  0.2561,  0.1796,  0.1946,  0.3320,\n",
      "         0.2893,  0.2151,  0.2024,  0.2093,  0.2542,  0.2014,  0.2218,  0.2298,\n",
      "         0.2048,  0.2382,  0.1760,  0.2634,  0.1819,  0.2093,  0.2849,  0.2239,\n",
      "         0.2517,  0.1858,  0.2029,  0.1995,  0.2063,  0.2116,  0.1985,  0.2337,\n",
      "         0.1839,  0.2522,  0.2616,  0.2122,  0.2092,  0.1677,  0.1482,  0.2732,\n",
      "         0.2636,  0.1906,  0.2054,  0.3108,  0.2581,  0.2278,  0.0837,  0.2060,\n",
      "         0.2390,  0.1736,  0.2121,  0.2365,  0.1514,  0.2405,  0.2713,  0.2376,\n",
      "         0.3303,  0.1846,  0.2434,  0.1712,  0.1933,  0.1785,  0.2814,  0.2440,\n",
      "         0.1980,  0.1926,  0.1991,  0.3108,  0.4768,  0.1768,  0.2194,  0.2829,\n",
      "         0.2151,  0.2317,  0.2561,  0.2483,  0.2015,  0.2015,  0.1911,  0.2376,\n",
      "         0.2654,  0.2044,  0.2053,  0.2893,  0.2444,  0.2058,  0.2181,  0.2404,\n",
      "         0.2034,  0.2268,  0.2102,  0.1877,  0.1819,  0.2614,  0.2640,  0.1826,\n",
      "         0.2013,  0.1838,  0.1921,  0.3591,  0.1897,  0.1858,  0.1882,  0.2181,\n",
      "         0.2678,  0.1809,  0.1941,  0.2757,  0.2253,  0.2239,  0.1643, -0.1062,\n",
      "         0.2219,  0.1887,  0.2068,  0.2468,  0.2500,  0.1952,  0.2698,  0.2034,\n",
      "         0.1966,  0.1719,  0.2101,  0.2776,  0.2415,  0.2991,  0.2268,  0.2054,\n",
      "         0.2732,  0.1999,  0.1992,  0.2288,  0.3181,  0.1731,  0.1936,  0.2024,\n",
      "         0.2005,  0.1956,  0.2268,  0.2434,  0.2194,  0.2394,  0.1848,  0.2493,\n",
      "         0.2356,  0.2042,  0.2132, -0.0842,  0.1599,  0.2561,  0.2263,  0.2136,\n",
      "         0.1848,  0.1944,  0.2401,  0.2654,  0.2188,  0.2810,  0.2019,  0.2674,\n",
      "         0.2258,  0.2620,  0.2068,  0.2068,  0.2121,  0.2265,  0.2620,  0.2136,\n",
      "         0.2614,  0.2161,  0.2058,  0.1858,  0.1839,  0.2278,  0.1971,  0.1966,\n",
      "         0.1829,  0.3108,  0.1975,  0.2146,  0.2298,  0.2121,  0.2503,  0.2415,\n",
      "         0.2031,  0.1974,  0.1838,  0.2395,  0.2234,  0.2024,  0.1790,  0.2249,\n",
      "         0.2004,  0.2366,  0.1858,  0.1808,  0.3225,  0.2356,  0.2464,  0.2014,\n",
      "         0.1966,  0.2258,  0.2459,  0.2347,  0.1730,  0.5271,  0.2005,  0.1933,\n",
      "         0.2278,  0.1756,  0.1726,  0.1546,  0.2058,  0.1913,  0.1815,  0.1854,\n",
      "         0.2234,  0.1887,  0.2159,  0.4925,  0.2063, -0.1555,  0.2288,  0.1507,\n",
      "         0.2229,  0.2063,  0.1787,  0.1927,  0.1917,  0.2107,  0.2102,  0.2332,\n",
      "         0.2463,  0.2001,  0.0964,  0.1975,  0.2561,  0.1877,  0.2292,  0.2366,\n",
      "         0.2050,  0.2810,  0.2317,  0.2380,  0.2908,  0.2776,  0.1995,  0.1872,\n",
      "         0.2146,  0.2482,  0.2497,  0.2024,  0.2165,  0.1962,  0.7893,  0.2833])\n",
      "\n",
      "Name: decoder.block.5.layer.1.EncDecAttention.q.weight\n",
      "Weight: tensor([[ 0.0764, -0.0862,  0.0199,  ..., -0.0160,  0.0368, -0.0994],\n",
      "        [ 0.0047,  0.0855,  0.0003,  ..., -0.0024,  0.0368, -0.0331],\n",
      "        [-0.0748, -0.0475,  0.0477,  ..., -0.0028,  0.0924, -0.0191],\n",
      "        ...,\n",
      "        [ 0.0183, -0.0315,  0.0525,  ..., -0.0364, -0.0348,  0.0393],\n",
      "        [ 0.0089,  0.0315,  0.0730,  ...,  0.0303,  0.0271,  0.0652],\n",
      "        [ 0.0304, -0.0598, -0.0302,  ..., -0.0369, -0.0123, -0.0452]])\n",
      "\n",
      "Name: decoder.block.5.layer.1.EncDecAttention.k.weight\n",
      "Weight: tensor([[ 0.1650,  0.2833, -0.0390,  ...,  0.2100,  0.1561, -0.0356],\n",
      "        [ 0.7893,  0.6994, -0.2853,  ...,  0.0457, -0.0167,  0.2755],\n",
      "        [ 0.0242, -0.6131, -0.0192,  ..., -0.4786,  0.4881, -0.3713],\n",
      "        ...,\n",
      "        [ 0.3748,  0.4549, -0.0187,  ..., -0.1691, -0.3495, -0.1198],\n",
      "        [-0.0755, -0.4436, -0.2219,  ...,  0.1043,  0.1081, -0.5586],\n",
      "        [-0.3693, -0.0998,  0.4492,  ...,  0.1070, -0.2141, -0.3866]])\n",
      "\n",
      "Name: decoder.block.5.layer.1.EncDecAttention.v.weight\n",
      "Weight: tensor([[ 2.1872, -0.5042,  2.8280,  ..., -1.2341,  0.4275, -0.2947],\n",
      "        [-1.9846, -0.8714, -1.2502,  ...,  0.3634,  0.3376, -1.3983],\n",
      "        [-0.7268, -0.7972,  2.7187,  ..., -1.7655, -0.3714,  0.3147],\n",
      "        ...,\n",
      "        [-1.5158,  1.2185, -0.3672,  ..., -0.5703, -1.9064, -0.0686],\n",
      "        [ 4.1565, -0.6169,  1.7811,  ..., -1.3751, -0.8946,  0.0058],\n",
      "        [-1.3280,  1.4373, -3.0782,  ...,  0.4101,  0.3397, -0.2990]])\n",
      "\n",
      "Name: decoder.block.5.layer.1.EncDecAttention.o.weight\n",
      "Weight: tensor([[ 2.4685,  0.2868, -0.2356,  ..., -2.1560,  3.0315,  0.2044],\n",
      "        [-1.9768,  0.6208,  0.4236,  ...,  1.4768,  0.4710, -0.6169],\n",
      "        [ 1.4216,  0.7692, -0.8713,  ..., -1.1638,  2.6096, -1.7966],\n",
      "        ...,\n",
      "        [-0.9065, -1.0550, -1.8206,  ...,  0.1184, -1.6403, -1.6092],\n",
      "        [-0.6136,  0.2058, -0.4436,  ..., -0.6989, -0.6247, -0.1540],\n",
      "        [ 0.4163, -0.3904,  0.2042,  ...,  0.1970,  0.3200, -0.1946]])\n",
      "\n",
      "Name: decoder.block.5.layer.1.layer_norm.weight\n",
      "Weight: tensor([ 0.1590,  0.1155,  0.1267,  0.1942,  0.0398,  0.1550,  0.2013,  0.1220,\n",
      "         0.1003,  0.1227,  0.1477,  0.1438,  0.1355,  0.1503, -0.0744,  0.1116,\n",
      "         0.1516,  0.1643,  0.1522,  0.1475,  0.1387,  0.1061,  0.1248,  0.0406,\n",
      "         0.1516,  0.1546,  0.1261,  0.1169,  0.1399,  0.1893,  0.1292,  0.1102,\n",
      "         0.1922,  0.1868,  0.1853,  0.1096,  0.1306,  0.1307,  0.2058,  0.1225,\n",
      "         0.1423,  0.1131,  0.1878,  0.1749,  0.1438,  0.1204,  0.0429,  0.1326,\n",
      "         0.1595,  0.1106,  0.2160,  0.1551,  0.1484,  0.1818,  0.1106,  0.1882,\n",
      "         0.1341,  0.1585,  0.1208,  0.1208,  0.1452,  0.1199,  0.1848,  0.1404,\n",
      "         0.1884,  0.1526,  0.1472,  0.1341,  0.1086,  0.1697,  0.1579,  0.1868,\n",
      "         0.1563,  0.1405,  0.1135,  0.1198,  0.2195,  0.1248,  0.1325,  0.1315,\n",
      "         0.1394,  0.1409,  0.1242,  0.2409,  0.1360,  0.1231,  0.1131,  0.1506,\n",
      "         0.1482,  0.0808,  0.1269,  0.1267,  0.1101,  0.1848,  0.1317,  0.1296,\n",
      "         0.1228,  0.1614,  0.3440, -0.1091,  0.1136,  0.1170,  0.1217,  0.1355,\n",
      "         0.1658,  0.1757,  0.1370,  0.1458,  0.2151,  0.1404,  0.2151,  0.1570,\n",
      "         0.1526,  0.1425,  0.1355, -0.1643,  0.1501,  0.1690,  0.1072,  0.1345,\n",
      "         0.1347,  0.1463,  0.1282,  0.1111,  0.1023,  0.2029,  0.1994,  0.1071,\n",
      "         0.1829,  0.1335,  0.1066,  0.1409,  0.1241,  0.1267,  0.1243,  0.1433,\n",
      "         0.1806,  0.1696,  0.1184,  0.1700,  0.1425,  0.1253,  0.1750,  0.2185,\n",
      "         0.1505,  0.1282,  0.1619,  0.1194,  0.1543,  0.0415,  0.1316,  0.1609,\n",
      "         0.1638,  0.1253,  0.1212,  0.1497,  0.1244,  0.1731,  0.1328,  0.2732,\n",
      "         0.1174,  0.1721,  0.1377,  0.1018, -0.1234,  0.1682,  0.1335,  0.1687,\n",
      "         0.1540,  0.1174,  0.1418,  0.1219,  0.1135,  0.1169,  0.1482,  0.1398,\n",
      "         0.1180,  0.1043,  0.1335,  0.1575,  0.1086,  0.2024,  1.5235,  0.1317,\n",
      "         0.2097,  0.1164,  0.1599,  0.1487,  0.1287,  0.1800, -0.1120,  0.1414,\n",
      "         0.1375,  0.1502,  0.1082,  0.1565,  0.1438,  0.1690,  0.1330,  0.1367,\n",
      "         0.1682,  0.1290,  0.1521,  0.1189,  0.1658,  0.1360,  1.2576,  0.1916,\n",
      "         0.1438,  0.1126,  0.1788,  0.2190,  0.1063,  0.0584,  0.1335,  0.1624,\n",
      "         0.1492,  0.1122, -0.1409,  0.1452,  0.1721,  0.1082,  0.1297,  0.1931,\n",
      "         0.1341,  0.1403,  0.1720,  0.1210,  0.2239,  0.1248,  0.1433,  0.1360,\n",
      "         0.2423,  0.1057,  0.1169,  0.2200,  0.2693,  0.1377,  0.1370,  0.1081,\n",
      "         0.1564,  0.1433,  0.1327,  0.1209,  0.1018,  0.0481,  0.1311,  0.2657,\n",
      "         0.0876,  0.1339,  0.1640,  0.1516,  0.1477,  0.1614,  0.1321,  0.1649,\n",
      "         0.2207,  0.1282,  0.1551,  0.1326,  0.2468,  0.1476,  0.1218,  0.1609,\n",
      "         0.2346,  0.1506,  0.1208,  0.1585,  0.1286,  0.1194,  0.1340,  0.1307,\n",
      "         0.1121,  0.0596,  0.1233,  0.1290,  0.1216,  0.1661,  0.1687,  0.1429,\n",
      "         0.1023,  0.1218,  0.1235,  0.1502,  0.1633,  0.1350,  0.1331,  0.1604,\n",
      "         0.1272,  0.1505,  0.1164,  0.1603,  0.1555,  0.1008,  0.0505,  0.1497,\n",
      "         0.2712,  0.1277,  0.1628,  0.1257,  0.1599,  0.1214, -0.0405,  0.1282,\n",
      "         0.1082,  0.1482,  0.1395,  0.1086, -0.0657,  0.1175,  0.2205,  0.1633,\n",
      "         0.1347,  0.1155,  0.2082,  0.1018,  0.1331,  0.1320, -0.1198,  0.1311,\n",
      "         0.1341,  0.1533,  0.1454, -0.1452,  0.1931,  0.1299,  0.1326,  0.1984,\n",
      "         0.1658,  0.1018,  0.1833,  0.1966,  0.1233,  0.1482,  0.1428,  0.1326,\n",
      "         0.1405,  0.1172,  0.1311,  0.2229,  0.1113,  0.1132,  0.1702,  0.1143,\n",
      "         0.1448,  0.1252,  0.1419,  0.1086,  0.1214,  0.1941,  0.1501,  0.1219,\n",
      "         0.1232,  0.1331,  0.1250,  0.2014,  0.1082,  0.1252,  0.1214,  0.1511,\n",
      "         0.2255,  0.1194,  0.1593,  0.1663,  0.1521,  0.1233,  0.1081, -0.0490,\n",
      "         0.1213,  0.1350,  0.1502,  0.2048,  0.1563,  0.1189, -0.1004,  0.1839,\n",
      "         0.1369,  0.1176,  0.1562, -0.1277,  0.1828,  0.1345,  0.1497,  0.1429,\n",
      "         0.1476,  0.1377,  0.0974,  0.1413,  0.1483,  0.1233,  0.1551,  0.1358,\n",
      "         0.1826,  0.1657,  0.1193,  0.1628,  0.1413, -0.1077,  0.1101,  0.2024,\n",
      "         0.1599,  0.1053,  0.1194, -0.0246,  0.1071,  0.1260,  0.2127,  0.1585,\n",
      "         0.1197,  0.1399,  0.1216,  0.1150,  0.1281,  0.1856,  0.1462,  0.2010,\n",
      "         0.1472,  0.1267,  0.1531,  0.1619,  0.1817,  0.1413,  0.1434,  0.1038,\n",
      "         0.1800,  0.1701,  0.1414,  0.1456,  0.1178,  0.1673,  0.1298,  0.1091,\n",
      "         0.1271,  0.2033,  0.1223,  0.1483,  0.1336,  0.1268,  0.1238,  0.1403,\n",
      "         0.2288,  0.1310,  0.1272,  0.1415,  0.2296,  0.1468,  0.1253,  0.1311,\n",
      "         0.1476,  0.2068,  0.1218,  0.1195,  0.1878,  0.1143,  0.1702,  0.1534,\n",
      "         0.1487,  0.1516,  0.1623,  0.1638,  0.1177,  0.4022,  0.1125,  0.1483,\n",
      "         0.1623,  0.1086,  0.1135,  0.0911,  0.1057,  0.1516,  0.1296,  0.1290,\n",
      "         0.1331,  0.1380,  0.1474,  0.1629,  0.1858,  0.1071,  0.2093,  0.0935,\n",
      "         0.1331,  0.1477,  0.1092,  0.1213,  0.1214,  0.1462,  0.1473,  0.1706,\n",
      "         0.1623,  0.1433, -0.0322,  0.1386,  0.2268,  0.1292,  0.1524,  0.1407,\n",
      "         0.1331, -0.1249,  0.1355,  0.1492,  0.2488,  0.1111,  0.1306,  0.1146,\n",
      "         0.1365,  0.2004,  0.1405,  0.1114,  0.1974,  0.1204,  0.2678,  0.1818])\n",
      "\n",
      "Name: decoder.block.5.layer.2.DenseReluDense.wi.weight\n",
      "Weight: tensor([[-0.0674, -0.3769, -0.1484,  ..., -0.4863,  0.0674, -0.5391],\n",
      "        [ 0.2450, -0.3555, -0.5310,  ...,  0.3279, -0.3105,  1.4299],\n",
      "        [ 0.0975, -1.1874, -0.0331,  ..., -0.3439, -0.6838,  1.8596],\n",
      "        ...,\n",
      "        [-0.8712,  0.5313,  0.3514,  ...,  0.0359, -0.6094,  0.8709],\n",
      "        [ 0.5820,  0.1523, -0.6211,  ..., -0.9922, -1.2188, -0.3026],\n",
      "        [ 0.9258, -0.0443,  0.4318,  ...,  0.3245,  0.1682, -0.2229]])\n",
      "\n",
      "Name: decoder.block.5.layer.2.DenseReluDense.wo.weight\n",
      "Weight: tensor([[ 2.3241e-01, -2.4043e-01, -1.2450e-01,  ...,  3.0000e-02,\n",
      "         -6.7977e-01,  3.5571e-01],\n",
      "        [-4.7353e-03, -9.7992e-02, -1.1950e-01,  ...,  6.3684e-01,\n",
      "         -4.7651e-01, -1.2700e-01],\n",
      "        [-3.4376e-01, -1.0454e-01, -4.2370e-01,  ...,  5.9750e-01,\n",
      "          3.4967e-01, -1.7650e-01],\n",
      "        ...,\n",
      "        [ 3.3592e-01,  2.0520e-01,  3.7329e-01,  ..., -1.7663e-02,\n",
      "         -2.2632e-02,  1.4085e-01],\n",
      "        [ 5.3125e+00,  1.9141e+00, -7.6545e-01,  ..., -1.2654e+00,\n",
      "          3.1250e+00, -2.5558e-01],\n",
      "        [ 2.0216e-01,  5.0190e-02, -1.2503e-01,  ..., -1.1474e-01,\n",
      "         -2.3440e-01, -2.4195e-01]])\n",
      "\n",
      "Name: decoder.block.5.layer.2.layer_norm.weight\n",
      "Weight: tensor([ 3.3279,  4.7503,  2.9372,  2.9529,  0.5114,  2.3747,  3.8907,  3.8438,\n",
      "         5.3747,  2.2031,  2.7190,  4.9372,  2.7810,  2.3126,  4.2497,  2.5627,\n",
      "         2.4841,  3.0935,  2.7190,  2.8909,  2.5315,  2.2032,  2.8591,  2.1091,\n",
      "         2.6560,  3.0471,  2.2815,  4.5310,  2.4843,  3.6096,  2.4687,  3.1409,\n",
      "         3.1716,  2.7189,  4.8126,  3.4217,  2.3591,  2.4378,  3.0625,  3.0002,\n",
      "         2.3440,  2.3909,  4.6249,  2.8278,  2.6096,  2.5315,  1.7888,  2.7659,\n",
      "         2.9378,  2.2346,  3.2341,  2.7034,  3.4216,  7.5003,  3.7341,  2.4685,\n",
      "         2.7033,  2.8909,  2.3122,  3.7972,  2.2972,  3.3596,  3.0159,  2.4685,\n",
      "         3.5315,  2.8284,  2.8279,  2.3128,  5.0003,  3.2810,  3.0310,  3.0622,\n",
      "         2.5623,  2.3594,  2.4534,  2.7342,  2.4690,  2.6409,  2.9845,  3.9060,\n",
      "         3.7347,  2.6878,  2.4685,  2.9060,  2.6095,  3.0472,  2.5940,  3.4690,\n",
      "         2.4216,  3.6565,  2.4529,  2.9065,  2.9372,  2.4377,  3.4687,  2.4216,\n",
      "         2.8440,  2.8279,  9.1878,  2.8125,  2.4841,  2.3440,  2.9841,  3.5627,\n",
      "         2.5622,  2.5315,  2.4843,  2.7341,  3.2497,  3.2190,  3.0003,  2.7810,\n",
      "         2.4372,  2.5940,  2.3596,  3.0471,  2.7501,  2.5002,  2.3909,  2.4060,\n",
      "         2.6716,  2.7034,  2.5315,  2.9534,  2.4529, 12.1253,  3.5627,  2.3278,\n",
      "         3.4846,  2.6872,  2.3127,  2.4376,  2.9372,  3.5003,  3.6873,  2.3753,\n",
      "         4.2502,  7.0628,  2.4528,  2.3591,  2.5001,  3.7028,  2.7966,  2.8749,\n",
      "         2.4061,  2.8592,  2.9534,  3.5471,  3.0315,  0.5661,  2.2342,  2.4997,\n",
      "         3.7972,  2.4375,  2.5782,  2.4998,  2.2654,  3.7815,  2.8284,  9.8122,\n",
      "         2.3595,  3.4217,  2.4690,  2.3127,  3.1406,  3.0935,  3.5940,  3.2034,\n",
      "         2.3278,  2.2971,  2.9534,  2.2028,  2.8435,  2.3903,  2.5935,  2.8597,\n",
      "         2.9060,  3.6722,  2.5153,  2.5310,  2.5154,  2.4685,  1.4919,  2.9374,\n",
      "         4.4065,  2.4529,  2.6250,  2.8903,  2.4690,  2.7503,  5.1253,  4.0940,\n",
      "         2.6408,  3.8753,  2.3283,  2.5622,  2.4997,  2.7502,  2.4377,  2.2341,\n",
      "         2.9690,  3.1404,  3.2659,  3.0310,  2.4841,  2.6096,  1.2107,  2.8126,\n",
      "         2.6872,  2.5159,  2.6408,  2.6565,  3.1565, -1.0315,  2.3591,  2.2346,\n",
      "         2.6247,  3.1404,  3.6247,  2.4217,  2.5003,  2.4534,  2.7971,  2.5784,\n",
      "         4.4685,  2.5627,  5.5003,  2.3440,  2.6719,  2.7190,  2.5940,  2.6409,\n",
      "         6.5315,  2.9528,  4.0003,  3.2034,  3.0154,  4.0315,  2.7654,  3.5310,\n",
      "         3.7502,  3.9534,  3.0159,  2.6409,  6.2815,  2.3591,  3.3909,  2.9378,\n",
      "         6.5628,  2.8592,  2.5780,  2.7812,  2.8595,  2.4060,  2.3596,  3.0159,\n",
      "         2.5158,  3.3435,  4.1253,  3.5159,  3.1560,  2.3284,  2.3753,  4.3440,\n",
      "         3.2342,  2.3904,  2.4377,  2.5156,  3.3128,  2.8753,  2.6249,  2.6872,\n",
      "         2.8283,  5.2189,  2.1716,  9.4378,  2.4221,  2.4686,  3.7971,  2.7972,\n",
      "         4.7815,  2.6722,  2.5315,  2.6096,  2.5628,  2.7185,  2.6247,  2.5466,\n",
      "         2.4377,  3.2346,  3.5312,  2.4685,  2.7654,  2.4685,  7.1878,  4.0940,\n",
      "         2.5623,  2.4530,  2.3903,  6.3752,  2.7188,  3.0315,  0.4821,  2.6561,\n",
      "         4.5003,  2.2655,  2.6717,  4.2813,  3.7811,  3.5001,  2.7190,  2.7342,\n",
      "         7.8128,  2.2344,  3.0311,  2.3440,  2.5468,  2.3753,  4.6878,  3.1404,\n",
      "         2.5003,  2.3593,  2.5471,  5.7190,  9.9372,  2.2034,  3.1092,  3.1560,\n",
      "         2.4532,  3.8435,  3.3594,  2.6560,  2.6247,  2.4689,  2.3753,  3.1091,\n",
      "         3.3909,  2.2341,  2.4529,  3.6409,  4.0310,  2.9220,  2.4372,  3.6409,\n",
      "         2.4690,  3.4065,  2.8284,  2.4534,  2.4689,  2.7815,  2.9378,  2.3753,\n",
      "         2.5315,  2.3591,  2.6404,  6.0002,  2.6565,  2.4529,  2.4841,  2.7341,\n",
      "         3.1252,  2.3909,  2.3909,  4.2185,  2.7502,  3.3903,  2.1872,  0.6794,\n",
      "         2.8283,  2.3122,  2.4221,  3.2034,  3.0159,  2.4841,  6.1560,  2.4685,\n",
      "         2.6404,  2.4690,  2.5940,  4.4687,  2.6092,  6.5628,  2.8903,  2.4842,\n",
      "         3.3597,  2.5157,  5.8753,  2.7190,  4.1878,  2.3903,  2.3281,  2.2815,\n",
      "         4.1565,  2.5314,  2.7341,  2.8283,  3.0784,  4.3128,  2.4528,  2.6716,\n",
      "         3.2815,  3.5313,  3.5315,  0.5778,  2.1253,  3.5310,  2.5159,  2.6096,\n",
      "         2.3909,  2.5940,  3.8908,  3.8278,  3.3128,  4.3123,  2.4846,  3.1092,\n",
      "         2.8903,  4.7503,  2.3748,  2.2659,  2.5623,  2.6249,  2.9685,  2.8440,\n",
      "         3.7659,  2.3753,  2.4220,  2.2501,  2.2659,  2.5628,  2.4687,  2.3435,\n",
      "         2.5628,  3.7810,  2.2810,  2.7034,  2.9060,  2.3909,  3.0471,  2.8596,\n",
      "         2.3278,  2.2033,  2.2190,  2.7503,  2.6878,  2.4377,  2.4222,  3.1565,\n",
      "         2.4534,  2.5314,  2.4690,  2.3127,  4.2815,  3.5002,  2.6721,  2.5936,\n",
      "         2.5159,  2.5315,  2.9847,  2.6253,  2.2502, 10.6877,  2.5311,  2.5315,\n",
      "         2.6093,  2.3596,  2.3750,  1.6872,  3.2345,  2.5159,  2.3122,  2.4377,\n",
      "         2.7810,  2.2971,  2.4685,  9.0628,  2.6096,  4.9997,  2.5778,  2.0155,\n",
      "         3.0470,  2.6096,  2.4065,  2.4847,  2.3435,  2.5314,  2.6251,  2.9372,\n",
      "         2.8596,  2.5315,  0.5310,  2.3749,  3.0310,  2.2033,  2.6877,  3.1252,\n",
      "         2.5002,  4.8748,  3.0466,  3.2497,  3.4846,  5.8753,  2.7970,  2.2502,\n",
      "         2.5779,  3.0159,  3.1253,  2.7814,  2.5466,  2.7659,  7.5310,  5.4690])\n",
      "\n",
      "Name: decoder.final_layer_norm.weight\n",
      "Weight: tensor([ 1.6384e-01,  3.1026e-01,  1.5501e-01,  1.4915e-01, -6.0953e-04,\n",
      "         1.2615e-01,  2.7139e-01,  2.6361e-01,  6.7160e-01,  1.0961e-01,\n",
      "         1.3449e-01,  3.5130e-01,  1.2715e-01,  1.1324e-01,  1.8747e+00,\n",
      "         1.3759e-01,  1.2180e-01,  1.9719e-01,  1.5124e-01,  1.4330e-01,\n",
      "         1.4914e-01,  9.9822e-02,  1.7941e-01,  7.0285e-01,  1.1936e-01,\n",
      "         1.9699e-01,  1.2578e-01,  5.8957e-01,  1.1368e-01,  2.2043e-01,\n",
      "         1.2572e-01,  2.6339e-01,  1.6495e-01,  1.2979e-01,  4.2942e-01,\n",
      "         2.4535e-01,  1.3060e-01,  1.2477e-01,  1.3751e-01,  1.8372e-01,\n",
      "         1.3059e-01,  1.0766e-01,  3.4542e-01,  1.6086e-01,  1.7289e-01,\n",
      "         1.3157e-01,  2.8144e-01,  1.6974e-01,  1.6099e-01,  1.2425e-01,\n",
      "         1.6673e-01,  1.7457e-01,  2.3410e-01,  4.6514e-01,  3.0496e-01,\n",
      "         1.3895e-01,  1.5403e-01,  1.6867e-01,  1.1301e-01,  2.6341e-01,\n",
      "         1.0914e-01,  2.9660e-01,  2.0986e-01,  1.2599e-01,  1.2278e-01,\n",
      "         1.8040e-01,  1.5697e-01,  1.1261e-01,  9.3332e-01,  2.2141e-01,\n",
      "         1.6823e-01,  1.5612e-01,  1.3945e-01,  1.2281e-01,  1.3839e-01,\n",
      "         1.3758e-01,  1.2595e-01,  1.6577e-01,  2.0879e-01,  2.5610e-01,\n",
      "         2.8292e-01,  1.5206e-01,  1.4920e-01,  1.6873e-01,  1.2033e-01,\n",
      "         2.2186e-01,  1.2325e-01,  2.0045e-01,  1.2963e-01,  3.5128e-01,\n",
      "         1.3255e-01,  2.0093e-01,  1.6965e-01,  1.3163e-01,  1.9319e-01,\n",
      "         1.2593e-01,  2.3801e-01,  1.3058e-01,  2.2189e-02,  1.2723e-01,\n",
      "         1.2101e-01,  1.1986e-01,  2.2679e-01,  5.6222e-01,  1.2571e-01,\n",
      "         1.3654e-01,  1.2431e-01,  1.3089e-01,  1.5066e-01,  1.8144e-01,\n",
      "         1.4719e-01,  1.9435e-01,  1.1789e-01,  1.1548e-01,  1.1161e-01,\n",
      "         1.8820e-01,  1.2374e-01,  1.2477e-01,  1.3581e-01,  1.0041e-01,\n",
      "         1.3673e-01,  1.4330e-01,  1.2146e-01,  1.2415e-01,  1.1398e-01,\n",
      "         6.5599e-01,  1.8625e-01,  1.2127e-01,  1.1837e-01,  1.3938e-01,\n",
      "         1.3468e-01,  1.1400e-01,  1.8754e-01,  2.4926e-01,  2.4005e-01,\n",
      "         1.3059e-01,  2.9855e-01,  3.7081e-01,  1.1593e-01,  1.2333e-01,\n",
      "         1.3359e-01,  4.6067e-01,  1.5616e-01,  1.3549e-01,  1.2430e-01,\n",
      "         1.8365e-01,  1.8918e-01,  2.3215e-01,  1.5598e-01,  9.1378e-01,\n",
      "         1.1545e-01,  1.1838e-01,  2.9270e-01,  1.1229e-01,  1.5116e-01,\n",
      "         1.2091e-01,  1.1444e-01,  2.3605e-01,  1.7471e-01,  9.5622e+00,\n",
      "         1.1693e-01,  2.1658e-01,  1.3158e-01,  1.3846e-01,  2.0090e-01,\n",
      "         1.5547e-01,  3.2981e-01,  2.4488e-01,  1.2087e-01,  1.1253e-01,\n",
      "         2.5172e-01,  1.1351e-01,  1.5696e-01,  1.1303e-01,  1.1058e-01,\n",
      "         1.5997e-01,  1.4431e-01,  3.5519e-01,  1.2123e-01,  1.2820e-01,\n",
      "         1.1691e-01,  1.3260e-01,  3.4663e-03,  1.7782e-01,  5.7785e-01,\n",
      "         1.3793e-01,  1.4043e-01,  1.5699e-01,  1.3266e-01,  1.8285e-01,\n",
      "         4.4060e+00,  3.8259e-01,  1.3206e-01,  3.0441e-01,  1.4044e-01,\n",
      "         1.2769e-01,  1.1781e-01,  1.9019e-01,  1.2474e-01,  1.3114e-01,\n",
      "         1.8942e-01,  2.2247e-01,  1.9699e-01,  1.7942e-01,  1.2476e-01,\n",
      "         1.4818e-01,  5.5907e-02,  2.1460e-01,  1.2229e-01,  1.2329e-01,\n",
      "         1.2864e-01,  1.2586e-01,  2.0785e-01,  4.2043e-02,  1.2042e-01,\n",
      "         1.1662e-01,  1.5355e-01,  1.9654e-01,  3.1808e-01,  1.2278e-01,\n",
      "         1.2327e-01,  1.2229e-01,  2.2242e-01,  1.2377e-01,  4.5675e-01,\n",
      "         1.2526e-01,  2.7564e-01,  1.1206e-01,  1.7411e-01,  1.7508e-01,\n",
      "         1.4036e-01,  1.3351e-01,  3.8061e-01,  1.6965e-01,  4.0011e-01,\n",
      "         1.7064e-01,  1.5039e-01,  3.1809e-01,  1.3450e-01,  2.7121e-01,\n",
      "         3.5551e-01,  2.9855e-01,  1.7888e-01,  1.2583e-01,  1.0778e+00,\n",
      "         4.5676e-01,  2.0877e-01,  1.6630e-01,  2.4971e-01,  2.0390e-01,\n",
      "         1.2036e-01,  1.2281e-01,  1.6237e-01,  1.2426e-01,  1.1302e-01,\n",
      "         1.5911e-01,  1.2488e-01,  2.4875e-01,  2.6341e-01,  2.0487e-01,\n",
      "         1.7699e-01,  1.1324e-01,  1.1551e-01,  1.3044e+00,  1.6378e-01,\n",
      "         1.1986e-01,  1.4858e-01,  1.1257e-01,  1.2375e-01,  1.9211e-01,\n",
      "         1.3689e-01,  1.5741e-01,  1.9992e-01,  1.3830e+00,  1.0376e-01,\n",
      "         7.1510e-01,  1.2431e-01,  1.2033e-01,  2.3508e-01,  2.2141e-01,\n",
      "         5.3487e-01,  1.8918e-01,  1.1936e-01,  1.7163e-01,  1.2962e-01,\n",
      "         1.5305e-01,  1.7550e-01,  1.6673e-01,  1.1939e-01,  2.0972e-01,\n",
      "         5.3521e-01,  1.2585e-01,  1.3602e-01,  1.2623e-01,  1.4060e+00,\n",
      "         3.6300e-01,  1.3058e-01,  1.1699e-01,  1.1448e-01,  1.0237e+00,\n",
      "         1.6132e-01,  1.9602e-01,  8.7509e-03,  1.2571e-01,  4.1379e-01,\n",
      "         1.1749e-01,  1.6001e-01,  4.7448e-01,  7.0285e-01,  2.0675e-01,\n",
      "         1.2378e-01,  1.7073e-01,  8.7862e-01,  1.2869e-01,  1.6627e-01,\n",
      "         1.2329e-01,  1.2809e-01,  1.1007e-01,  3.5721e-01,  2.0918e-01,\n",
      "         1.3974e-01,  1.1846e-01,  1.1638e-01,  4.3722e-01,  4.8122e+00,\n",
      "         1.0671e-01,  1.9121e-01,  1.0180e-01,  1.2140e-01,  4.4112e-01,\n",
      "         2.5559e-01,  1.5213e-01,  2.2238e-01,  1.0568e-01,  1.2280e-01,\n",
      "         2.0187e-01,  1.9408e-01,  1.2810e-01,  1.3360e-01,  1.9406e-01,\n",
      "         3.0260e-01,  1.7783e-01,  1.4327e-01,  3.5940e-01,  1.3255e-01,\n",
      "         2.6731e-01,  1.8430e-01,  1.3353e-01,  1.4134e-01,  1.4188e-01,\n",
      "         1.6965e-01,  1.4050e-01,  1.2716e-01,  1.1626e-01,  1.5027e-01,\n",
      "         3.1027e-01,  1.6709e-01,  1.2671e-01,  1.4914e-01,  1.6185e-01,\n",
      "         1.4556e-01,  1.0861e-01,  1.2427e-01,  2.0480e-01,  1.4732e-01,\n",
      "         1.9802e-01,  1.0814e-01,  5.1963e-02,  1.5305e-01,  1.2082e-01,\n",
      "         1.2186e-01,  1.7261e-01,  1.3258e-01,  1.2867e-01,  4.8409e-01,\n",
      "         1.2134e-01,  1.2184e-01,  1.4181e-01,  1.0674e-01,  3.6691e-01,\n",
      "         1.1795e-01,  1.1013e+00,  1.8637e-01,  1.2968e-01,  2.1164e-01,\n",
      "         1.3211e-01,  3.9230e-01,  1.3937e-01,  3.6117e-01,  1.1838e-01,\n",
      "         1.1371e-01,  1.1205e-01,  2.1699e-01,  1.4525e-01,  1.5112e-01,\n",
      "         1.6328e-01,  1.9557e-01,  2.0383e-01,  1.3546e-01,  1.5500e-01,\n",
      "         2.7903e-01,  4.1966e-01,  1.8917e-01,  1.8040e-02,  1.0325e-01,\n",
      "         1.6282e-01,  1.1936e-01,  1.2668e-01,  1.2668e-01,  1.2367e-01,\n",
      "         2.4582e-01,  3.3966e-01,  2.4973e-01,  3.6887e-01,  1.2770e-01,\n",
      "         1.6089e-01,  1.7551e-01,  4.6306e-01,  1.2622e-01,  1.1011e-01,\n",
      "         1.5598e-01,  1.2970e-01,  1.4775e-01,  1.4369e-01,  2.1361e-01,\n",
      "         1.1740e-01,  1.2514e-01,  1.2580e-01,  1.0911e-01,  1.3449e-01,\n",
      "         1.2279e-01,  1.2235e-01,  1.1350e-01,  2.5202e-01,  1.1105e-01,\n",
      "         1.4771e-01,  1.7883e-01,  1.1261e-01,  1.8736e-01,  1.9548e-01,\n",
      "         1.2235e-01,  1.0778e-01,  1.0275e-01,  1.7844e-01,  1.2911e-01,\n",
      "         1.2863e-01,  1.1447e-01,  2.0203e-01,  1.2144e-01,  1.1888e-01,\n",
      "         1.1154e-01,  1.1068e-01,  4.0989e-01,  2.6535e-01,  1.6183e-01,\n",
      "         1.1974e-01,  1.1351e-01,  1.3201e-01,  1.6426e-01,  1.1547e-01,\n",
      "         1.0764e-01,  7.0341e-01,  1.2668e-01,  1.2136e-01,  1.3547e-01,\n",
      "         1.0471e-01,  9.8395e-02,  1.1936e-01,  3.4154e-01,  1.2512e-01,\n",
      "         1.1844e-01,  1.0740e-01,  1.4725e-01,  1.2131e-01,  1.3162e-01,\n",
      "         5.5051e-01,  1.1546e-01,  6.0519e-01,  1.2962e-01,  1.0177e-01,\n",
      "         2.7164e-01,  1.3008e-01,  1.1985e-01,  1.0862e-01,  1.2039e-01,\n",
      "         1.1985e-01,  1.5065e-01,  1.7746e-01,  1.6186e-01,  1.4367e-01,\n",
      "        -3.9560e-04,  1.0720e-01,  1.4772e-01,  1.1892e-01,  1.2131e-01,\n",
      "         2.0774e-01,  1.2864e-01,  2.3358e-01,  2.0285e-01,  2.0676e-01,\n",
      "         1.3839e-01,  9.9191e-01,  1.7356e-01,  1.2429e-01,  1.4524e-01,\n",
      "         1.9900e-01,  2.4877e-01,  1.5011e-01,  1.5342e-01,  1.3557e-01,\n",
      "        -6.9177e-06,  4.3332e-01])\n",
      "\n",
      "Name: lm_head.weight\n",
      "Weight: tensor([[ -2.0153,   0.2239,  -7.0940,  ...,  -0.3533,   2.6409,  -2.8909],\n",
      "        [ 12.6247,   8.1872, -11.6247,  ...,   7.9372,  -7.3127,   0.9456],\n",
      "        [ -8.7499,   7.1873,  27.8749,  ..., -26.7501,   0.8555,  -1.5154],\n",
      "        ...,\n",
      "        [-25.2499, -28.4999, -17.2499,  ..., -17.7499,  -5.2500,  27.3749],\n",
      "        [-25.4999, -29.3749, -18.2499,  ..., -17.7499,  -4.8125,  27.7499],\n",
      "        [-26.7499, -28.3749, -17.8749,  ..., -18.4999,  -7.0000,  27.6249]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = model_test.state_dict()\n",
    "\n",
    "# Now, `weights` is a dictionary where the keys are the names of the parameters\n",
    "# and the values are the weights of those parameters. You can print it out like this:\n",
    "for name, weight in weights.items():\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Weight: {weight}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"./bill_sum_experiment_3_t5_small_merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\"\n",
    "text = \"summarize: The Declaration of Independence, formally titled The unanimous Declaration of the thirteen united States of America (in the engrossed version but not the original printing), is the founding document of the United States. On July 4, 1776, it was adopted unanimously by the 56 delegates to the Second Continental Congress, who had convened at the Pennsylvania State House, later renamed Independence Hall, in the colonial era capital of Philadelphia. The declaration explains to the world why the Thirteen Colonies regarded themselves as independent sovereign states no longer subject to British colonial rule. The 56 delegates who signed the Declaration of Independence came to be known as the nation's Founding Fathers, and the Declaration has become one of the most circulated, reprinted, and influential documents in world history. The Second Continental Congress charged the Committee of Five, including John Adams, Benjamin Franklin, Thomas Jefferson, Robert R. Livingston, and Roger Sherman, with authoring the Declaration. Adams, a leading proponent of independence, persuaded the Committee of Five to charge Jefferson with writing the document's original draft, which the Second Continental Congress then edited. Jefferson largely wrote the Declaration in isolation between June 11 and June 28, 1776, from the second floor of a three-story home he was renting at 700 Market Street in Philadelphia. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Declaration of Independence was adopted unanimously by the 56 delegates to the Second Continental Congress . it explains why the Thirteen Colonies regarded themselves as independent sovereign states no longer subject to British colonial rule . the Declaration has become one of the most circulated, reprinted, and influential documents in world history .'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"t5_f_experiment_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"the Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs . it's the most aggressive action on tackling the climate crisis in american history . no one making under $400,000 per year will pay a penny more in taxes .\"}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5ee04c74df410795e60e26ceab02e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fbc435b11944e7aff6ab92d689ff59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704ed1dfc4144e698788e75ba851e978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66deffa4669c430d8e3c0e903a1c1437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"t5_f_experiment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"the Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs . it's the most aggressive action on tackling the climate crisis in american history . no one making under $400,000 per year will pay a penny more in taxes .\"}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"stevhliu/my_awesome_billsum_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'On July 4, 1776, the Declaration of Independence was adopted unanimously by the 56 delegates to the Second Continental Congress, who had convened at the Pennsylvania State House, later renamed Independence Hall, in the colonial era capital of Philadelphia . the Declaration explains to the world why the Thirteen Colonies regarded themselves as independent sovereign states no longer subject to British colonialism. The Declaration has become one of the most circulated, reprinted, and influential documents in world history.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "dataset = load_dataset(\"lewtun/drug-reviews\")\n",
    "train_data = dataset['train']\n",
    "eval_data = dataset['test']\n",
    "reviews_train = train_data['review']\n",
    "ratings_train = train_data['rating']\n",
    "reviews_eval = eval_data['review']\n",
    "ratings_eval = eval_data['rating']\n",
    "drug_data_train = {'label': [int(rating-1) for rating in ratings_train],'text': reviews_train}\n",
    "drug_data_train = Dataset.from_dict(drug_data_train)\n",
    "drug_data_eval = {'label': [int(rating-1) for rating in ratings_eval],'text': reviews_eval}\n",
    "drug_data_eval = Dataset.from_dict(drug_data_eval)\n",
    "# reviews = dataset['reviews']\n",
    "# ratings = dataset['rating']\n",
    "# drug_data = {'label': [int(rating) for rating in ratings],'text': reviews}\n",
    "# drug_data = Dataset.from_dict(drug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89db6c8d41a4ab89e60ef00f759f2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/161297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b23709c69443fda9560042f76b6cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_drug_train = drug_data_train.map(lambda examples:tokenizer(examples[\"text\"], truncation=True, max_length=1024),batched=True)\n",
    "tokenized_drug_test = drug_data_eval.map(lambda examples:tokenizer(examples[\"text\"], truncation=True, max_length=1024),batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"openai-community/gpt2\",\n",
    "            num_labels=10)\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_drug_train.shuffle(seed=42).select(range(5))\n",
    "eval_dataset = tokenized_drug_test.shuffle(seed=42).select(range(5))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = HF_ACCESS_TOKEN \n",
    "username = HF_USERNAME
    "output_repo = \"test_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"test\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=6e-5,    #read that with larger batch size we can increase learning rate\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=1,\n",
    "    #fp16=True,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    #evaluation_strategy=\"no\",\n",
    "    #do_eval=False,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    hub_model_id=f\"{username}/{output_repo}\",\n",
    "    hub_token = access_token,\n",
    "    push_to_hub=False\n",
    ")\n",
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=train_dataset,\n",
    "eval_dataset=eval_dataset,\n",
    "tokenizer=tokenizer,\n",
    "data_collator=data_collator,\n",
    "compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************TRAINING STARTED*************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.699694</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df33deb9d52c4e949d3abb6ba19e3341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************TRAINING COMPLETED**************\n"
     ]
    }
   ],
   "source": [
    "print('************TRAINING STARTED*************')\n",
    "result = trainer.train()\n",
    "print('*************TRAINING COMPLETED**************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [4, 1, 3],\n",
       " 'text': [\"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\",\n",
       "  \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\",\n",
       "  \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\"]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset['train']\n",
    "train_dataset[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
